<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>Hacker News</title>
        <link>https://news.ycombinator.com/newest</link>
        <description>Hacker News</description>
        <lastBuildDate>Wed, 14 Jul 2021 20:05:05 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>awesome</generator>
        <language>en</language>
        <image>
            <title>Hacker News</title>
            <url>https://remyhax.xyz/image/profile.jpg</url>
            <link>https://news.ycombinator.com/newest</link>
        </image>
        <copyright>DO WHAT THE FUCK YOU WANT TO PUBLIC LICENSE</copyright>
        <item>
            <title><![CDATA[Microsoft fails to provide Windows 10 VM images for developers | Ars Technica]]></title>
            <link>https://arstechnica.com/gadgets/2021/07/microsoft-fails-to-provide-windows-10-vm-images-for-developers</link>
            <guid>https://arstechnica.com/gadgets/2021/07/microsoft-fails-to-provide-windows-10-vm-images-for-developers</guid>
            <pubDate>Wed, 14 Jul 2021 20:04:26 GMT</pubDate>
            <content:encoded><![CDATA[SKIP TO MAIN CONTENT
SUBSCRIBE
SIGN IN
DUDE, WHERE'S MY VM? —
Developing for Windows 10 using VMs? Hope you’re using Hyper-V
Microsoft's Windows 10 VMs for devs expired on July 10. They're still missing.

JIM SALTER - 7/14/2021, 3:50 PM

Enlarge / Image not found: why has it taken Microsoft five days (and counting) to upload fresh developer VM images for non-Hyper-V platforms?
Sean Gladwell / Getty Images

Microsoft typically makes Windows 10 Enterprise virtual machine images available to independent developers via its developer.microsoft.com portal. For some reason, that process seems to have fallen through the cracks this month—images are available now for Microsoft's Hyper-V hypervisor but are conspicuously missing for competing hypervisors VMWare, Parallels, and VirtualBox.

@windowsdev It's pretty telling that you guys have let the free VMWare/VirtualBox/Parallels Windows dev images expire but updated the HyperV image. Preferential treatment much?@VMware @virtualbox @ParallelsMac @ParallelsCares Antitrust? 🤑🥳😎@FTC Yo, we got shenanigans afoot!

— Matthew Boyette (@Dyndrilliac) July 12, 2021

Ars first became aware of this problem via impassioned tweets from Matthew Boyette, an Ars reader and independent developer whose workflow depends on these Windows 10 Enterprise VM images. The images themselves are decidedly ephemeral—they expire each month, requiring devs using the program to download new, refreshed images.

June's developer VM images expired five days ago (July 10), and despite several days of Boyette's angry tweets, the missing VM images are still missing. While VM images for Hyper-V—Microsoft's own hypervisor—were uploaded to the portal on time, devs who use VMWare, VirtualBox, or Parallels to host their virtual machines are still out of luck.

Advertisement

The lack of images presents a larger problem for developers who depend on them than one might expect. While it's true that a developer can still download a Windows 10 ISO and install a new VM from scratch, that doesn't replace everything the developer VMs offer. For one thing, a scratch-installed Windows 10 VM would be unlicensed and, therefore, not allow certain operating system functions (such as desktop personalization) which may be important for some developers' applications.

There's also a sizable laundry list of preinstalled and preconfigured software and features on the developer image—including the Windows 10 Software Developer Kit, Visual Studio 2019, Visual Studio Code, the Windows Subsystem for Linux (with Ubuntu pre-installed), and more. Recreating the entire environment is certainly still possible—but it represents substantial hours of work on the part of the hapless dev attempting to do so, along with plenty of additional room for error on the dev's part.

Enlarge / Microsoft is apparently being specific when it states that it's "working on uploading" (not creating) the missing VM images. Note that the list of lengths and hashes is fully populated.
Jim Salter

Bizarrely, the bottom of the developer image-download portal shows valid file names, lengths, and even hashes of the missing VM images—they're just not available for download.

Ars inquired about the status of the missing images Tuesday afternoon. As of Wednesday afternoon, Microsoft's PR firm has still not acknowledged the inquiry, and the images are still unavailable.

READER COMMENTS
8
WITH 6 POSTERS PARTICIPATING, INCLUDING STORY AUTHOR
SHARE THIS STORY
SHARE ON FACEBOOK
SHARE ON TWITTER
SHARE ON REDDIT
JIM SALTER
Jim is an author, podcaster, mercenary sysadmin, coder, and father of three—not necessarily in that order.
EMAIL jim.salter@arstechnica.com // TWITTER @jrssnet
Advertisement
Channel Ars Technica
SITREP: F-16 replacement search a signal of F-35 fail?

Footage courtesy of Dvids, Boeing, and The United States Navy.

SITREP: F-16 replacement search a signal of F-35 fail?
Sitrep: Boeing 707
Steve Burke of GamersNexus Reacts To Their Top 1000 Comments On YouTube
Scott Manley Reacts To His Top 1000 YouTube Comments
LGR's Clint Basinger Reacts To His Top 1000 YouTube Comments
How Forza's Racing AI Uses Neural Networks To Evolve
The F-35's next tech upgrade
Fighter Pilot Breaks Down Every Button in an F-15 Cockpit
Linus "Tech Tips" Sebastian Reacts to His Top 1000 YouTube Comments
Customizing Mini 4WD Racers For High Speeds On A Small Scale
MegaBots: Born to Smash Anything in Their Path
First Look: Xbox Adaptive Controller
Quantum Computing Expert Explains One Concept in 5 Levels of Difficulty
Kids versus 80s tech: Game Boy, Vectrex and a stereo system
Expert Explains One Concept in 5 Levels of Difficulty - Blockchain
Best wearable tech of 2017
The Moov HR Sweat - heart rate monitor in a headband | Ars Technica
More videos
← PREVIOUS STORY
Related Stories
Today on Ars
STORE
SUBSCRIBE
ABOUT US
RSS FEEDS
VIEW MOBILE SITE
CONTACT US
STAFF
ADVERTISE WITH US
REPRINTS
NEWSLETTER SIGNUP

Join the Ars Orbital Transmission mailing list to get weekly updates delivered to your inbox.

SIGN ME UP →

CNMN Collection
WIRED Media Group
© 2021 Condé Nast. All rights reserved. Use of and/or registration on any portion of this site constitutes acceptance of our User Agreement (updated 1/1/20) and Privacy Policy and Cookie Statement (updated 1/1/20) and Ars Technica Addendum (effective 8/21/2018). Ars may earn compensation on sales from links on this site. Read our affiliate link policy.
Your California Privacy Rights | Cookies Settings
The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Condé Nast.
Ad Choices]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Steinar H. Gunderson]]></title>
            <link>http://blog.sesse.net/blog/tech/2021-07-13-15-32_optimization_silver_bullets.html</link>
            <guid>http://blog.sesse.net/blog/tech/2021-07-13-15-32_optimization_silver_bullets.html</guid>
            <pubDate>Wed, 14 Jul 2021 20:04:17 GMT</pubDate>
            <content:encoded><![CDATA[<	July 2021	
Su	Mo	Tu	We	Th	Fr	Sa
 	 	 	 	1	2	3
4	5	6	7	8	9	10
11	12	13	14	15	16	17
18	19	20	21	22	23	24
25	26	27	28	29	30	31
Categories
/ (3)
  tech/ (3)
Steinar H. Gunderson
Tue, 13 Jul 2021 - Optimization silver bullets

If you work with optimizing code for a while, you'll notice that a fairly common pattern is for people to believe in optimization silver bullets; just one trick that they think is always the solution for whatever woes you may have. It's not that said thing is bad per se, it's just that they keep suggesting the same thing over and over even if that's not actually the issue.

To name some examples: I've seen people suggesting removing mallocs is always the case (even if malloc didn't show up on the profile), or that adding likely() and unlikely() everywhere would double the IPC of a complex system (PGO, with near-perfect condition probabilities, gave 5%), or designed a system entirely around minimizing instruction cache pressure (where the system they intended to replace didn't have issues with instruction cache). And I guess we've all seen the people insisting on optimizing their code on -O9, because higher is better, right, and who are the GCC people to compile their own code with -O2 anyway?

I've more or less learned to ignore these people, as long as they don't show up with profiles and microbenchmarks, which they never do. (This is the easiest way to see if people's suggestions are bogeymen or real; if people know what they're doing, they can point to a real profile, and they'll write a stable microbenchmark to show that they've actually fixed the issue and to guard against future regressions.) But there's one silver bullet that always rubs me the wrong way: False sharing.

False sharing is when two unrelated items happen to lie on the same cache line, and they are accessed frequently by different cores. Seemingly, false sharing is just exotic enough that people have heard of it and are proud of that, and then they start being afraid of it everywhere for no good reason. I've seen people writing large incantations to protect against false sharing, presumably blowing the data cache in the process, and then discovered that due to them misunderstanding the compiler, the entire thing had been a no-op for years. It's pretty crazy.

That's why I was very happy to finally, after 25 years of multithreaded coding, discover a real case of false sharing in PiStorm; one thread had a local variable made global for some no-longer-relevant debugging reasons, and another thread was making constant writes to a global one in a busy loop. Really a classic, bad case of false sharing. Rune wrote up a patch, and lo and behold, the benchmarks went up!

…by about one percent.

[15:32] | | Optimization silver bullets
Steinar H. Gunderson <steinar+blog@gunderson.no>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Resilience, not collapse: What the Easter Island myth gets wrong | EurekAlert! Science News]]></title>
            <link>https://www.eurekalert.org/pub_releases/2021-07/bu-rn070921.php</link>
            <guid>https://www.eurekalert.org/pub_releases/2021-07/bu-rn070921.php</guid>
            <pubDate>Wed, 14 Jul 2021 20:02:35 GMT</pubDate>
            <content:encoded><![CDATA[Skip to main content
ADVANCED SEARCH
HOME
COVID-19
NEWS RELEASES
MULTIMEDIA
MEETINGS
PORTALS
ABOUT
LOGIN
NEWS RELEASE 13-JUL-2021
Resilience, not collapse: What the Easter Island myth gets wrong

BINGHAMTON UNIVERSITY

Research News

    SHARE
 PRINT  E-MAIL

BINGHAMTON, N.Y. -- New research from Binghamton University, State University of New York suggests that the demographic collapse at the core of the Easter Island myth didn't really happen.

You probably know this story, or a version of it: On Easter Island, the people cut down every tree, perhaps to make fields for agriculture or to erect giant statues to honor their clans. This foolish decision led to a catastrophic collapse, with only a few thousand remaining to witness the first European boats landing on their remote shores in 1722.

But did the demographic collapse at the core of the Easter Island myth really happen? The answer, according to new research by Binghamton University anthropologists Robert DiNapoli and Carl Lipo, is no.

Their research, "Approximate Bayesian Computation of radiocarbon and paleoenvironmental record shows population resilience on Rapa Nui (Easter Island)," was recently published in the journal Nature Communications. Co-authors include Enrico Crema of the University of Cambridge, Timothy Rieth of the International Archaeological Research Institute and Terry Hunt of the University of Arizona.

Easter Island, or Rapa Nui in the native language, has long been a focus of scholarship into questions related to environmental collapse. But to resolve those questions, researchers first need to reconstruct the island's population levels to ascertain whether such a collapse occurred and, if so, the scale.

"For Rapa Nui, a big part of scholarly and popular discussion about the island has centered around this idea that there was a demographic collapse, and that it's correlated in time with climate changes and environmental changes," explained DiNapoli, a postdoctoral research associate in environmental studies and anthropology.

Sometime after it was settled between the 12th to 13th centuries AD, the once-forested island was denuded of trees; most often, scholars point to human-prompted clearing for agriculture and the introduction of invasive species such as rats. These environmental changes, the argument goes, reduced the island's carrying capacity and led to a demographic decline.

Additionally, around the year 1500, there was a climactic shift in the Southern Oscillation index; that shift led to a dryer climate on Rapa Nui.

"One argument is that changes in the environment had a negative impact. People see that there was a drought and said, 'Well, the drought caused these changes,'" said Lipo, a professor of anthropology and environmental studies and associate dean of Harpur College. "There are changes. Their population changes and their environment changes; over time, the palm trees were lost and at the end, the climate got drier. But do those changes really explain what we're seeing in the population data through the radiocarbon dating?"

Reconstructing population changes

Archaeologists have different ways to reconstruct population sizes using proxy measures, such as looking at the different ages of individuals at burial sites or counting ancient house sites. That latter measure can be problematic because it makes assumptions as to the number of people who live in each house, and whether the houses were occupied at the same time, DiNapoli said.

The most common technique, however, uses radiocarbon dating to track the extent of human activity during a moment in time, and extrapolating population changes from that data. But radiocarbon dates can be uncertain, DiNapoli acknowledged.

For the first time, DiNapoli and Lipo have presented a method that is able to both resolve these uncertainties and show how changes in population sizes relate to environmental variables over time.

Standard statistical methods don't work when it comes to linking the radiocarbon data to environmental and climate changes, and the population shifts connected with them. To do so would involve estimating a "likelihood function," which is currently difficult to compute. Approximate Bayesian Computation, however, is a form of statistical modeling that doesn't require a likelihood function, and thus gives researchers a workaround, DiNapoli explained.

Using this technique, the researchers determined that the island experienced steady population growth from its initial settlement until European contact in 1722. After that date, two models show a possible population plateau, while another two models show possible decline.

In short, there is no evidence that the islanders used the now-vanished palm trees for food, a key point of many collapse myths. Current research shows that deforestation was prolonged and didn't result in catastrophic erosion; the trees were ultimately replaced by gardens mulched with stone that increased agricultural productivity. During times of drought, the people may have relied on freshwater coastal seeps.

Construction of the moai statues, considered by some to be a contributing factor of collapse, actually continued even after European arrival.

In short, the island never had more than a few thousand people prior to European contact, and their numbers were increasing rather than dwindling, their research shows.

"Those resilience strategies were very successful, despite the fact that the climate got drier," Lipo said. "They are a really good case for resiliency and sustainability."

Burying the myth

Why, then, does the popular narrative of Easter Island's collapse persist? It likely has less to do with the ancient Rapa Nui people than ourselves, Lipo explained.

The concept that changes in the environment affect human populations began to take off in the 1960s, Lipo said. Over time, that focus became more intense, as researchers began to consider changes in the environment as a primary driver of cultural shifts and transformations.

But this correlation may derive more from modern concerns with industrialization-driven pollution and climate change, rather than archaeological evidence. Environmental changes, Lipo points out, occur on different time scales and in different magnitudes. How human communities respond to these changes varies.

Take a classic example of the overexploitation of resources: the collapse of the cod fisheries in the American Northeast. While the economies of individual communities may have collapsed, larger harvesting efforts simply switched to the other side of the world.

On an isolated island, however, sustainability is a matter of the community's very survival and resources tend to be managed conservatively. A misstep in resource management could lead to tangible, catastrophic consequences, such as starvation.

"The consequences of your actions are immediately obvious to you, and everyone else around you," Lipo said.

Lipo acknowledged that proponents of the Easter Island collapse story tend to see him as a climate-change denier; that's emphatically not the case. But he cautioned that the ways ancient peoples dealt with climate and environmental changes aren't necessarily reflective of current global crises and their impact in the modern world. In fact, they may have a good deal to teach us about resilience and sustainability.

"There's a natural tendency to think that people in the past aren't as smart as we are and that they somehow made all these mistakes, but it's really the opposite," Lipo said. "They produced offspring, and the success that created the present. Even though their technologies might be more simple than ours, there is so much to be learned about the context in which they were able to survive."

###

Disclaimer: AAAS and EurekAlert! are not responsible for the accuracy of news releases posted to EurekAlert! by contributing institutions or for the use of any information through the EurekAlert system.

    SHARE
 PRINT  E-MAIL

Media Contact

John Brhel
jbrhel@binghamton.edu

 @binghamtonu

http://www.binghamton.edu 

More on this News Release
Resilience, not collapse: What the Easter Island myth gets wrong

BINGHAMTON UNIVERSITY

JOURNAL
Nature Communications
KEYWORDS
ANTHROPOLOGY
ARCHAEOLOGY
EARTH SCIENCE
HISTORY
HYDROLOGY/WATER RESOURCES
NEW WORLD
SOCIAL/BEHAVIORAL SCIENCE
RELATED JOURNAL ARTICLE
http://dx.doi.org/10.1038/s41467-021-24252-z 
More in Social & Behavior
Even on Facebook, COVID-19 polarized members of US Congress
OHIO STATE UNIVERSITY
US congressional members struck a different tone along party lines in 8 months of COVID-19 social
AMERICAN ASSOCIATION FOR THE ADVANCEMENT OF SCIENCE
Communication strongly linked to productivity in a software organization
PLOS
Teasing out the impact of Airbnb listings on neighborhood crime
PLOS
View all in Social & Behavior 
Trending News Releases
USC study shows dire impacts downstream of Nile River dam
UNIVERSITY OF SOUTHERN CALIFORNIA
Empathy may drive rats and other mammals to help friends over strangers
ELIFE
Escort services and strip clubs don't increase sex crimes
OXFORD UNIVERSITY PRESS USA
Neutron-clustering effect in nuclear reactors demonstrated for first time
DOE/LOS ALAMOS NATIONAL LABORATORY
View all latest news releases 

Copyright © 2021 by the American Association for the Advancement of Science (AAAS)

Latest News Releases RSS Feed
All EurekAlert! RSS Feeds
@EurekAlert
facebook.com/EurekAlert
Help / FAQ
Disclaimer
Privacy Policy
Terms & Conditions
Contact EurekAlert!]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Watch "Fight to Repair," demand the right to repair — Free Software Foundation — Working together for free software]]></title>
            <link>https://u.fsf.org/fight-to-repair</link>
            <guid>https://u.fsf.org/fight-to-repair</guid>
            <pubDate>Wed, 14 Jul 2021 20:02:32 GMT</pubDate>
            <content:encoded><![CDATA[​
Move freedom forward with a donation to the FSF!

Without free software, we cannot and will not have a free society. We rely on donations from people like you, who use and appreciate our work. Fuel our journey forward, and help us reach our ultimate destination: full software freedom.

Support us with a donation today, and help us maximize our summer fundraising goal by donating before July 19 – Every contribution will be matched dollar for dollar by our generous donors up to USD 11,000.

Read more | Join

 Join
 Renew
 Donate
Log in Help! Members forum
about campaigns licensing membership resources community donate shop search
Community ›
Watch "Fight to Repair," demand the right to repair
by Zoe Kooyman — Published on Jan 11, 2021 04:52 PM
"Fight to Repair" is an animated video from the Free Software Foundation (FSF) about two free software engineers rushing to fix a life-threatening problem in a vehicle's autopilot code.

Coming up with a fix for the bug is only the first step in their journey, which has them facing off against the malicious proprietary software corporation DeceptiCor, and culminates in a high-speed motorcycle chase.

This video is the newest addition to the series of animated videos created by the FSF on the subject of free software. Safety regulations on the operation of vehicles and other potentially dangerous devices may be necessary, but we know this can be accomplished without denying users the right to repair. Fight to Repair dramatizes something we see happening more and more frequently -- companies giving themselves and their software unjust control over users, often also leaving those users in unsafe situations in order to maximize profit.

As part of the video launch, the FSF has dedicated a new campaign and a collaborative resource page to the right to repair movement to help spread global awareness of this issue and to highlight how, when devices are powered by software, having a right to repair requires having the four freedoms that define free software.

Support our work

To help us bring attention to the importance of the right to repair, and the need to maintain our rights to own and fix technology, please show your support by promoting this video.

Share a message on your favorite microblog.
Here's a short URL you can use: https://u.fsf.org/fight-to-repair
Use these images and the #FighttoRepair hashtag
Read about FSF's fight to repair campaign on fsf.org/ftr, and add to the resources page

If you enjoy this video, please consider becoming an FSF associate member or donating to the FSF to help us create more videos like this to help spread free software awareness.

Download the video:
webm: 720p | 360p

Ogg Theora: 720p | 360p

mp4: 720p | 360p

Source files: Source files

More information about the different formats the FSF chooses to use

Subtitles and translations

Help us translate to many different languages so we can share this video across the globe! Translation drafts and the how-to explanation can be found on the LibrePlanet wiki. Once you have finalized a translation, email campaigns@fsf.org and we will publish it.

Subtitle files: English | French | Brazilian | Persian | Italian | Dutch | Spanish

Embed

Embed Fight to Repair on your site or blog with this code:

<iframe src="https://www.fsf.org/videos/fight-to-repair/iframe.html" id="fight-to-repair-iframe" scrolling="no" style="overflow: hidden; margin: 0; border: 0 none; display: block; width: 100%; height: 600px"></iframe>
<script>
// @license magnet:?xt=urn:btih:1f739d935676111cfff4b4693e3816e664797050&dn=gpl-3.0.txt GPL-3.0-or-later
window.onmessage = function (e) { if (e.data.hasOwnProperty("fsfIframeHeight")) { document.getElementById('fight-to-repair-iframe').style.height=`${e.data.fsfIframeHeight}px`; } };
// @license-end
</script>

Video credits:

Fight to Repair created for the Free Software Foundation
LENGTH: 3:11
PRODUCER & DIRECTOR: Brad Burkhart
STORY: Brad Burkhart
ANIMATOR: Zygis Luksas


Fight to Repair by the Free Software Foundation Copyright © 2021 is licensed under the Creative Commons Attribution-ShareAlike 4.0 International License.

Document Actions
Share on social networks Syndicate: News Events Blogs Jobs GNU
Filed under: video

Take Action!
The journey starts with a single step. Join the community brainstorms about the new FSF Freedom Ladder campaign

FSF community blog
Licensing Compliance Lab blog
Associate Membership blog
System Administrator's blog
Free Software Directory blog
GNU Press blog
Sign up

Enter your email address to receive our monthly newsletter, the
Free Software Supporter

News
 Apply to be the FSF's next executive director
Jul 02, 2021
 FSF takes next step in commitment to improving board governance
Jul 01, 2021
 Update to the FSF and GNU's plan to move IRC channels to Libera.Chat
Jun 15, 2021
More news…

Recent blogs
Step by step encryption with the updated Email Self-Defense guide
Push freedom even further at double the speed this week
New! Contributor's Frequently Asked Questions (FAQ) guide
The journey begins with a single step: climb the freedom ladder
Recent blogs -
More…

Upcoming Events
 "Freedom ladder" IRC discussion and brainstorming: July 15
Jul 15, 2021 04:00 PM - 05:00 PM — #fsf Libera.Chat IRC channel
 "Freedom ladder" IRC discussion and brainstorming: July 22
Jul 22, 2021 04:00 PM - 05:00 PM — #fsf Libera.Chat IRC channel
Previous events…
Upcoming events…
 

The FSF is a charity with a worldwide mission to advance software freedom — learn about our history and work.

Copyright © 2004-2021 Free Software Foundation, Inc. Privacy Policy.

This work is licensed under a Creative Commons Attribution-No Derivative Works 3.0 license (or later version) — Why this license?

About
Staff and Board
Contact Us
Press Information
Jobs
Volunteering and Internships
Privacy Policy
JavaScript Licenses
Hardware Database
Free Software Directory
Free Software Resources
Copyright Infringement Notification
Campaigns
High Priority Free Software Projects
Free JavaScript
Secure Boot vs Restricted Boot
Upgrade from Windows
Surveillance
GNU Operating System
Defective by Design
End Software Patents
OpenDocument
Free BIOS
Connect with free software users
Licensing
Education
Licenses
GNU GPL
GNU AGPL
GNU LGPL
GNU FDL
Licensing FAQ
Compliance
How to use GNU licenses
for your own software
Latest News
Upcoming Events
FSF Blogs
Donate to the FSF
Join the FSF
Patrons
Associate Members
My Account
Working Together for Free Software Fund
Philosophy
The Free Software Definition
Copyleft: Pragmatic Idealism
Free Software and Free Manuals
Selling Free Software
Motives for Writing Free Software
The Right To Read
Why Open Source Misses the Point of Free Software
Complete Sitemap
Plone
Zope
Python
CiviCRM
HTML5

Arabic
Belarussian
Bulgarian
Catalan
Chinese
Cornish
Czech
Danish
English
French
German
Greek
Hebrew
Hindi
Italian
Japanese
Korean
Norwegian
Polish
Portuguese
Portuguese (Brazil)
Romanian
Russian
Slovak
Spanish
Swedish
Turkish
Urdu
Welsh
   

Send your feedback on our translations and new translations of pages to campaigns@fsf.org.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Preserving Worlds]]></title>
            <link>https://preservingworlds.net/</link>
            <guid>https://preservingworlds.net/</guid>
            <pubDate>Wed, 14 Jul 2021 20:02:31 GMT</pubDate>
            <content:encoded><![CDATA[PRESENTS:
Greetings, Netizens!

Watch now on Means TV! 

Preserving Worlds is a documentary series about aging virtual worlds.

Virtual worlds are delicate things, and they can vanish with hardly a trace. You can archive the offline software, but a dead world can only tell you so much. It’s just as important to document how people spent their time within it.

Preserving Worlds is a travelogue that takes you through some of the most interesting and impactful online games and communities of the past forty years to see what it’s like to visit them today. Along the way, you’ll meet people who are working against obsolescence to keep the communities they care about alive and accessible.

The series takes an ethnographic approach to capture historically important information about the player communities of online video games, as well as some offline games indelibly stamped by the creative contributions of their players.

This website's purpose is to provide you with supporting information to help you learn more about the games we featured, see some of the efforts that have been made to preserve them, find out about the music and player-created areas/games that appear in each episode, and learn how you can access these games for yourself. Click a game's name above to learn more about it!

Preserving Worlds was created by Derek Murphy and Mitchell Zemil, the filmmakers behind the feature-length surrealist documentary Sarasota Half in Dream.

The Preserving Worlds theme song is "Wilton, Clarkson, James" by Graham Kartna.

The character portraits and imaginary UI windows for this series were created by Bachelor Soft.

Thanks for visiting!

(Terms & Conditions)]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Hackers Move to Extort Gaming Giant EA]]></title>
            <link>https://www.vice.com/en/article/m7e57n/hackers-extort-ea-fifa</link>
            <guid>https://www.vice.com/en/article/m7e57n/hackers-extort-ea-fifa</guid>
            <pubDate>Wed, 14 Jul 2021 20:02:27 GMT</pubDate>
            <content:encoded><![CDATA[ADVERTISEMENT
SIGN INCREATE ACCOUNT
+ ENGLISH
Video
TV
News
Tech
Rec Room
Hackers Move to Extort Gaming Giant EA
After trying to sell a cache of stolen data, hackers are now dumping some of the information publicly in the hopes of forcing EA to pay a ransom.
By Joseph Cox
July 13, 2021, 10:49pm
Share
Tweet
Snap
IMAGE: ANDREAS RENTZ/GETTY IMAGES
Hacking. Disinformation. Surveillance. CYBER is Motherboard's podcast and reporting on the dark underbelly of the internet.
SEE MORE →

The hackers who previously stole a wealth of data from gaming giant Electronic Artshave moved from trying to sell that data to now releasing parts of it publicly. In one message on a forum accompanying the data dump, the hackers say explicitly they are trying to extort EA as well.

ADVERTISEMENT

"Few week ago we send email for ransome [sic] to EA but we dont get any response so we will posting the src [source]," one of the posts from the hackers reads. A compressed, 1.3GB cache the hackers released appears to include references to internal EA tools and the company's Origin store, according to a copy viewed by Motherboard.

"If they dont contact us or dont pay us we will keep posting it," the hackers threatened. The data they stole totals in at around 780GB, Motherboard previously reported. That data includes source code for the Frostbite engine, used in games such as Battlefield; internal development tools, and software development kits (SDKs). The hackers also provided Motherboard with screenshots that appear to show data related to The Sims.

Do you work at EA? Do you know anything else about this breach or another? We’d love to hear from you. Using a non-work phone or computer, you can contact Joseph Cox securely on Signal on +44 20 8133 5190, Wickr on josephcox, OTR chat on jfcox@jabber.ccc.de, or email joseph.cox@vice.com.

In a statement on Tuesday, an EA spokesperson told Motherboard "We're aware of the recent posts by the alleged hackers and we are analyzing the files released. At this time, we continue to believe that it does not contain data that poses any concern to player privacy, and we have no reason to believe that there is any material risk to our games, our business or our players. We continue to work with federal law enforcement officials as part of this ongoing criminal investigation." EA added it has made security improvements in the wake of the incident.

In messages over the past few weeks to Motherboard, the hackers have repeatedly claimed they have sent ransom demands to EA. At the time, EA told Motherboard it had not received such a demand. The company now said it has faced an extortion threat.

At one point, the hackers asked Motherboard to directly deliver an extortion message to EA on their behalf. Motherboard declined to do so. Now, the hackers have publicly aired their extortion attempt themselves.

Motherboard previously reported that the hackers broke into EA by purchasing a Slack login token from an underground market. The hackers then moved through EA's network before finding the source code and other data.

Subscribe to our cybersecurity podcast, CYBER.

TAGGED:
HACKINGHACKERSCYBEREXTORTION
ORIGINAL REPORTING ON EVERYTHING THAT MATTERS IN YOUR INBOX.
Subscribe

By signing up to the VICE newsletter you agree to receive electronic communications from VICE that may sometimes include advertisements or sponsored content.

MORE
FROM VICE
Tech
Finance Giant Plaid Paid People $500 for Their Employer Payroll Logins
JOSEPH COX
05.11.21
Tech
Lawyer Asks For New Trial After Cellebrite Vulnerability Discovery
JOSEPH COX
04.27.21
Tech
Hacker Tried to Poison Florida City's Water Supply, Police Say
JASON KOEBLER, JOSEPH COX
02.08.21
Tech
There's Another Facebook Phone Number Database Online
JOSEPH COX
04.09.21
Tech
Bot Lets Hackers Easily Look Up Facebook Users' Phone Numbers
JOSEPH COX
01.25.21
Tech
T-Mobile, Verizon, AT&T Stop SMS Hijacks After Motherboard Investigation
JOSEPH COX
03.25.21
ADVERTISEMENT
ABOUT
JOBS
PARTNER
VICE VOICES
CONTENT FUNDING ON VICE
SECURITY POLICY
PRIVACY & TERMS
ACCESSIBILITY STATEMENT
DO NOT SELL MY INFO
© 2021 VICE MEDIA GROUP]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Why Are Enterprises So Slow? – zwischenzugs]]></title>
            <link>https://zwischenzugs.com/2018/10/02/why-are-enterprises-so-slow</link>
            <guid>https://zwischenzugs.com/2018/10/02/why-are-enterprises-so-slow</guid>
            <pubDate>Wed, 14 Jul 2021 19:57:29 GMT</pubDate>
            <content:encoded><![CDATA[Skip to content

zwischenzugs

Why Are Enterprises So Slow?
 zwischenzugs
 Uncategorized
 October 2, 2018
18 Minutes
tl;dr
In this article I want to explain a few things about enterprises and their software, based on my experiences, and also describe what things need to be in place to make change  come about. Have you ever found yourself saying things like:
Why are enterprises so slow?
How do they decide what to buy?
Why is it so hard to deliver things in an enterprise?
I worked for a large ‘enterprise’ organisation for a few years trying to deliver infrastructure software change, and found myself having to explain these things to developers who worked there, salespeople, external open source engineers, software engineers who worked for enterprise vendors, and even many, many people within that organisation. A few of those people suggested I write these explanations up so that they could pass it on to their fellow salespeople/engineers etc..

The polygon of Enterprise despair

Background
Before the enterprise, I worked for a startup that grew from a single room to 700+ people over 15 years. ‘Enterprise’ was a word often thrown at us when rejecting our software, usually in the sentence “your software isn’t enterprise enough”. I had no idea what that meant, but I have a much better idea now. It didn’t help that the people saying that were usually pretty clueless about software engineering. Like many other software developers whose experience was in an unregulated startup environment, I had little respect for the concept of enterprise software. Seems I wasn’t alone. When I finally got sick of the startup life I took a job at a huge organisation in financial services over 200 times as large. You don’t get much more ‘enterprise’ than that, but even within that context I was working in the ‘infrastructure team’, the part of the group that got beaten up for being (supposedly) slow to deliver, and then delivering less usable software than was desired. So it was like being in the enterprise, squared. Over the time that I worked there, I got a great insight into the constraints on delivery that cause client frustration to happen, and – worse luck – I was responsible for helping to deliver change within it. This is quite a long post, so I’ve broken this up into several parts to make it easier to digest:
Thought Experiment
What would happen if an enterprise acted like a startup?
Reducing Risk
Some ways enterprises reduce risk
The principle underlying these methods
Cumulative Constraints
Consequences of the culture of risk reduction
A New Hope?
What can be done?
1) Thought Experiment
Before we start, let’s imagine a counterfactual situation – imagine an enterprise acted like a startup. Showing how this doesn’t work (and therefore why it generally doesn’t happen) will help illustrate why some of the constraints that cause the slowdowns we see in large organisations exist. First, let’s look at what a small team might do to change some software. We’ll make it a really simple example, and one you might well do routinely at home – upgrading a Linux distribution. In both cases, the relationship is:
IT person
Manager
Here’s how the conversation might go at a really small startup:
‘Lean’ OS Upgrade – Small Company
Shall we upgrade the OS?
Yes, ok.
Oh, I’ve hit a problem. One of the falanges have stopped working.
OK, do some work to fix the transpondster.
Might take me a few hours
OK
… OK, done. Can you test?
Yup, looks good.
Great.
‘Lean’ OS Upgrade – Enterprise
Shall we upgrade the OS?
Yes.
OK, done.
Um, you brought down the payments system.
Whoops. I’ll roll back
OK.
Done. We’ll look into it.
Hi. The regulator called. They saw something on the news about payments being down. They want to know what happened.
Um, OK. I’ll write something up.
Thanks.
…
They read your write-up and have asked for evidence of who decided what when. They want a timeline.
I’ll check the emails.
By the way, you’re going to be audited in a couple of months. We’ll have to cancel all projects until then?
But we’ve got so much technical debt!
If we don’t get this right, they’ll shut us down and we’ll be fired.
…
OK, we have the results of the audit.
Audit has uncovered 59 other problems you need to solve.
OK…
We’ll have to drop other projects, and maybe lose some people.
Um, OK…
Oh, and my boss is being hauled in front of the regulator to justify what happened. If it doesn’t go well he’s out of a job and his boss might go to prison if they think something fishy is going on.
Now that’s a bad release… That’s a worst-case scenario, but let’s unpick what these regulated enterprises do to mitigate both the risk and the consequences of the above scenario. Specifically:
‘Who owns this?’
‘How is this maintained?’
‘Who buys it?’
‘Who’s signed off the deployment?’
2) Reducing Risk
‘Who Owns This?’ / ‘One Throat to Choke’
This is a big one. One of the most commonly-asked questions when architecting a solution within an enterprise is: ‘Who is responsible for that component/service/system?‘ In our enterprise ‘Lean OS Upgrade’ scenario above one of the first questions that will be asked is: ‘Who owns the operating system?’ That group will be identifiable through some internal system which tracks ownership of tools and technologies. Those identified as responsible will be responsible for some or all of the lifecycle management for that technology. This might include:
Upgrade management
Support (directly or via a vendor)
Security patching
Deciding who can and can’t use it
Overall policy on usage (expand/deprecate/continue usage)
This ownership results in ‘one throat to choke’ for audit functions. Much like the police will go after the drug dealer rather than the casual user, the audit functions of an enterprise will go after the formally responsible person or team than the (potentially thousands of) teams using an outdated version of a particular technology. There’s richer pickings there. From ownership comes responsibility. A lot of the political footwork in an enterprise revolves around trying to not own technologies. Who wants to be responsible for Java usage across a technology function of dozens of thousands of staff, any of whom might be doing crazy stuff? You first, mate.
Enterprises and Vendors
This also explains enterprises’ love of vendor software over pure open source. If you’ve paid someone to maintain and support a technical stack, then they become responsible for that whole stack. That doesn’t solve all your problems (you still will need to integrate their software with your IT infrastructure, and things get fuzzier the closer you look at the resulting solution), but from a governance point of view you’ve successfully passed the buck.
What is governance? IT Governance is a term that covers all the processes and structures that ensures the IT is appropriately managed in a way that satisfies those that govern the organisation. Being ‘out of governance’ (ie not conforming to standards) is considered a dangerous place to be, because you may be forced to spend money to get back ‘in’ to governance.
‘How is this maintained?’
Another aspect of managing software in an enterprise context is its maintenance. In our idealised startup above ‘Dev’ and ‘Ops’ were the same thing (ie, one person). Lo and behold you have DevOps! Unfortunately, the DevOps slogan ‘you built it, you run it’ doesn’t usually work in an Enterprise context for a few reasons. Partly it’s historical ie ‘it’s the way things have been done’ for decades, so there is a strong institutional bias towards not changing this. Jobs and heavily-invested-in processes depend on its persistence. But further bolstering this conservatism is the regulatory framework that governs how software is managed.
Regulations
Regulations are rules created by regulators, who in turn are groups of people with power ultimately derived from government or other controlling authorities. So, effectively, they have the force of law as far as your business is concerned. Regulators are not inclined to embrace fashionable new software deployment methods, and their paradigms are rooted in the experiences of software built in previous decades. What does this mean? If your software is regulated, then it’s likely that your engineering (dev) and operations teams (ops) will be separate groups of people specialising in those roles, and one of the drivers of this is the regulations, which demand a separation to ensure that changes are under some kind of control and oversight. Now, there is (arguably) a loophole here that some have exploited: regulations often talk about ‘separation of roles’ between engineering and operations, and don’t explicitly say that these roles need to be fulfilled by different people. But if you’re a really big enterprise, that might be technically correct but effectively irrelevant. Why? Because, to ‘simplify’ things, these large enterprise often create a set of rules that cover all the regulations that may ever apply to their business across all jurisdictions. And those rules are generally the strictest you can imagine. Added to that, those rules develop a life and culture of their own within the organisation independent of the regulator such that they can’t easily be brought into question.
Resistance is futile. Dev and Ops must be separate because that’s what we wrote down years ago.
So you can end up in a situation where you are forced to work in a way prescribed years ago by your internal regulations, which are in turn based on interpretations of regulations which were written years before that! And if you want to change that, it will itself likely take years and agreement from multiple parties who are unlikely to want to risk losing their job so you can deliver your app slightly faster. Obviously, this separation slows things down as engineering must make the code more tolerant to mistakes and failure so that another team can pick it up and carry it through to production. Or you just throw it over the wall and hope for the best. Either way, parties become more resistant to change.
Change Control
That’s not the only way in which the speed of change is reduced in an enterprise. In order to ensure that changes to systems can be attributed to responsible individuals, there is usually some kind of system that tracks and audits changes. One person will raise a ‘change record’, which will usually involve filling out an enormous form, and then this change must be ‘signed off’ by one or more other person to ensure that changes don’t happen without due oversight. In theory, the person signing off must carefully examine the change to ensure it is sensible and valid. In reality, most of the time trust relationships build up between change raiser and change validator which can speed things up. If the change is large and significant, then it is more likely to be closely scrutinised. There might also exist ‘standard changes’ or ‘templated changes’, which codify more routine and lower-risk updates and are pre-authorised. These must also be signed off before being deployed (usually at a higher level of responsibility, making it harder to achieve). While in theory the change can be signed off in minutes, in reality change requests can take months as obscure fields in forms are filled out wrongly (‘you put the wrong code in field 44B! Start again.’), sign-off deadlines expire, change freezes come and go, and so on. All this makes the effort of making changes far more onerous than it is elsewhere.
Security ‘Sign-Off’
If you’re working on something significant, such as a new product, or major release of a large-scale product, then it may become necessary to get what most people informally call ‘security sign-off’. Processes around this vary from place to place, but essentially, one or more security experts descend at some point on your project and audit it. I had imagined such reviews to be a very scientific process, but in reality it’s more like a medieval trial by ordeal. You get poked and prodded in various ways while questions are asked to determine weaknesses in your story. This might involve a penetration test, a look at your code and documentation, or an interview with the engineers. There will likely be references to various ‘security standards’ you may or may not have read, which in turn are enforced with differing degrees of severity. The outcome of this is usually some kind of report and a set of risks that have been identified. These risks (depending on their severity – I’ve never heard of there being none) may need to be ‘signed off’ by someone senior so that responsibility lies with them if there is a breach. That process in itself is arduous (especially when the senior doesn’t fully understand the risk) and can be repeated on a regular basis until it is sufficiently ‘mitigated’ through further engineering effort or process controls. After which it’s then re-reviewed. None of this is quick.
Summary: Corporate, not Individual Responsibility
If there’s a common thread to these factors in reducing risk, it is to shift responsibility and power from the individual to the corporate entity. If you’re a regulated, systemically-significant enterprise, then the last thing you or the public wants is for one person to wield too much power, either through knowledge of a system, or ability to alter that system in their own interests. The corollary of this is that it is very hard for one person to make change by themselves. And, as we all know, if a task is given to multiple people to achieve together, then things get complicated and change slows up pretty fast as everyone must keep each other informed as to what everyone else is doing. Once this principle of corporate responsibility is understood, then many other processes start to make sense. An example of one of these is sourcing (aka procurement: the process of buying software or other IT services).
Example – Sourcing
Working for such an enterprise, and before I stopped answering, I would get phoned up by salespeople all the time who seemed to imagine that I had a chequebook ready to sign for any technology I happened to like. The reality could not have been further from the truth. What many people don’t expect is that to prevent a situation where one person could get too much power it can be the case that technical people have no direct control over the negotiation (or ‘sourcing process’) at all. What often happens is something close to this:
You go to senior person to get sign-off for a budget for purpose X
They agree
You document at least two options for products that fulfil that purpose
The ‘sourcing team’ take that document and negotiate with the suppliers
Some magic happens
You get told which supplier ‘won’
You can see why this process helps reduce the risk that someone takes a bribe to push a particular vendor solution (there’s also often strict rules around accepting so much as a coffee from a potential supplier), which is a good thing. On the other hand, this process can take months or even years. And might need to be repeated if the process takes so long that funding has disappeared or teams have been disbanded. To complicate matters further, sourcing might have its own ‘preferred supplier lists‘ of companies that have been vetted and audited in the past. If your preferred supplier isn’t on that list (and hasn’t made a deal with one on those list), the process could take even longer.
3) Cumulative Constraints
What we have learned so far is that enterprises are fundamentally slowed down by attempts to reduce the power and individual responsibility in favour of corporate responsibility. This usually results in:
More onerous change control
Higher bars for change planning
Higher bars for buying solutions
Higher bars for security requirements
Separation of engineering and ops functions
all of which slow down delivery. It’s like entropy. You can fight it, but in the end physics wins. Now we’ll take a step outside these individual constraints to look at what happens when you structure a large scale enterprise organisation where its component groups are all fighting these same challenges.
Dependency Constraints
When you try and deliver in an enterprise you will find that your team has dependencies on other teams to provide you IT services. The classic example of this is firewall changes. You, as a developer decide – in classic agile microservices/’all the shiny’ fashion – to create a new service running on a particular port on a set of hosts. You gulp Coke Zero all night and daub the code together to get a working prototype. To allow connectivity, you need to open up some ports on the firewall. You raise a change, and discover the process involves updating a spreadsheet by hand and then raising a change request which requires at least a week’s notice. Your one night’s development is now going to elapse a week before you can try it out. And that’s hoping you filled everything out correctly and didn’t miss anything. If you did, then you have to go round again… One of the joyous things about working in an unregulated startup is that if you see a problem in one of your dependencies you have the option of taking it over and running it yourself. Don’t like your cloud provider? Switch. Think your app might work better in erlang? Rewrite. Fed up with the firewall process? Write a script to do that, and move to gitops. So why not do the same in the enterprise? Why not just ‘find your dependencies and eliminate them‘? Some do indeed take this approach, and it costs them dearly. Either they have to spend great sums of money managing the processes required to maintain and stay ‘within governance’ for the technology they’ve decided to own, or they get hit with an audit sooner or later and get found out. At that point, they might go cap in hand to the infrastructure team, whose sympathy to their plight is in proportion to the amount of funding infrastructure is being offered to solve the problems for them… The reality is that – as I said above – taking responsibility and owning a technology or layer of your stack brings with it real costs and risks that you may not be able to bear and stay in business. So however great you are as a team, you’re delivery cadence is constrained to a local maxima based on your external dependencies, which are (effectively) non-negotiable. This is a scaling up of the same constraints on individuals in favour of corporate power and responsibility. Just as it is significantly harder for you to make that much difference, it is harder for your team to make much difference, for the same structural reasons.
If you like this, you might like one of my books: Learn Git the Hard Way, Learn Terraform the Hard Way,  Learn Bash the Hard Way 
Cultural Constraints
Now that the ingredients for slow delivery are already there in a static, structural sense, let’s look at what happens when you ‘bake’ that structure over decades into the organisation and then try to make change within it.
Calcified Paradigms
Since reasoning about technology on a corporate scale is hard, creating change within it can only work at all if there are collective paradigms around which processes and functions can reason. These paradigms become ingrained, and surfacing and reshaping these conceptual frameworks can be an effort that must repeated over and over across an organisation if you are to successfully make change. The two big examples of this I’ve been aware of are the ‘machine paradigm’ and charging models, but one might add ‘secrets are used manually’ or many others that may also be bubbling under my conscious awareness.
The ‘machine paradigm’
Since von Neumann outlined the architecture of the computer, the view of the fundamental unit of computation as being a single discrete physical entity has held sway. Yes, you can share workloads on a single machine (mainframes still exist, for example, and two applications might use the same physical device), but for the broad mass of applications, the idea of needing a separate physical machine to run on (for performance or security reasons) has underpinned assumptions of applications’ design, build, test, and deploy phases. Recently (mostly in the last 10 years), this paradigm has been modified by virtual machines, multiples of which sit on one larger machine that runs a hypervisor. Ironically, this has reinforced the ‘machine paradigm’, since for backward compatibility each VM has all the trappings of a physical machine, such as network interfaces, mac addresses, numbers of CPUs and so on. Whether you fill out a form and wait for a physical machine or a virtual machine to be provisioned makes little difference – you’re still in the machine paradigm. Recently, aPaaSes, Kubernetes, and cloud computing have overthrown the idea that an application need sit on a ‘machine’, but the penetration of this novel (or old, if you used mainframes) idea, like the future, is unevenly distributed.
Charging models
Another paradigm that’s very hard to get traction on changing is charging models. How money moves around within an enterprise is a huge subject in itself, and has all sorts of secondary effects that are of no small interest to IT. To grossly generalise, IT is moving from a ‘capex’ model to an ‘opex’ model. Instead of buying kit and software and then running it until it wears out (capex), the ‘new’ model is to rent software and services which can be easily scaled up and down as business demand requires. Now, if you think IT in an enterprise is conservative, then prepare to deal with those that manage and handle the money! For good reason, they are as a rule very disinclined to change payment models within an organisation, since any change in process will result in bugs (old and new) being surfaced, institutional upheaval, and who knows what else. The end result is that moving to these new models can be painful. Trying to cross-charge within an organisation of any size can result in surreal conversations about ‘wooden dollars’ (ie non-existent money exchanged in lieu of real money) or services being charged out to other parts of the business, but never paid for due to conversations that may or may not have been had outside your control.
Learned Helplessness
After decades of these habits of thoughts, you end up with several consequences:
Those who don’t like the way of working leave
Those that remain calcify into whole generations of employees
Those that remain tend to prize and prefer those that agree with their views
Suggestions of change to these groups of people result in entire generations, nay armies of employees that resist change. The irony is that they are completely right. Most efforts to change do fail, and therefore most efforts to do so are wasted. The reasons are arguably circular, ie that change is resisted because it won’t work, and it won’t work because it’s resisted. But it’s also quite rational, since the reasons it won’t work are based on the external constraints that exist we have discussed above. But it’s simple game theory to follow the logic. This has previously been described as the ‘square of despair‘:  Although I’d prefer to call it the ‘polygon of despair‘, since these four are fairly arbitrary. You could add to this list, for example:
Internal charging models
Change control
Institutional inertia
Audit
Regulation
Outdated paradigms
all of which have been discussed above.

The Decagon of Despair

4) A New Hope?
Is it all a lost cause? Is there really no hope for change? Does it always end up looking like this, at best a mass of compromises that feel like failure?  Well, no. But it is bloody hard. Here’s the things I think will stack the deck in your favour:
Senior Leadership Support
I think this is the big one. If you’re looking to swim against habits of thought, then stiff resolve is required. If senior management aren’t willing to sacrifice, aren’t united in favour of it, then all sorts of primary decisions and (equally important) second-guessed decisions made by underlings from different branches of the management tree that have conflicting aims. People don’t like to talk about it, but it helps if people get fired for not constructively working with the changes. That tends to focus the mind. The classic precedent of this is point 6 of Jeff Bezos’s ‘API Mandate’:  You senior leadership will also need buckets of patience as the work to do this is very front-loaded, the pain being felt far earlier benefits being felt far later than the pain.
Reduce Complexity
Talking of pain, you will do yourself favours if you fight tooth and nail to reduce complexity. This may involve taking some risks as you call out that the entire effort may be ruined by compromises that defeat the purpose, or create bureaucratic or technical quicksand that your project will flounder in later. Calling those dangers may get you a reputation, or even cost you your job. As the title of A Seat at the Table (a book I highly recommend on the subject) implies, it’s very close to a poker game.
Cross-functional Team
It might sound obvious to those that work in smaller companies, but it’s much easier to achieve change if you have a team of people that span the functions of your organisation working together. The collaboration not only benefits from seeing how things need be designed to fulfil requirements at an earlier stage, but more creative solutions are found by people who understand their function’s needs better, and the requirements of the project. If you want to go the skunkworks route, then the representatives of the other functions can tell you where your MVP shortcuts are going to bite you later on. The alternative – and this is almost invariably much, much slower – is to ‘build, then check’. So you might spent several months building your solution before you find it’s fundamentally flawed based on some corporate rule or principle that can’t be questioned.
Use Your Cynical Old Hands
The flip side of those that constitute the ‘institutional inertia’ I described above is that many of those people know the organisation inside out. These people often lose heart regarding change not because they no longer care, but because they believe that when push comes to shove the changes won’t get support. These people can be your biggest asset. The key is to persuade them that it’s possible, and that you need their help. That can be hard for both sides, as your enthusiasm for change hits their brick wall, cemented by their hard-won (or lost) experience. They may give you messages that are hard to hear about how hard it will be. But don’t underestimate the loyalty and resilience you get if they are heard.
If you liked this post, you might also like:
Five Things I Did to Change a Team’s Culture
My 20-Year Experience of Software Development Methodologies
Things I Learned Managing Site Reliability for Some of the World’s Busiest Gambling Sites
A Checklist for Docker in the Enterprise (Updated)
Or one of my books: Learn Git the Hard Way Learn Terraform the Hard Way Learn Bash the Hard Way 
If you enjoyed this, then please consider buying me a coffee to encourage me to do more.
Share this:
Email
Share
Related

If You Want To Transform IT, Start With Finance
July 12, 2021
With 4 comments

My 20-Year Experience of Software Development Methodologies
October 15, 2017
With 64 comments

'AWS vs K8s' is the new 'Windows vs Linux'
March 25, 2019
With 28 comments

Published by zwischenzugs

View all posts by zwischenzugs

Published
October 2, 2018
Post navigation
Previous Post
 Anatomy of a Linux DNS Lookup – Part V – Two Debug Nightmares
Next Post
Learn Bash Debugging Techniques the Hard Way
31 thoughts on “Why Are Enterprises So Slow?”
unixbhaskar
October 2, 2018 at 12:21 pm

Good one Ian! Encountered those many times :(

Reply
Pingback: Dew Drop - October 2, 2018 (#2815) - Live from TechBash - Morning Dew
Pingback: New top story on Hacker News: Why Are Enterprises So Slow? – Golden News
Pingback: New top story on Hacker News: Why Are Enterprises So Slow? – News about world
Pingback: New top story on Hacker News: Why Are Enterprises So Slow? – Hckr News
Pingback: New top story on Hacker News: Why Are Enterprises So Slow? – World Best News
Pingback: New top story on Hacker News: Why Are Enterprises So Slow? - EYFnews
Pingback: New top story on Hacker News: Why Are Enterprises So Slow? – Latest news
z
October 3, 2018 at 1:13 pm

i worked in a big fin enterprise for a while and i find these points extremely valid :). One is powerless without full support from senior leadership to bring abouy organizational behavioural changes :(

Reply
Pingback: Bookmarks for October 2nd through October 3rd : Extenuating Circumstances
Pingback: Interesting Links for 04-10-2018 | Made from Truth and Lies
Graham
October 4, 2018 at 11:56 am

Great article Ian. It sadly explains why so many good people leave large organisations, and why shit enterprise software doesn’t improve.

“Lean Control” frameworks are perhaps a way to address the above issues. That in turn requires lots of support from senior management in lots of areas.

Reply
zwischenzugs
October 4, 2018 at 12:04 pm

Hey Graham, it was almost written for IB ;-) Yes, Lean Control was the best hope I saw, and it was streets ahead of the more transactional methods in terms of speed of delivery. Let me know if you’re up for a lunch/coffee soon.

Reply
Pingback: Food for Agile Thought #162: Organizational Agility, Enterprise Slowness, Product Strategy, State of DevOps Report 2018 – Matteo Borghesi
Pingback: Link Propagation 138: A Network Troubleshooting Guide
Pingback: Booby trapped! - Devs: learn how to go from coder to consultant
Pingback: Why Corporate Apps Fail – Ian Dick
Pingback: Björn Wilmsmann – Nonsense We Put up With: Complexity, Agile Gone Wrong and Enterprise Decision Making
Pingback: Styles of Software Infrastructure Management | Undrinkable Kool-Aid
Pingback: Styles Of Software Infrastructure Management – aster.cloud
Pingback: Questi non sono i contenitori che stai cercando – Italia
Pingback: Ang mga Hindi Ito Ang Mga Container na Hinahanap Mo – Ang Pilipinas
Pingback: Dies sind nicht die Container, nach denen Sie suchen – Deutschland
Pingback: ‘AWS vs K8s’ is the new ‘Windows vs Linux’ – zwischenzugs
Pingback: ‘AWS vs K8s’ is the new ‘Windows vs Linux’ - Entertaining WE
Pingback: 开发者可能低估了容器部署的复杂性 - DLCoder | DLCoder
Pingback: Why Everyone Working in DevOps Should Read The Toyota Way – zwischenzugs
Pingback: The Runbooks Project – zwischenzugs
Pingback: Why Are Enterprises So Slow? – John DeHope
Pingback: The Runbooks Project – WordPress Ecosystem News
Pingback: GitOps Decisions – WordPress Ecosystem News
Leave a Reply

This site uses Akismet to reduce spam. Learn how your comment data is processed.

Follow me on Twitter
Top Posts & Pages
If You Want To Transform IT, Start With Finance
'AWS vs K8s' is the new 'Windows vs Linux'
Why Are Enterprises So Slow?
Five Things I Did to Change a Team's Culture
How (and Why) I Run My Own DNS Servers
Bash to Python Converter
Ten Things I Wish I'd Known Before Using Jenkins Pipelines
How To Waste Hundreds of Millions on Your IT Transformation
Anatomy of a Linux DNS Lookup - Part I
Things I Learned Managing Site Reliability for Some of the World's Busiest Gambling Sites
Recent Posts
If You Want To Transform IT, Start With Finance
How To Waste Hundreds of Millions on Your IT Transformation
When Should I Interrupt Someone?
An Incompetent Newbie Takes Up 3D Printing
GitOps Decisions
Five Ways to Undo a Commit in Git
The Halving of the Centre: Covid and its Effect on London Property
Why Do We Have Dev Rels Now?
The Runbooks Project
Some Relatively Obscure Bash Tips
Riding the Tiger: Lessons Learned Implementing Istio
The Astonishing Prescience of Nam June Paik
Notes on Books Read in 2019
The First Non-Bullshit Book About Culture I’ve Read
Why Everyone Working in DevOps Should Read The Toyota Way
Surgically Busting the Docker Cache
Software Security Field Guide for the Bewildered
The Lazy Person’s Guide to the Info Command
A Hot Take on GitHub Actions
Seven God-Like Bash History Shortcuts You Will Actually Use
How Long Will It Take For The Leavers To Leave?
Goodbye Docker: Purging is Such Sweet Sorrow
Seven Surprising Bash Variables
The Missing Readline Primer
Apple’s HQ, Ruskin, Gothic Architecture, and Agile
Eight Obscure Bash Options You Might Want to Know About
‘AWS vs K8s’ is the new ‘Windows vs Linux’
Pranking the Bash Binary
Bash Startup Explained
Git Hooks the Hard Way
Notes on Books Read in 2018
Six Ways to Level Up Your nmap Game
Five Things I Wish I’d Known About Git
Eleven bash Tips You Might Want to Know
Learn Bash Debugging Techniques the Hard Way
Why Are Enterprises So Slow?
Anatomy of a Linux DNS Lookup – Part V – Two Debug Nightmares
Anatomy of a Linux DNS Lookup – Part IV
Anatomy of a Linux DNS Lookup – Part III
Anatomy of a Linux DNS Lookup – Part II
Anatomy of a Linux DNS Lookup – Part I
A Docker Image in Less Than 1000 Bytes
Autotrace – Debug on Steroids
Beyond ‘Punk Rock Git’ in Eleven Steps
Sandboxing Docker with Google’s gVisor
Unprivileged Docker Builds – A Proof of Concept
Learn Git Rebase Interactively
Terminal Perf Graphs in one Command
git log – the Good Parts
Five Key Git Concepts Explained the Hard Way
Create Your Own Git Diagrams
Five Things I Did to Change a Team’s Culture
Centralise Your Bash History
How (and Why) I Run My Own DNS Servers
Ten More Things I Wish I'd Known About bash
Download a Free Sample of Learn Bash the Hard Way
Ten Things I Wish I’d Known About bash
Project Management as Code with Graphviz
How to Manually Clear Locks in Jenkins
How I Manage My Time
Ten Things I Wish I’d Known About Chef
Vagrant and Ohai / Chef IP Address Hack
‘Towards a National Computer Grid’ – Electronic Computers, 1965
A Complete Chef Infrastructure on Your Laptop
Ten Things I Wish I’d Known Before Using Vagrant
A Checklist for Docker in the Enterprise (Updated)
OpenShift 3.6 DNS In Pictures
Puppeteer – Headless Chrome in a Container
My 20-Year Experience of Software Development Methodologies
A Non-Cloud Serverless Application Pattern Using Git and Docker
Run Your Own AWS APIs on OpenShift
Dockerized Headless Chrome Example
Convert a Server to a Docker Container (Update II)
Automating Dockerized Jenkins Upgrades
Ten Things I Wish I’d Known Before Using Jenkins Pipelines
Five Books I Advise Every DevOps Engineer to Read
Things I Learned Managing Site Reliability for Some of the World’s Busiest Gambling Sites
Clustered VM Testing How-To
Easy Shell Automation
1-Minute Multi-Node VM Setup
Migrating an OpenShift etcd Cluster
A Complete OpenShift Cluster on Vagrant, Step by Step
Learn Kubernetes the Hard Way (the Easy and Cheap Way)
Docker in the Enterprise
Terraform and Dynamic Environments
Bash to Python Converter
Hello world Unikernel Walkthrough
A checklist for Docker in the Enterprise
A Quick Tour of Docker 1.12
Power ‘git log’ graphing
ssh -R (reverse tunnel) man page hell
Writing a Technical Book
Interactive Git Tutorials – Rebase and Bisect
Hitler Uses Docker, Annotated
Linux Scales
Play With Kubernetes Quickly Using Docker (Updated)
Convert Any Server to a Docker Container (Updated)
CI as Code Part III: Dynamic Jenkins-Swarm Example
Docker 1.10 Highlights – Updated
CI as Code Part II: Stateless Jenkins With Dynamic Docker Slaves
CI as Code Part I: Stateless Jenkins Deployments Using Docker
Docker Ecosystem Rosetta Stones
Understanding Docker – A Tour of Logical Volume Management
Automating Docker Security Validation
The IT Crowd Was Right – What I learned by reading a lot of RFCs
Understanding Docker – Network Namespaces
DockerConEU 2015 Talk – You Know More Than You Think
Docker Migration In-Flight CRIU
A High Availability Phoenix and A/B Deployment Framework using Docker
Quick Intro to Kubernetes
Take OpenShift for a spin in four commands
RedHat's Docker Build Method – S2I
RedHat’s Docker Build Method – S2I
Bash Shortcuts Gem
A CoreOS Cluster in Two Minutes With Four Commands
The Most Pointless Docker Command Ever
My Favourite Docker Tip
Convert Any Server to a Docker Container
A Field Guide to Docker Security Measures
Docker SELinux Experimentation with Reduced Pain
Storage Drivers and Docker
Play With Kubernetes Quickly Using Docker
Play with an OpenShift PaaS using Docker
Scale Your Jenkins Compute With Your Dev Team: Use Docker and Jenkins Swarm
Docker in Practice – A Guide for Engineers
Fight Docker Package Drift!
Win at 2048 with Docker and ShutIt (Redux)
Set Up a Deis (Docker-Friendly) Paas on Digital Ocean for $0.18 Per Hour in Six Easy Steps Using ShutIt
Create your own CoreOS cluster in 6 easy steps for $0.03
Make Your Own Bespoke Docker Image
Taming Slaves with Docker and ShutIt
Docker – One Year On
Using ShutIt to Build Your Own Taiga Server
Using ShutIt and Docker to play with AWS (Part Two)
Talk on Docker and ShutIt
Using ShutIt and Docker to play with AWS (Part One)
Phoenix deployment pain (and win)
Phoenix Deployment with Docker and ShutIt
Docker, ShutIt and the Perfect 2048 Game (Videos)
Docker, ShutIt and the Perfect 2048 Game (4 – Halfway There)
Docker, ShutIt and the Perfect 2048 Game (3 – Brute Force Escapes)
Docker, ShutIt and the Perfect 2048 Game (2)
Docker, ShutIt, and The Perfect 2048 Game
My Favourite Secret Weapon – strace
Shakespeare’s Vocabulary Considered Unexceptional
Website Built with WordPress.com.
Follow]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Jackson Palmer on Twitter: "I am often asked if I will “return to cryptocurrency” or begin regularly sharing my thoughts on the topic again. My answer is a wholehearted “no”, but to avoid repeating myself I figure it might be worthwhile briefly explaining why here…" / Twitter]]></title>
            <link>https://twitter.com/ummjackson/status/1415353984617914370</link>
            <guid>https://twitter.com/ummjackson/status/1415353984617914370</guid>
            <pubDate>Wed, 14 Jul 2021 19:57:27 GMT</pubDate>
            <content:encoded><![CDATA[Don’t miss what’s happening
People on Twitter are the first to know.
Log in
Sign up
Thread
See new Tweets
Conversation
Jackson Palmer
@ummjackson
I am often asked if I will “return to cryptocurrency” or begin regularly sharing my thoughts on the topic again. My answer is a wholehearted “no”, but to avoid repeating myself I figure it might be worthwhile briefly explaining why here…
12:54 PM · Jul 14, 2021·Twitter Web App
863
 Retweets
389
 Quote Tweets
3,346
 Likes
Who can reply?
People @ummjackson mentioned can reply.
Jackson Palmer
@ummjackson
·
3h
Replying to 
@ummjackson
After years of studying it, I believe that cryptocurrency is an inherently right-wing, hyper-capitalistic technology built primarily to amplify the wealth of its proponents through a combination of tax avoidance, diminished regulatory oversight and artificially enforced scarcity.
1
1.7K
4.8K
Jackson Palmer
@ummjackson
·
3h
Despite claims of “decentralization”, the cryptocurrency industry is controlled by a powerful cartel of wealthy figures who, with time, have evolved to incorporate many of the same institutions tied to the existing centralized financial system they supposedly set out to replace.
1
341
2K
Jackson Palmer
@ummjackson
·
3h
The cryptocurrency industry leverages a network of shady business connections, bought influencers and pay-for-play media outlets to perpetuate a cult-like “get rich quick” funnel designed to extract new money from the financially desperate and naive.
1
243
1.6K
Jackson Palmer
@ummjackson
·
3h
Financial exploitation undoubtedly existed before cryptocurrency, but cryptocurrency is almost purpose built to make the funnel of profiteering more efficient for those at the top and less safeguarded for the vulnerable.
1
130
1.3K
Jackson Palmer
@ummjackson
·
3h
Cryptocurrency is like taking the worst parts of today's capitalist system (eg. corruption, fraud, inequality) and using software to technically limit the use of interventions (eg. audits, regulation, taxation) which serve as protections or safety nets for the average person.
1
376
1.7K
Jackson Palmer
@ummjackson
·
3h
Lose your savings account password? Your fault.
Fall victim to a scam? Your fault.
Billionaires manipulating markets? They’re geniuses.

This is the type of dangerous “free for all” capitalism cryptocurrency was unfortunately architected to facilitate since its inception.
1
212
1.6K
Jackson Palmer
@ummjackson
·
3h
But these days even the most modest critique of cryptocurrency will draw smears from the powerful figures in control of the industry and the ire of retail investors who they’ve sold the false promise of one day being a fellow billionaire. Good-faith debate is near impossible.
1
111
1.2K
Jackson Palmer
@ummjackson
·
3h
For these reasons, I simply no longer go out of my way to engage in public discussion regarding cryptocurrency. It doesn't align with my politics or belief system, and I don't have the energy to try and discuss that with those unwilling to engage in a grounded conversation.
1
76
1.2K
Jackson Palmer
@ummjackson
·
3h
I applaud those with the energy to continue asking the hard questions and applying the lens of rigorous skepticism all technology should be subject to. New technology can make the world a better place, but not when decoupled from its inherent politics or societal consequences.
145
1.5K]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Adaptive immunity induces mutualism between commensal eukaryotes | Nature]]></title>
            <link>https://www.nature.com/articles/s41586-021-03722-w</link>
            <guid>https://www.nature.com/articles/s41586-021-03722-w</guid>
            <pubDate>Wed, 14 Jul 2021 19:57:25 GMT</pubDate>
            <content:encoded><![CDATA[Skip to main content

Advertisement

View all journals
Search
Login
Explore content
Journal information
Publish with us
nature  articles  article
Article
Published: 14 July 2021
Adaptive immunity induces mutualism between commensal eukaryotes
Kyla S. Ost, Teresa R. O’Meara, W. Zac Stephens, Tyson Chiaro, Haoyang Zhou, Jourdan Penman, Rickesha Bell, Jason R. Catanzaro, Deguang Song, Shakti Singh, Daniel H. Call, Elizabeth Hwang-Wong, Kimberly E. Hanson, John F. Valentine, Kenneth A. Christensen, Ryan M. O’Connell, Brendan Cormack, Ashraf S. Ibrahim, Noah W. Palm, Suzanne M. Noble & June L. Round 

Nature (2021)Cite this article

41 Altmetric

Metrics
details

Abstract

Pathogenic fungi reside in the intestinal microbiota but rarely cause disease. Little is known about the interactions between fungi and the immune system that promote commensalism. Here we investigate the role of adaptive immunity in promoting mutual interactions between fungi and host. We find that potentially pathogenic Candida species induce and are targeted by intestinal immunoglobulin A (IgA) responses. Focused studies on Candida albicans reveal that the pathogenic hyphal morphotype, which is specialized for adhesion and invasion, is preferentially targeted and suppressed by intestinal IgA responses. IgA from mice and humans directly targets hyphal-enriched cell-surface adhesins. Although typically required for pathogenesis, C. albicans hyphae are less fit for gut colonization1,2 and we show that immune selection against hyphae improves the competitive fitness of C. albicans. C. albicans exacerbates intestinal colitis3 and we demonstrate that hyphae and an IgA-targeted adhesin exacerbate intestinal damage. Finally, using a clinically relevant vaccine to induce an adhesin-specific immune response protects mice from C. albicans-associated damage during colitis. Together, our findings show that adaptive immunity suppresses harmful fungal effectors, with benefits to both C. albicans and its host. Thus, IgA uniquely uncouples colonization from pathogenesis in commensal fungi to promote homeostasis.

Access options

Subscribe to Journal

Get full journal access for 1 year

$199.00

only $3.90 per issue

Subscribe

All prices are NET prices.
VAT will be added later in the checkout.
Tax calculation will be finalised during checkout.

Rent or Buy article

Get time limited or full article access on ReadCube.

from$8.99

Rent or Buy

All prices are NET prices.

Additional access options:
Log in
Access through your institution
Learn about institutional subscriptions
Data availability

Raw C. albicans RNA-seq reads have been deposited at the NCBI Sequence Read Archive under the BioProject accession number PRJNA728116. All other data needed to evaluate the conclusions in the paper are available within the Article or its Supplementary Information. Source data are provided with this paper.

Code availability

All code used for processing and mapping RNA-seq reads is available at https://github.com/RoundLab/Ost_CandidaRNASeq.

References
1.

Witchley, J. N. et al. Candida albicans morphogenesis programs control the balance between gut commensalism and invasive infection. Cell Host Microbe 25, 432–443 (2019).

CAS
 
Article
 
Google Scholar
 

2.

Tso, G. H. W. et al. Experimental evolution of a fungal pathogen into a gut symbiont. Science 362, 589–595 (2018).

ADS
 
CAS
 
Article
 
Google Scholar
 

3.

Leonardi, I. et al. CX3CR1+ mononuclear phagocytes control immunity to intestinal fungi. Science 359, 232–236 (2018).

ADS
 
CAS
 
Article
 
Google Scholar
 

4.

Zhai, B. et al. High-resolution mycobiota analysis reveals dynamic intestinal translocation preceding invasive candidiasis. Nat. Med. 26, 59–64 (2020).

CAS
 
Article
 
Google Scholar
 

5.

Jain, U. et al. Debaryomyces is enriched in Crohn’s disease intestinal tissue and impairs healing in mice. Science 371, 1154–1159 (2021).

ADS
 
CAS
 
Article
 
Google Scholar
 

6.

Li, X. V., Leonardi, I. & Iliev, I. D. Gut mycobiota in immunity and inflammatory disease. Immunity 50, 1365–1379 (2019).

CAS
 
Article
 
Google Scholar
 

7.

Weis, A. M. & Round, J. L. Microbiota–antibody interactions that regulate gut homeostasis. Cell Host Microbe 29, 334–346 (2021).

CAS
 
Article
 
Google Scholar
 

8.

Huertas, B. et al. Serum antibody profile during colonization of the mouse gut by Candida albicans: relevance for protection during systemic infection. J. Proteome Res. 16, 335–345 (2017).

CAS
 
Article
 
Google Scholar
 

9.

Doron, I. et al. Human gut mycobiota tune immunity via CARD9-dependent induction of anti-fungal IgG antibodies. Cell 184, 1017–1031 (2021).

CAS
 
Article
 
Google Scholar
 

10.

Bai, X.-D., Liu, X.-H. & Tong, Q.-Y. Intestinal colonization with Candida albicans and mucosal immunity. World J. Gastroenterol. 10, 2124–2126 (2004).

Article
 
Google Scholar
 

11.

Millet, N., Solis, N. V. & Swidergall, M. Mucosal IgA prevents commensal Candida albicans dysbiosis in the oral cavity. Front. Immunol. 11, 555363 (2020).

CAS
 
Article
 
Google Scholar
 

12.

Standaert-Vitse, A. et al. Candida albicans is an immunogen for anti-Saccharomyces cerevisiae antibody markers of Crohn’s disease. Gastroenterology 130, 1764–1775 (2006).

CAS
 
Article
 
Google Scholar
 

13.

Strope, P. K. et al. The 100-genomes strains, an S. cerevisiae resource that illuminates its natural phenotypic and genotypic variation and emergence as an opportunistic pathogen. Genome Res. 25, 762–774 (2015).

CAS
 
Article
 
Google Scholar
 

14.

Richardson, J. P., Ho, J. & Naglik, J. R. Candida–epithelial interactions. J. Fungi 4, 22 (2018).

Article
 
Google Scholar
 

15.

Noble, S. M., Gianetti, B. A. & Witchley, J. N. Candida albicans cell-type switching and functional plasticity in the mammalian host. Nat. Rev. Microbiol. 15, 96–108 (2017).

CAS
 
Article
 
Google Scholar
 

16.

Noble, S. M., French, S., Kohn, L. A., Chen, V. & Johnson, A. D. Systematic screens of a Candida albicans homozygous deletion library decouple morphogenetic switching and pathogenicity. Nat. Genet. 42, 590–598 (2010).

CAS
 
Article
 
Google Scholar
 

17.

Homann, O. R., Dea, J., Noble, S. M. & Johnson, A. D. A phenotypic profile of the Candida albicans regulatory network. PLoS Genet. 5, e1000783 (2009).

Article
 
Google Scholar
 

18.

Lohse, M. B., Gulati, M., Johnson, A. D. & Nobile, C. J. Development and regulation of single- and multi-species Candida albicans biofilms. Nat. Rev. Microbiol. 16, 19–31 (2018).

CAS
 
Article
 
Google Scholar
 

19.

Braun, B. R., Kadosh, D. & Johnson, A. D. NRG1, a repressor of filamentous growth in C. albicans, is down-regulated during filament induction. EMBO J. 20, 4753–4761 (2001).

CAS
 
Article
 
Google Scholar
 

20.

Ruben, S. et al. Ahr1 and Tup1 contribute to the transcriptional control of virulence-associated genes in Candida albicans. MBio 11, e00206-20 (2020).

Article
 
Google Scholar
 

21.

De Groot, P. W. J., Bader, O., De Boer, A. D., Weig, M. & Chauhan, N. Adhesins in human fungal pathogens: glue with plenty of stick. Eukaryot. Cell 12, 470–481 (2013).

PubMed
 
PubMed Central
 
Google Scholar
 

22.

Askew, C. et al. The zinc cluster transcription factor Ahr1p directs Mcm1p regulation of Candida albicans adhesion. Mol. Microbiol. 79, 940–953 (2011).

CAS
 
Article
 
Google Scholar
 

23.

Carreté, L. et al. Patterns of genomic variation in the opportunistic pathogen Candida glabrata suggest the existence of mating and a secondary association with humans. Curr. Biol. 28, 15–27 (2018).

Article
 
Google Scholar
 

24.

Nobbs, A. H., Vickerman, M. M. & Jenkinson, H. F. Heterologous expression of Candida albicans cell wall-associated adhesins in Saccharomyces cerevisiae reveals differential specificities in adherence and biofilm formation and in binding oral Streptococcus gordonii. Eukaryot. Cell 9, 1622–1634 (2010).

CAS
 
Article
 
Google Scholar
 

25.

Edwards, J. E. Jr et al. A fungal immunotherapeutic vaccine (NDV-3A) for treatment of recurrent vulvovaginal candidiasis—a phase 2 randomized, double-blind, placebo-controlled trial. Clin. Infect. Dis. 66, 1928–1936 (2018).

CAS
 
Article
 
Google Scholar
 

26.

Fiedorová, K. et al. Bacterial but not fungal gut microbiota alterations are associated with common variable immunodeficiency (CVID) phenotype. Front. Immunol. 10, 1914 (2019).

Article
 
Google Scholar
 

27.

Spellberg, B. J. et al. Efficacy of the anti-Candida rAls3p-N or rAls1p-N vaccines against disseminated and mucosal candidiasis. J. Infect. Dis. 194, 256–260 (2006).

CAS
 
Article
 
Google Scholar
 

28.

Ibrahim, A. S. et al. Vaccination with recombinant N-terminal domain of Als1p improves survival during murine disseminated candidiasis by enhancing cell-mediated, not humoral, immunity. Infect. Immun. 73, 999–1005 (2005).

CAS
 
Article
 
Google Scholar
 

29.

Voth, W. P., Richards, J. D., Shaw, J. M. & Stillman, D. J. Yeast vectors for integration at the HO locus. Nucleic Acids Res. 29, e59 (2001).

CAS
 
Article
 
Google Scholar
 

30.

Igyártó, B. Z. et al. Skin-resident murine dendritic cell subsets promote distinct and opposing antigen-specific T helper cell responses. Immunity 35, 260–272 (2011).

Article
 
Google Scholar
 

31.

Basso, L. R., Jr et al. Transformation of Candida albicans with a synthetic hygromycin B resistance gene. Yeast 27, 1039–1048 (2010).

CAS
 
Article
 
Google Scholar
 

32.

Seman, B. G. et al. Yeast and filaments have specialized, independent activities in a zebrafish model of Candida albicans infection. Infect. Immun. 86, e00415-18 (2018).

Article
 
Google Scholar
 

33.

Schindelin, J. et al. Fiji: an open-source platform for biological-image analysis. Nat. Methods 9, 676–682 (2012).

CAS
 
Google Scholar
 

34.

Martin, M. Cutadapt removes adapter sequences from high-throughput sequencing reads. EMBnet J. 17, 10–12 (2011).

Article
 
Google Scholar
 

35.

Bray, N. L., Pimentel, H., Melsted, P. & Pachter, L. Near-optimal probabilistic RNA-seq quantification. Nat. Biotechnol. 34, 525–527 (2016).

CAS
 
Article
 
Google Scholar
 

36.

Pimentel, H., Bray, N. L., Puente, S., Melsted, P. & Pachter, L. Differential analysis of RNA-seq incorporating quantification uncertainty. Nat. Methods 14, 687–690 (2017).

CAS
 
Article
 
Google Scholar
 

37.

Yu, G., Wang, L. G., Han, Y. & He, Q. Y. clusterProfiler: an R package for comparing biological themes among gene clusters. OMICS 16, 284–287 (2012).

CAS
 
Article
 
Google Scholar
 

38.

Sergushichev, A. A. An algorithm for fast preranked gene set enrichment analysis using cumulative statistic calculation. Preprint at https://doi.org/10.1101/060012 (2016).

39.

Blighe, K., Rana S. & Lewis, M. EnhancedVolcano: publication-ready volcano plots with enhanced colouring and labeling. https://github.com/kevinblighe/EnhancedVolcano (2018).

40.

Kubinak, J. L. et al. MyD88 signaling in T cells directs IgA-mediated control of the microbiota to promote health. Cell Host Microbe 17, 153–163 (2015).

CAS
 
Article
 
Google Scholar
 

41.

Plaine, A. et al. Functional analysis of Candida albicans GPI-anchored proteins: roles in cell wall integrity and caspofungin sensitivity. Fungal Genet. Biol. 45, 1404–1414 (2008).

CAS
 
Article
 
Google Scholar
 

42.

Singh, S. et al. The NDV-3A vaccine protects mice from multidrug resistant Candida auris infection. PLoS Pathog. 15, e1007460 (2019).

CAS
 
Article
 
Google Scholar
 

Download references

Acknowledgements

We thank A. Weis and J. Hill for their edits of this manuscript; R. Wheeler for providing the pENO1-iRFP and pENO1-Neon C. albicans constructs; L. Cowen for the pLC605 TetO construct; J. Berman for the YJM11522 C. albicans strain; A. Nobbs for the S. cerevisiae strains expressing C. albicans adhesins; D. Stillman for S. cerevisiae strains and reagents; and the ULAM GF Mouse Facility at the University of Michigan for the GF Rag1−/− mice. Proteomics mass spectrometry analysis was performed at the Mass Spectrometry and Proteomics Core Facility at the University of Utah. Mass spectrometry equipment was obtained through a Shared Instrumentation Grant 1 S10 OD018210 01A1. This work was supported by the Helen Hay Whitney Foundation (K.S.O.), a University of Utah NRSA Microbial Pathogenesis T32 Training Grant (K.S.O.), a CCFA Senior Research Award (J.L.R.), NIDDK R01DK124336 (J.L.R.), the Edward Mallinckrodt Jr. Foundation (J.L.R.), a NSF CAREER award (IOS-1253278) (J.L.R.), a Packard Fellowship in Science and Engineering (J.L.R.), a Burroughs Welcome Investigator in Pathogenesis Award (J.L.R), the American Asthma Foundation (J.L.R.), the Margolis Foundation (J.L.R.), an MS Society Center grant (J.L.R.), NIAID R01046223 (B.C.), an NIH New Innovator Award DP2GM111099-01 (R.M.O.), NHLBI R00HL102228-05 (R.M.O.), an American Cancer Society Research Grant (R.M.O.), a Kimmel Scholar Award (R.M.O.), R01AG047956 (R.M.O.) and NIAID R01AI141202 (A.S.I.). This work was supported by the University of Utah Flow Cytometry Facility in addition to the National Cancer Institute through award number 5P30CA042014-24. The support and resources from the Center for High Performance Computing at the University of Utah are gratefully acknowledged.

Author information
Affiliations

Department of Pathology, Division of Microbiology and Immunology, University of Utah School of Medicine, Salt Lake City, UT, USA

Kyla S. Ost, W. Zac Stephens, Tyson Chiaro, Haoyang Zhou, Jourdan Penman, Rickesha Bell, Ryan M. O’Connell & June L. Round

Huntsman Cancer Institute, University of Utah, Salt Lake City, UT, USA

Kyla S. Ost, W. Zac Stephens, Tyson Chiaro, Haoyang Zhou, Jourdan Penman, Rickesha Bell, Ryan M. O’Connell & June L. Round

Department of Microbiology and Immunology, University of Michigan Medical School, Ann Arbor, MI, USA

Teresa R. O’Meara

Section of Pulmonology, Allergy, Immunology and Sleep Medicine, Department of Pediatrics, Yale University School of Medicine, New Haven, CT, USA

Jason R. Catanzaro

Department of Immunobiology, Yale University School of Medicine, New Haven, CT, USA

Deguang Song & Noah W. Palm

The Lundquist Institute of Biomedical Innovation, Harbor–UCLA Medical Center, Torrance, CA, USA

Shakti Singh & Ashraf S. Ibrahim

Department of Chemistry and Biochemistry, Brigham Young University, Provo, UT, USA

Daniel H. Call & Kenneth A. Christensen

Department of Molecular Biology and Genetics, Johns Hopkins University School of Medicine, Baltimore, MD, USA

Elizabeth Hwang-Wong & Brendan Cormack

Department of Pathology, Division of Clinical Microbiology, University of Utah, Salt Lake City, UT, USA

Kimberly E. Hanson

Department of Internal Medicine, Division of Gastroenterology, University of Utah School of Medicine, Salt Lake City, UT, USA

John F. Valentine

David Geffen School of Medicine at UCLA, Los Angeles, CA, USA

Ashraf S. Ibrahim

Department of Microbiology and Immunology, UCSF School of Medicine, San Francisco, CA, USA

Suzanne M. Noble

Contributions

K.S.O. conceived the study, performed most experiments and helped to write the manuscript. T.R.O. helped with experimental design and fungal strain creation, and edited the manuscript. W.Z.S. analysed the RNA-seq data, helped with experimental design and edited the manuscript. T.C. helped with the immune profiling experiments and edited the manuscript. H.Z. helped to perform the C. albicans IgA screens and edited the manuscript. J.P. helped with fungal IgA-binding assays and edited the manuscript. R.B. managed the GF mouse experiments, helped with the immune profiling experiments and edited the manuscript. J.R.C., D.S. and N.W.P. provided the collection of human faecal samples, provided guidance on human antibody experiments and edited the manuscript. D.H.C. and K.A.C. guided the imaging flow cytometry experiments and edited the manuscript. E.H.-W. and B.C. created the S. cerevisiae strains expressing the C. glabrata adhesin-like proteins and edited the manuscript. K.E.H. edited the manuscript and provided the clinical C. glabrata strains. R.M.O. provided guidance on immunological experiments. S.M.N. provided C. albicans strains, provided guidance on fungal genetics experiments and edited the manuscript. A.S.I. and S.S. provided the NDV-3A vaccine and edited the manuscript. J.F.V. provided the human serum samples. J.L.R conceived the study, guided the experiments, analysed data and helped to write the manuscript.

Corresponding author

Correspondence to June L. Round.

Ethics declarations
Competing interests

The authors declare no competing interests.

Additional information

Peer review information Nature thanks Gordon Brown and the other, anonymous, reviewer(s) for their contribution to the peer review of this work.

Publisher’s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.

Extended data figures and tables
Extended Data Fig. 1 Human faecal and serum anti-fungal antibodies.

a, Human faecal antibody binding to cultured fungi and quantified by flow cytometry after staining with fluorescent secondary antibodies (n = 70). Staining intensity normalized to fungi stained with secondary antibodies but without human faecal wash. Box plots show minimum 25% quartile and maximum 75% quartile around the median and whiskers show range. b, IgA binding to cultured fungi from serial dilutions of human faecal wash (n = 30 healthy, n = 23 Crohn’s disease and n = 17 UC). Geometric mean with 95% CI c, d, Human serum antibody binding to cultured fungi. Serum diluted 1:75. (n = 12, n = 4 healthy and n = 8 Crohn’s disease). Mean ± s.d. e, Faecal ASCA IgA levels from undiluted faecal wash (n = 30 healthy, n = 18 Crohn’s disease and n = 14 UC). Median with 95% CI f, Serum ASCA IgA levels from human serum samples diluted 1:100 (n = 4 healthy and n = 8 Crohn’s disease). Median with 95% CI. P values calculated using two-way ANOVA with Tukey’s test (a), one-way ANOVA with Dunn’s test (c) or two-sided Mann–Whitney U-test (f, d).

Source data

Extended Data Fig. 2 IgA targets Candida species but not S. cerevisiae.

a, IgA-bound faecal fungi gating strategy. b, Peyer’s patch GC B cell and TFH cell gating strategy. c, Colon LP IgA plasma cell gating strategy (n = 4 mice per group 30 days after inoculation; representative of two experiments for b, c). d, IgA binding to faecal GFP+ S. cerevisiae and GFP+ C. albicans in monocolonized SW mice. e, Total IgA levels from monocolonized SW mice. f, Flow cytometry quantification of SW IgA binding to cultured S. cerevisiae and C. albicans (n = 4 C. albicans-colonized and n = 5 S. cerevisiae-colonized, one experiment for d–f). g, h, Serum antibody binding to cultured C. albicans or S. cerevisiae from SW (g) or B6 (h) GF or monocolonized mice. Antibody quantified by flow cytometry from serum diluted 1:25 (SW: GF n = 4, Sc-colonized n = 5, Ca-colonized n = 5; B6: GF n = 3, Sc n = 5, Ca-colonized n = 3). i, Lumen and tissue-associated fungal burden in monocolonized B6 mice 30 days after inoculation (n = 4 mice per group; one experiment; representative of two experiments). j, Whole-intestinal IgA four weeks after inoculation. k, Caecal wash IgA binding to cultured C. glabrata measured by flow cytometry. l, Peyer’s patch TFH cells four weeks after inoculation. m, Peyer’s patch GC B cells (n = 4 mice per group; one experiment for j–m). n, IgA binding to cultured C. glabrata, S. cerevisiae and C. albicans from faecal wash from GF, C. albicans-monocolonized or C. glabrata-monocolonized intestinal wash (n = 2 C. albicans, n = 3 C. glabrata and n = 3 S. cerevisiae faecal washes) o, Percentage of IgA binding and binding intensity of faecal C. albicans during colonization of antibiotic-treated wild-type and Tcrb−/− mice (n = 6 Tcrb−/− and n =8 wild-type mice from two experiments). P values calculated using two-way ANOVA (d, o), with Sidak’s test (b, e, f, g, h, n), or two-sided unpaired t-test (j, k, l, m). Mean values ± s.d. for b, d–o.

Source data

Extended Data Fig. 3 An IgA response is not induced by 124 distinct S. cerevisiae strains.

a, IgA binding to the 20–24 strains from each pool was assessed by flow cytometry. Mice were gavaged weekly with the indicated pool for three weeks and caecal wash from mice was used as a source of IgA. C. albicans bound by IgA from C. albicans-monocolonized mice is shown in red. b, Total IgA in caecum contents quantified by ELISA. Mean values ± s.d. c, IgA binding to S. cerevisiae (pre-gated on CFW intermediate) populations from caecal material. (n = 3 mice per group representative of two experiments).

Source data

Extended Data Fig. 4 Fungal burden and GO term enrichment analysis of RNA-seq comparison of C. albicans in monocolonized wild-type and Rag1−/− mice.

a, Fungal burden in wild-type and Rag1−/− mice monocolonized with C. albicans four weeks after inoculation. Mean values ± s.d. b, c, Biological process (b) or molecular function (c) GO term enrichment in genes with q ≤ 0.05 and log2-transformed fold change ≥ 1 or ≤ −1. d, Volcano plot of the ratio of C. albicans transcripts in wild-type and Rag1−/− mice with active transmembrane transporter activity genes labelled in red (n = 5 wild type and 4 Rag1−/− mice for a–d; one experiment). e, C. albicans morphology in colon contents from monocolonized wild-type or Rag1−/− mice four weeks after colonization. Mean values ± s.d. (n = 3 mice per group; one experiment). f, IgA binding to C. albicans in the faeces of antibiotic-treated wild-type and μMT−/− mice four weeks after inoculation. Mean values ± s.d. (n = 5 mice per group; one experiment). P values calculated using two-way ANOVA with Sidak’s multiple comparisons test (a, f) or two-sided unpaired t-test (e).

Source data

Extended Data Fig. 5 Filamentation and Ahr1 promote intestinal IgA responses.

a, Morphology of indicated C. albicans strains incubated for 4 h in RPMI with 10% FBS, YPD or YPD + 5 μg ml−1 aTC). TetO-NRG1 constitutively expresses NRG1 when untreated (TetOn), but aTC repressed NRG1 expression (TetOff). b, C. albicans in caecum contents stained with AF488 anti-Candida antibody. c, Intestinal fungal burden (mean values ± s.d.). d, Peyer’s patch TFH cells (ICOS+PD-1+CD4+CD3+ live cells) (mean values ± s.d.). e, Peyer’s patch GC B cells (GL-7+Fas+IgD−CD19+ live cells) (mean values ± s.d.). f, Colon LP IgA+ plasma cells (IgA+CD138+CD45+CD3−CD19− live cells) (mean values ± s.d.) quantified from mice monocolonized for four weeks (for c–f, n = 4 mice per group; one experiment). g, Faecal AHR1 qPCR in aTC-treated mice monocolonized with wild-type or TetO-AHR1 (TetOff-AHR1) (wild type n = 3 and TetOff-ALS1 n = 5; one experiment). Mean values ± s.d. h, Fungal burden of wild-type- and TetOff-AHR1-monocolonized mice. i, IgA from wild-type- or TetOff-AHR1-monocolonized mice, j, k, Peyer’s patch TFH cells (j) and Peyer’s patch GC B cells (k) from mice monocolonized with wild type or TetOff-AHR1. l, qRT–PCR from the small intestinal contents of monocolonized mice (for h–l, wild type n = 8 and TetOff-ALS1 n = 10 mice per group from two experiments). m, Intestinal IgA (from C. albicans-monocolonized mice) binding to strains that were cultured untreated or were treated with aTC. n, Human IgA binding to indicated strains cultured without aTC (wild type, ahr1∆/∆, ahr1∆/∆ TetOn-ALS1) or with 5 μg ml−1 aTC (ahr1∆/∆ TetOff-ALS1). IgA binding quantified by flow cytometry (healthy n = 13 and IBD n = 22; one experiment. Samples chosen had enough C. albicans-reactive IgA to bind at least 10% of cultured wild-type C. albicans). P values calculated using one-way ANOVA with Tukey’s test (c–f), two-way ANOVA with Sidak’s test (i), two-sided unpaired t-test (j, k, l), two-sided Mann–Whitney U-test (g) or Friedman test with Dunn’s test (n).

Source data

Extended Data Fig. 6 C. albicans- and C. glabrata-induced IgA targets adhesins or adhesin-like proteins.

a, Anti-HA staining of the control S. cerevisiae expressing the Cwp1 scaffold control and the S. cerevisiae strains expressing HA-tagged C. albicans adhesins. b, Anti-HA and IgA binding to S. cerevisiae strains expressing HA-tagged C. glabrata adhesins after incubation in caecal wash from mice monocolonized with C. glabrata. SC104, SC106, SC97 and SC27 express adhesins not tagged by HA. HA and IgA binding quantified by flow cytometry.

Source data

Extended Data Fig. 7 Antibody induction by S. cerevisiae strains expressing Candida adhesins.

GF SW mice were monocolonized with the indicated strains or left GF. Colonized mice were gavaged three times per week with cultured strains. The control S. cerevisiae expresses the CWP1 cell surface scaffold but not an adhesin. a, Weekly faecal IgA levels normalized by faecal weight. b, c, Intestinal IgA (b) and IgG (c) levels at day 28 normalized by material weight. d, Colon lamina propria IgG1 plasma cells (live IgG1+IgA−CD138+CD19−CD3−CD45+ live cells). e, Colon lamina propria IgA plasma cells (live IgA+IgG1−CD138+CD19−CD3−CD45+ live cells) (for a–e, GF n = 6, control Sc n = 4, Sc + Als1 n = 5, Sc + Als3 n = 5, Sc + Hwp1 n = 4, Sc + CAGL0B00154g n = 5 mice per group; one experiment). P values calculated using one-way ANOVA with Tukey’s test (d, e) or two-way ANOVA with Tukey’s test (a–c). All data are mean ± s.d.

Source data

Extended Data Fig. 8 Immune-enhanced fitness diminishes after 14 days.

Competitive index (CI) of C. albicans conditioned for four weeks in indicated GF recipient mice. B6-conditioned C. albicans was iRFP+ and Rag1−/−-conditioned C. albicans was Neon+. CI normalized to the CI when strains were competed in wild-type and Rag1−/− mice directly from culture (competition mice, n = 3 B6 and n = 4 Rag1−/− mice from one experiment). P values calculated using two-way ANOVA with Sidak’s test. Data are mean ± s.d.

Source data

Extended Data Fig. 9 AHR1 exacerbates DSS colitis.

a, Schematic of DSS colitis experiments. b, Histology images and scores for mice treated with no C. albicans or with TetO-AHR1 with and without aTC (no-Ca UT, no-Ca aTC and TetOn-AHR1 UT n = 7 mice per group, TetOff-AHR1 aTC n = 8 mice per group from two independent experiments). Data are mean ± s.d. c, DSS histology images for mice treated with no C. albicans or with wild-type C. albicans, ahr1∆/∆ C. albicans, TetOn-ALS1 ahr1∆/∆ C. albicans and TetOff-ALS1 ahr1∆/∆ C. albicans (aTC-treated). P values calculated using two-way ANOVA with Tukey’s test (b).

Source data

Extended Data Fig. 10 NDV-3A induces an intestinal anti-Als3 antibody response.

a, model of monocolonization and DSS experiment in vaccinated mice. b, c, ELISA quantification of Als3-specific IgA (b) and IgG (c) from the faeces of GF mice one week after boost with alum of NDV-3A vaccine. d, e, Faecal (d) and intestinal (e) lumen CFU of C. albicans in monocolonized alum or NDV-3A vaccinated mice. Intestinal CFU quantified 12 days after colonization. f, Imaging flow cytometry images of IgA+ C. albicans from caecum of NDV-3A vaccinated mice. g, Percentage of hyphae quantified using an AF488 anti-Candida antibody to visualize morphology from indicated intestinal region 12 days after monocolonization. h, HWP1 and HYR1 transcripts quantified by qRT–PCR from colon C. albicans 12 days after monocolonization. (for b–h, n = 5 mice per group; one experiment). i, j, ELISA quantification of Als3-specific IgA (i) and IgG (j) in the faeces of conventionally colonized mice used for the DSS experiment. k, C. albicans CFU in colon contents after DSS treatment (for i–k, n = 10 mice per group, one experiment). l, Example H&E-stained histology images from the NDV-3A DSS experiment. P values calculated using two-way ANOVA with Sidak’s test (b, c, i, j). All data are mean ± s.d. Silhouettes in a were created using BioRender.

Source data

Supplementary information
Supplementary Information

This file contains Supplementary Figure 1.

Reporting Summary
Supplementary Table 1

RNAseq differential gene expression analysis.

Supplementary Table 2

IgA binding screen of Noble and Homann knock-out collections.

Supplementary Table 3

IgA targeted hyphae vs. yeast cell wall proteomics analysis.

Supplementary Table 4

Fungal strains used in this study.

Supplementary Table 5

S. cerevisiae strains expressing C. albicans or C. glabrata adhesins or adhesin-like domains.

Supplementary Table 6

Primers used for this study.

Supplementary Table 7

Plasmids used in this study.

Supplementary Table 8

Flow cytometry antibodies used in this study.

Supplementary Table 9

Human fecal and serum metadata.

Source data
Source Data Fig. 1
Source Data Fig. 2
Source Data Fig. 3
Source Data Extended Data Fig. 1
Source Data Extended Data Fig. 2
Source Data Extended Data Fig. 3
Source Data Extended Data Fig. 4
Source Data Extended Data Fig. 5
Source Data Extended Data Fig. 6
Source Data Extended Data Fig. 7
Source Data Extended Data Fig. 8
Source Data Extended Data Fig. 9
Source Data Extended Data Fig. 10
Rights and permissions

Reprints and Permissions

About this article
Cite this article

Ost, K.S., O’Meara, T.R., Stephens, W.Z. et al. Adaptive immunity induces mutualism between commensal eukaryotes. Nature (2021). https://doi.org/10.1038/s41586-021-03722-w

Download citation

Received
24 June 2020

Accepted
14 June 2021

Published
14 July 2021

DOI
https://doi.org/10.1038/s41586-021-03722-w

Subjects
Fungal host response
Mucosal immunology
Comments

By submitting a comment you agree to abide by our Terms and Community Guidelines. If you find something abusive or that does not comply with our terms or guidelines please flag it as inappropriate.

Nature ISSN 1476-4687 (online)

nature.com sitemap
About us
Press releases
Press office
Contact us
Discover content
Journals A-Z
Articles by subject
Nano
Protocol Exchange
Nature Index
Publishing policies
Nature portfolio policies
Open access
Author & Researcher services
Reprints & permissions
Research data
Language editing
Scientific editing
Nature Masterclasses
Nature Research Academies
Libraries & institutions
Librarian service & tools
Librarian portal
Open research
Recommend to library
Advertising & partnerships
Advertising
Partnerships & Services
Media kits
Branded content
Career development
Nature Careers
Nature
 Conferences
Nature
 events
Regional websites
Nature Africa
Nature China
Nature India
Nature Italy
Nature Japan
Nature Korea
Nature Middle East
Legal & Privacy
Privacy Policy
Use of cookies
Manage cookies/Do not sell my data
Legal notice
Accessibility statement
Terms & Conditions
California Privacy Statement

© 2021 Springer Nature Limited

Close

Sign up for the Nature Briefing newsletter — what matters in science, free to your inbox daily.

Email address
 Sign up
I agree my information will be processed in accordance with the Nature and Springer Nature Limited Privacy Policy.
Your privacy

We use cookies to make sure that our website works properly, as well as some "optional" cookies to personalise content and advertising, provide social media features and analyse how people use our site. By accepting some or all optional cookies you give consent to the processing of your personal data, including transfer to third parties, some in countries outside of the European Economic Area that do not offer the same data protection standards as the country where you live. You can decide which optional cookies to accept by clicking on "Manage Settings", where you can also find more information about how your personal data is processed.View our privacy policy

Manage Settings Accept All Cookies]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Europe aims to kill gasoline and diesel cars by 2035 - CNN]]></title>
            <link>https://edition.cnn.com/2021/07/14/business/eu-emissions-climate-cars/index.html</link>
            <guid>https://edition.cnn.com/2021/07/14/business/eu-emissions-climate-cars/index.html</guid>
            <pubDate>Wed, 14 Jul 2021 19:57:22 GMT</pubDate>
            <content:encoded><![CDATA[LIVE TV
MARKETS
see all
DOW
	
34,929.96
	
41.17
	
0.12%


S&P 500
	
4,373.65
	
4.44
	
0.10%


NASDAQ
	
14,641.83
	
-35.82
	
-0.24%
FEATURED
Inflation Calculator

Prices are rising. Use this tool to see if inflation will impact your standard of living

Europe aims to kill gasoline and diesel cars by 2035

By Charles Riley, CNN Business

Updated 1528 GMT (2328 HKT) July 14, 2021

These tiny cars are cute and easy to park. Will anyone want them?
The Hummer electric SUV is coming
See this Tesla competitor's new electric pickup
The McLaren Artura is an electric hybrid with the speed of a supercar
See Porsche's 911 GT3 on the racetrack
See Ford's new Raptor F-150 in action
Review: The Ghost is more modest and simple, but it's still a Rolls-Royce
This Mini Cooper is built to race. No, really
Go inside the EV startup working with Uber and UPS
Watch the new Ford Bronco go way off road
See Ferrari's new plug-in hybrid
Check out Airstream's first all-terrain adventure van
Meet the Maverick, Ford's compact $20k truck
This boat-inspired Rolls-Royce could be the most expensive new car ever
Check out the new electric Ford F-150 Lightning
See the new all-electric EQS luxury sedan from Mercedes
These tiny cars are cute and easy to park. Will anyone want them?
The Hummer electric SUV is coming
See this Tesla competitor's new electric pickup
The McLaren Artura is an electric hybrid with the speed of a supercar
See Porsche's 911 GT3 on the racetrack
See Ford's new Raptor F-150 in action
Review: The Ghost is more modest and simple, but it's still a Rolls-Royce
This Mini Cooper is built to race. No, really
Go inside the EV startup working with Uber and UPS
Watch the new Ford Bronco go way off road
See Ferrari's new plug-in hybrid
Check out Airstream's first all-terrain adventure van
Meet the Maverick, Ford's compact $20k truck
This boat-inspired Rolls-Royce could be the most expensive new car ever
Check out the new electric Ford F-150 Lightning
See the new all-electric EQS luxury sedan from Mercedes

London (CNN Business)The European Union has announced plans to end the sale of polluting vehicles by 2035, an ambitious goal that would put hybrid cars on the endangered species list and usher in a rapid and dramatic shift to fully electric models.

The European Commission said Wednesday that it wants to require the auto industry to slash the average emissions of new cars by 55% by 2030. A further reduction to 100% by 2035 effectively means that all new cars registered from that year onward must be zero-emission vehicles. The United Kingdom has already made a similar commitment.
The new 2030 goal would be a significant leap from the current EU target of cutting emissions from new cars by 37.5%, which was only set in December 2018.
The proposed rule changes are part of a much larger package aimed at propelling the European Union towards its goal of cutting greenhouse gas emissions by at least 55% by 2030 compared to 1990 levels. Europe wants to be the first continent to be climate neutral in 2050.
"The fossil fuel economy has reached its limits. We want to leave the next generation a healthy planet as well as good jobs and growth that does not hurt our nature," European Commission President Ursula von der Leyen said in a statement.
VW hopes its electric bus can drive huge sales growth in the US
To facilitate the shift to electric cars, the Commission said it would require the 27 EU member states to expand vehicle charging capacity. Charging points will be installed every 60 kilometers (37.3 miles) on major highways, and the minimum tax rate for gasoline and diesel fuel will be hiked.
"This is a turning point for the auto industry and good news for drivers," said William Todts, the executive director of lobby group Transport & Environment. "The new EU rules will democratize electric cars and give a major boost to charging."
The auto industry plays a vital role in Europe's economy, accounting for 7% of gross domestic product and supporting 14.6 million jobs in the region. But transport is the only sector where greenhouse gas emissions are rising, and road vehicles accounted for 21% of CO2 emissions in 2017.
Carmakers have seen the writing on the wall, and many have announced ambitious plans in recent months to increase production of electric vehicles. Investors have rewarded the most ambitious companies by boosting their share prices.
Volkswagen (VLKAF), which owns brands including Audi and Porsche, said Tuesday that it wants electric vehicles to account for 50% of its sales by 2030. By 2040, Europe's largest carmaker plans to sell only zero-emission vehicles in its major markets, which include the United States and China.
Ford (F) has announced plans to sell only electric passenger vehicles in Europe by 2030. Renault (RNLSY), Volvo (VOLAF), BMW (BMWYY) and Mercedes-Benz owner Daimler (DDAIF) have outlined their own programs to boost production of cleaner cars.
Still, many carmakers will need to accelerate their plans to meet the EU targets, which are among the world's most aggressive. In order to balance out the emissions generated in 2030 by vehicles with internal combustion engines, including hybrids, carmakers will need to sell loads of electric cars.
Volkswagen and BMW fined $1 billion for running emissions cartel
"These targets should not come as a surprise [to carmakers], although they clearly require an accelerated shift towards [battery electric vehicles] over time," Barclays analysts wrote in a recent research note.
The pace of change demanded by regulators matters to carmakers because they plan to use profits from sales of gas and diesel vehicles to fund the research and development of electric vehicles.
Volkswagen finance chief Arno Antlitz said on Tuesday that the company's internal combustion engine business would "help to generate the profits and cash flows" needed to pay for investments in software, autonomous driving and production platforms for electric vehicles. Volkswagen has earmarked €73 billion ($86 billion) through 2025 to develop the technologies.
It could be years before the EU rules come into force. The plan needs to be read, amended and approved by lawmakers in the EU Parliament and the EU Council, the forum in which the elected leaders of each member state debate such matters.
Britain announced last year that it would ban sales of new gasoline and diesel cars — including hybrids — starting in 2035.
Still, time is of the essence. Todts said carmakers must move quickly to help solve the climate crisis.
"The problem is carmakers will only have to start selling those cleaner cars in 2030. Our planet cannot afford another nine years of big talk but little action from the auto industry," he said.

Search
World
US Politics
Business
Health
Entertainment
Tech
Style
Travel
Sports
Videos
Features
Weather
More
FOLLOW CNN BUSINESS
Most stock quote data provided by BATS. Market indices are shown in real time, except for the DJIA, which is delayed by two minutes. All times are ET. Disclaimer. Morningstar: Copyright 2018 Morningstar, Inc. All Rights Reserved. Factset: FactSet Research Systems Inc.2018. All rights reserved. Chicago Mercantile Association: Certain market data is the property of Chicago Mercantile Exchange Inc. and its licensors. All rights reserved. Dow Jones: The Dow Jones branded indices are proprietary to and are calculated, distributed and marketed by DJI Opco, a subsidiary of S&P Dow Jones Indices LLC and have been licensed for use to S&P Opco, LLC and CNN. Standard & Poor's and S&P are registered trademarks of Standard & Poor's Financial Services LLC and Dow Jones is a registered trademark of Dow Jones Trademark Holdings LLC. All content of the Dow Jones branded indices Copyright S&P Dow Jones Indices LLC 2018 and/or its affiliates.
Terms of Use
Privacy Policy
Do Not Sell My Personal Information
AdChoices
About Us
Modern Slavery Act Statement
Advertise with us
CNN Store
Newsletters
Transcripts
License Footage
CNN Newsource
Sitemap
© 2021 Cable News Network.A Warner Media Company.All Rights Reserved.
CNN Sans ™ & © 2016 Cable News Network.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Designing a Calendar Table]]></title>
            <link>https://www.sqlshack.com/designing-a-calendar-table/</link>
            <guid>https://www.sqlshack.com/designing-a-calendar-table/</guid>
            <pubDate>Wed, 14 Jul 2021 19:57:15 GMT</pubDate>
            <content:encoded><![CDATA[This website uses cookies. By continuing to use this site and/or clicking the "Accept" button you are providing consent




Quest Software and its affiliates do NOT sell the Personal Data you provide to us either when you register on our websites or when you do business with us. For more information about our Privacy Policy and our data protection efforts, please visit GDPR-HQ

SQLShack
Skip to content
SQL Server training Español  

Designing a Calendar Table
March 22, 2017 by Ed Pollack
Introduction

There is a common need in reporting to aggregate or return data that is crunched based on date attributes. These may include weekdays, holidays, quarters, or time of year. While any of this information can be calculated on the fly, a calendar table can save time, improve performance, and increase the consistency of data returned by our important reporting processes.

What is a Calendar Table and Why is it Useful?

A calendar table is a permanent table containing a list of dates and various components of those dates. These may be the result of DATEPART operations, time of year, holiday analysis, or any other creative operations we can think of.

The primary key of this table will always be the date, or some easy-to-use representation of that date. Each subsequent column will be an attribute of that date, where the types and size of those columns can vary greatly. At first glance, it may seem that a table such as this would be superfluous, and that this data is easy to generate, but oftentimes as our reporting needs become complex, so does the creation, maintenance, and usage of this data.

As a result, storing calendar data in a permanent location can be an easy solution. Here are some reasons why this data is useful and why storing it in a dedicated table can be a great decision:

Data is relatively easy to generate and requires little maintenance once created.
Calendar data can be used to service any reports that require it, removing the need to recreate it in each report.
We can implement a large number of calendar metrics, and can easily add more as needed.
Calendar data is tiny in terms of space used. Performance against this data is generally quite fast.
Complex reports can be simplified by removing commonly used DATEPART and DATEADD computations.
Important business logic, such as holidays, can be centralized and maintained in a single location.
Maintaining calendar data in a single table ensures we do not encounter inconsistencies between different reports, reporting systems, or applications that need it.

There are many different reasons why a calendar table can be useful—this article is our opportunity to create one from scratch, populate it with data, analyze it, and put it to good use!

Implementing a Calendar Table

Our first step is to identify and define metrics that we want to collect. This is where we should look at our reporting needs and determine what sorts of date-related calculations we perform on a regular basis. For our examples here, we will include 33 different metrics (plus the calendar date itself), though you are free to add more as needed. Once introduced, we’ll walk through how to populate this data, and then how to use it.

Date Parts

The simplest metrics are basic date components, including:

Calendar Month: The numeric representation of the month, a number from 1-12.
Calendar Day: The numeric representation of the calendar day, a number from 1-31. The maximum value depends on the month and on whether it is a leap year.
Calendar Year: The numeric representation of the year, such as 1979 or 2017.
Calendar Quarter: The numeric representation of the quarter, a number from 1-4.
Day Name: The common name for the day of the week, such as Tuesday or Saturday.
Day of Week: The numeric representation of the day of the week, a number from 1(Sunday) through 7 (Saturday). In some countries the number 1 is used to represent Monday, though here we will use Sunday for this calculation.
Month Name: The common name for the month, such as February or October.

These are all bits and pieces of the date itself and are useful whenever we are looking to find out metrics on specific days of the week, fiscal quarters, or other date parts.

Relative Points in Time

Knowing when a date is, with respect to other calendar metrics, can be very handy in understanding how business changes over time. The following metrics allow you to determine in what part of the week, month, or year a date occurs:

Day of Week in Month: The occurrence of a day of week within the current month. Ie: The third Thursday of the current month.
Day of Week in Year: The occurrence of a day of week within the current year. Ie: The seventeenth Monday of the current year.
Day of Week in Quarter: The occurrence of a day of week within the current quarter. Ie: The seventh Saturday of the current quarter.
Day of Quarter: The day number within the current quarter.
Day of Year: The day number out of the current year.
Week of Month: The week number within the current month. With this calculation, the weeks count starting on the first of the month, regardless of the day of week.
Week of Quarter: The week number within the current quarter.
Week of Year: The week number within the current year.
First Date of Week: The start date of the week. Sunday is assumed here, but could be defined differently.
Last Date of Week: The end date of the week. Saturday is assumed here, but could be defined differently.
First Date of Month: The first date of the current month.
Last Date of Month: The last date of the current month.
First Date of Quarter: The first date of the current quarter.
Last Date of Quarter: The last date of the current quarter.
First Date of Year: The first date of the current year.
Last Date of Year: The last date of the current year.

These metrics allow us to easily determine when holidays or special dates occur. In addition, they can be used to assist with special processes that occur during specific weeks, such as tax preparation, invoicing, or other routing operations.

The “Day of Week of…” metrics are measures of how many of a given day have occurred thus far in a time period. The following illustration shows this metric for Wednesdays in March, 2017:

The “Day of Week of Month” for the 1st is 1, the 8th is 2, the 15th is 3, and so on. The similar metrics for quarter and year are calculated in the same fashion, by asking, “So far this year, how many Mondays have we had”, assuming the date we are looking at is a Monday.

Knowing boundaries, such as the start and end of weeks can allow for year-over-year trending by week, or for quick data crunching by specific periods in time.

Holidays and Business Days

Many business care about holidays, holiday seasons, and when business days occur. This can influence load on software systems, allocation of resources, employee coverage, and financial trending. Including some data that describes when holidays occur and what they are can greatly assist in this sort of analysis, removing the need for complex, ad-hoc reporting at a later time.

Is Holiday? A bit that indicates if a given date is a holiday or not.
Is Holiday Season? A bit that indicates if a given date is part of a holiday season or not.
Holiday Name: Indicates the name of the holiday, if applicable.
Holiday Season Name: Indicates the name of the holiday season, if applicable.
Is Weekday? A bit that indicates if a given day is a weekday, typically Monday-Friday.
Is Business Day? A bit that combines weekday and holiday data to determine if it is a business/work day.
Previous Business Day: This is the immediately preceding business day.
Next Business Day: This is the immediately following business day.

Business days can vary greatly across different industries. A week off for some may equate to the busiest week of the year for others. Summer vacation for teachers could be prime time for an outdoor amusement park. Being able to enumerate all of these rules into a handful of simple bits can make metrics-gathering significantly faster and easier!

Miscellaneous Metrics

We could come up with endless lists of date-related metrics, but for those that didn’t fit into other categories, here are a few examples that could be handy:

Is Leap Year: Is the current date is contained within a leap year, then this bit would be set to 1.
Days in Month: Contains the number of days in the current month.
Calendar Date String: A representation of the date in a string, delimited by forward slashes. This is useful for quickly displaying a more familiar string-based date format to the user. Other formats can be stored, too.

The purpose of a calendar table is to improve the speed, accuracy, and ease of reporting. Many of these metrics could easily be calculated on the fly as a report is run, but over time, the need for more complex metrics would make this incredibly messy. Even getting the days in a month could be a nuisance as a CASE statement including details for leap years would be cumbersome.

Create the Dim_Date Table

Our first step is to create a calendar table for use in all of our subsequent examples:

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
	
 
CREATE TABLE dbo.Dim_Date
(	Calendar_Date DATE NOT NULL CONSTRAINT PK_Dim_Date PRIMARY KEY CLUSTERED, -- The date addressed in this row.
	Calendar_Date_String VARCHAR(10) NOT NULL, -- The VARCHAR formatted date, such as 07/03/2017
	Calendar_Month TINYINT NOT NULL, -- Number from 1-12
	Calendar_Day TINYINT NOT NULL, -- Number from 1 through 31
	Calendar_Year SMALLINT NOT NULL, -- Current year, eg: 2017, 2025, 1984.
	Calendar_Quarter TINYINT NOT NULL, -- 1-4, indicates quarter within the current year.
	Day_Name VARCHAR(9) NOT NULL, -- Name of the day of the week, Sunday...Saturday
	Day_of_Week TINYINT NOT NULL, -- Number from 1-7 (1 = Sunday)
	Day_of_Week_in_Month TINYINT NOT NULL, -- Number from 1-5, indicates for example that it's the Nth saturday of the month.
	Day_of_Week_in_Year TINYINT NOT NULL, -- Number from 1-53, indicates for example that it's the Nth saturday of the year.
	Day_of_Week_in_Quarter TINYINT NOT NULL, -- Number from 1-13, indicates for example that it's the Nth saturday of the quarter.
	Day_of_Quarter TINYINT NOT NULL, -- Number from 1-92, indicates the day # in the quarter.
	Day_of_Year SMALLINT NOT NULL, -- Number from 1-366
	Week_of_Month TINYINT NOT NULL, -- Number from 1-6, indicates the number of week within the current month.
	Week_of_Quarter TINYINT NOT NULL, -- Number from 1-14, indicates the number of week within the current quarter.
	Week_of_Year TINYINT NOT NULL, -- Number from 1-53, indicates the number of week within the current year.
	Month_Name VARCHAR(9) NOT NULL, -- January-December
	First_Date_of_Week DATE NOT NULL, -- Date of the first day of this week.
	Last_Date_of_Week DATE NOT NULL, -- Date of the last day of this week.
	First_Date_of_Month DATE NOT NULL, -- Date of the first day of this month.
	Last_Date_of_Month DATE NOT NULL, -- Date of the last day of this month.
	First_Date_of_Quarter DATE NOT NULL, -- Date of the first day of this quarter.
	Last_Date_of_Quarter DATE NOT NULL, -- Date of the last day of this quarter.
	First_Date_of_Year DATE NOT NULL, -- Date of the first day of this year.
	Last_Date_of_Year DATE NOT NULL, -- Date of the last day of this year.
	Is_Holiday BIT NOT NULL, -- 1 if a holiday
	Is_Holiday_Season BIT NOT NULL, -- 1 if part of a holiday season
	Holiday_Name VARCHAR(50) NULL, -- Name of holiday, if Is_Holiday = 1
	Holiday_Season_Name VARCHAR(50) NULL, -- Name of holiday season, if Is_Holiday_Season = 1
	Is_Weekday BIT NOT NULL, -- 1 if Monday-->Friday, 0 for Saturday/Sunday
	Is_Business_Day BIT NOT NULL, -- 1 if a workday, otherwise 0.
	Previous_Business_Day DATE NULL, -- Previous date that is a work day
	Next_Business_Day DATE NULL, -- Next date that is a work day
	Is_Leap_Year BIT NOT NULL, -- 1 if current year is a leap year.
	Days_in_Month TINYINT NOT NULL -- Number of days in the current month.
);
 

There are two ways to approach the structure of this data. One is to create computed columns that automatically populate based on the date, and the other is to populate all via script instead. I have chosen to allow for manual population with the rationale being:

Even if we toss 100 years of data into the date table, performance will be good enough that it will populate in approximately a few minutes.
Being able to use metrics immediately for further calculations Is immensely useful, simplifying code & maintenance. This is especially handy for more complex calculations involving calendars and holidays.
Populating a calendar table is a one-time affair. Once complete, the data is available indefinitely.

Also note that the primary key on the table is a DATE. Integers have often been used as the primary key on calendar tables in older versions of SQL Server due to the lack of an appropriate DATE data type. Not only is DATE more intuitive and easier to use, but it only consumes 3 bytes instead of 4 for an INT. In theory, a SMALLINT (2 bytes) could be used, but there is some risk of overflow if we decide to trend far into the past or into the future. If for any reason (backward compatibility, etc…) you needed to use an integer, augmenting this process to do so would not be difficult.

Once created, we can move forward with creating a stored procedure that can be used to insert data into this table.

Populating a Calendar Table

To keep our stored proc simple, we’ll have only 2 parameters: A start and end date. Any existing data in this date range will be deleted and repopulated in its entirety. This allows for easy recreation of data in the event that any changes are made to this process, such as defining holidays or business days.

1
2
3
4
5
6
7
8
	
 
CREATE PROCEDURE dbo.Populate_Dim_Date
	@Start_Date DATE,
	@End_Date DATE
AS
BEGIN
	SET NOCOUNT ON;
 

With the proc declaration out of the way, we can quickly check for a few anomalous conditions that we would want to alert on:

1
2
3
4
5
6
7
8
9
10
11
12
13
	
 
IF @Start_Date IS NULL OR @End_Date IS NULL
BEGIN
	SELECT 'Start and end dates MUST be provided in order for this stored procedure to work.';
	RETURN;
END
 
	IF @Start_Date > @End_Date
	BEGIN
		SELECT 'Start date must be less than or equal to the end date.';
		RETURN;
	END
 

These validations ensure that we are not passing in NULL data or end dates that occur prior to start dates. The error is a nudge on the shoulder instead of throwing a RAISERROR, as this is more of a maintenance utility than an ongoing process.

The next step is to remove any data from Dim_Date that falls within the range specified:

1
2
3
4
	
 
DELETE FROM dbo.Dim_Date
WHERE Dim_Date.Calendar_Date BETWEEN @Start_Date AND @End_Date;
  
While we could leave data alone or update it, I found that it was convenient when testing to be able to completely destroy existing data and recreate it. Since the amount of time needed to do this is small, the cost was more than worth the convenience.

In order to accurately generate our data, I chose a methodical approach in which we declare variables, assign them one at a time, and then insert a row into Dim_Date when complete. The iterative approach is typically going to operate slower than a set-based approach, but the ability to use scalar variables to do so helps keep that runtime acceptable. A set-based approach could be devised with a numbers table or set of CTEs in order to reduce runtime, but the trade-off would be complexity and contention.

The long laundry list of local variables is as follows:

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
	
 
DECLARE @Date_Counter DATE = @Start_Date;
DECLARE @Calendar_Date_String VARCHAR(10);
DECLARE @Calendar_Month TINYINT;
DECLARE @Calendar_Day TINYINT;
DECLARE @Calendar_Year SMALLINT;
DECLARE @Calendar_Quarter TINYINT;
DECLARE @Day_Name VARCHAR(9);
DECLARE @Day_of_Week TINYINT;
DECLARE @Day_of_Week_in_Month TINYINT;
DECLARE @Day_of_Week_in_Year TINYINT;
DECLARE @Day_of_Week_in_Quarter TINYINT;
DECLARE @Day_of_Quarter TINYINT;
DECLARE @Day_of_Year SMALLINT;
DECLARE @Week_of_Month TINYINT;
DECLARE @Week_of_Quarter TINYINT;
DECLARE @Week_of_Year TINYINT;
DECLARE @Month_Name VARCHAR(9);
DECLARE @First_Date_of_Week DATE;
DECLARE @Last_Date_of_Week DATE;
DECLARE @First_Date_of_Month DATE;
DECLARE @Last_Date_of_Month DATE;
DECLARE @First_Date_of_Quarter DATE;
DECLARE @Last_Date_of_Quarter DATE;
DECLARE @First_Date_of_Year DATE;
DECLARE @Last_Date_of_Year DATE;
DECLARE @Is_Holiday BIT;
DECLARE @Is_Holiday_Season BIT;
DECLARE @Holiday_Name VARCHAR(50);
DECLARE @Holiday_Season_Name VARCHAR(50);
DECLARE @Is_Weekday BIT;
DECLARE @Is_Business_Day BIT;
DECLARE @Is_Leap_Year BIT;
DECLARE @Days_in_Month TINYINT;
 

There is a variable for nearly every column, allowing calculations to be kept simple. We also benefit from being able to use any calculations in subsequent operations. @Date_Counter will iterate from @Start_Date through @End_date, as we insert rows into our calendar table.

From this point on, we enter a loop, assign values to the variables, and then insert a row into Dim_Date. The following are all of these calculations, along with a description of what they mean:

1
2
3
4
5
6
7
8
9
	
 
SELECT @Calendar_Month = DATEPART(MONTH, @Date_Counter);
SELECT @Calendar_Day = DATEPART(DAY, @Date_Counter);
SELECT @Calendar_Year = DATEPART(YEAR, @Date_Counter);
SELECT @Calendar_Quarter = DATEPART(QUARTER, @Date_Counter);
SELECT @Day_of_Week = DATEPART(WEEKDAY, @Date_Counter);
SELECT @Day_of_Year = DATEPART(DAYOFYEAR, @Date_Counter);
SELECT @Week_of_Year = DATEPART(WEEK, @Date_Counter);
 

These seven variables all represent date parts and can be captured using DATEPART and some simple TSQL. Once we have these values, we can derive additional information about the date:

1
2
3
4
	
 
SELECT @Calendar_Date_String = CAST(@Calendar_Month AS VARCHAR(10)) + '/' + CAST(@Calendar_Day 
AS VARCHAR(10)) + '/' + CAST(@Calendar_Year AS VARCHAR(10));
 

Capturing a string version of the date is handy for quick & reliable display in a specific format. The format MM/DD/YYYY is used above, but could very easily be tinkered with in order to display using other orderings or delimiters. CONVERT may be also used to format the date in a variety of forms. For example, consider the following TSQL:

1
2
3
4
5
6
7
	
 
SELECT CONVERT(VARCHAR(25), CURRENT_TIMESTAMP, 101);
SELECT CONVERT(VARCHAR(25), CURRENT_TIMESTAMP, 102);
SELECT CONVERT(VARCHAR(25), CURRENT_TIMESTAMP, 103);
SELECT CONVERT(VARCHAR(25), CURRENT_TIMESTAMP, 10);
SELECT CONVERT(VARCHAR(25), CURRENT_TIMESTAMP, 107);
 

The results show a bunch of ways that we can take a date and reformat it based on local, international, or stylistic formats:

1
2
3
4
5
6
7
8
	
 
SELECT @Is_Weekday = CASE
				WHEN @Day_of_Week IN (1, 7)
					THEN 0
				ELSE 1
			END;
SELECT @Is_Business_Day =	@Is_Weekday;
 

Weekdays are defined here as all days of the week except Saturday & Sunday (the weekend). In some countries or businesses, this may be defined differently, and can easily be tweaked for those purposes. Business days will be defined as all weekdays that are also not holidays. We will handle holidays near the end of our stored procedure, but will set this equal to @Is_Weekday for now, as a convenience for our future calculations where we will set this equal to zero for any holidays identified.

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
	
 
SELECT @Day_Name = CASE @Day_of_Week
					WHEN 1 THEN 'Sunday'
					WHEN 2 THEN 'Monday'
					WHEN 3 THEN 'Tuesday'
					WHEN 4 THEN 'Wednesday'
					WHEN 5 THEN 'Thursday'
					WHEN 6 THEN 'Friday'
					WHEN 7 THEN 'Saturday'
				END;
 
SELECT @Month_Name = CASE @Calendar_Month
					WHEN 1 THEN 'January'
					WHEN 2 THEN 'February'
					WHEN 3 THEN 'March'
					WHEN 4 THEN 'April'
					WHEN 5 THEN 'May'
					WHEN 6 THEN 'June'
					WHEN 7 THEN 'July'
					WHEN 8 THEN 'August'
					WHEN 9 THEN 'September'
					WHEN 10 THEN 'October'
					WHEN 11 THEN 'November'
					WHEN 12 THEN 'December'
				END;
 

Month and day names are provided as a convenience and can be pulled in order to quickly display date-related strings in a variety of formats.

1
2
3
4
5
6
	
 
SELECT @Day_of_Quarter = DATEDIFF(DAY, DATEADD(QUARTER, DATEDIFF(QUARTER, 0 , @Date_Counter), 0), @Date_Counter) + 1;
SELECT @Day_of_Year = DATEPART(DAYOFYEAR, @Date_Counter);
SELECT @Week_of_Month = DATEDIFF(WEEK, DATEADD(WEEK, DATEDIFF(WEEK, 0, DATEADD(MONTH, DATEDIFF(MONTH, 0, @Date_Counter), 0)), 0), @Date_Counter ) + 1;
SELECT @Week_of_Quarter = DATEDIFF(DAY, DATEADD(QUARTER, DATEDIFF(QUARTER, 0, @Date_Counter), 0), @Date_Counter)/7 + 1;
 

These statements perform a bit of more complex date math in order to determine the position of the date within its month, quarter, or year. The basis of these calculations is to calculate the start of a given year, week, or month, and then subtract the days or weeks from that point in time and the date being calculated. To emphasize the results, though, and their relative simplicity, the following TSQL results show the date, day of week, and day of week within the month for the start of 2017:

The results show that we are starting at the beginning of the month and breaking it into sets of seven. The same pattern holds true for the quarterly and yearly metrics.

1
2
3
4
5
6
7
8
9
10
	
 
SELECT @First_Date_of_Week = DATEADD(DAY, -1 * @Day_of_Week + 1, @Date_Counter);
SELECT @Last_Date_of_Week = DATEADD(DAY, 1 * (7 - @Day_of_Week), @Date_Counter);
SELECT @First_Date_of_Month = DATEADD(DAY, -1 * DATEPART(DAY, @Date_Counter) + 1, @Date_Counter);
SELECT @Last_Date_of_Month = EOMONTH(@Date_Counter);
SELECT @First_Date_of_Quarter = DATEADD(QUARTER, DATEDIFF(QUARTER, 0, @Date_Counter), 0);
SELECT @Last_Date_of_Quarter = DATEADD (DAY, -1, DATEADD(QUARTER, DATEDIFF(QUARTER, 0, @Date_Counter) + 1, 0));
SELECT @First_Date_of_Year = DATEADD(YEAR, DATEDIFF(YEAR, 0, @Date_Counter), 0);
SELECT @Last_Date_of_Year = DATEADD(DAY, -1, DATEADD(YEAR, DATEDIFF(YEAR, 0, @Date_Counter) + 1, 0));
 

Determining the first and last dates in a given week, month, quarter, or year are similar calculations to positions in time. To figure out the first date in a period, we determine how far into the period we are and subtract that number of days. To determine the last date in a period, we do the opposite, subtracting the current date position from the period length. @Last_Date_of_Month can be determined with a built-in function, EOMONTH, which saves us a bit of work on that calculation.

1
2
3
4
5
	
 
SELECT @Day_of_Week_in_Month = (@Calendar_Day + 6) / 7;
SELECT @Day_of_Week_in_Year = (@Day_of_Year + 6) / 7;
SELECT @Day_of_Week_in_Quarter = (@Day_of_Quarter + 6) / 7;
 

We can figure out the count of how many given days have occurred up to (and including) the date in question by taking the day number in the period, “rounding up” and dividing by seven (without a remainder). This breaks the period into weekly chunks, allowing us to understand where in the total period the current date falls.

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
	
 
SELECT @Is_Leap_Year = CASE
					WHEN @Calendar_Year % 4 <> 0 THEN 0
					WHEN @Calendar_Year % 100 <> 0 THEN 1
					WHEN @Calendar_Year % 400 <> 0 THEN 0
					ELSE 1
				END;
 
SELECT @Days_in_Month = CASE
					WHEN @Calendar_Month IN (4, 6, 9, 11) THEN 30				
                                        WHEN @Calendar_Month IN (1, 3, 5, 7, 8, 10, 12) THEN 31
					WHEN @Calendar_Month = 2 AND @Is_Leap_Year = 1 THEN 29
					ELSE 28
				END;
 

The first BIT column determines if it is a leap year, which can help in knowing how many days are in the year, are in February, or if a leap year child actually gets a birthday in a given year. The second column uses the calendar month and that leap year bit to determine the number of days in the month, which prevents the need to figure it out later.

What is Next?

At this point we have defined all of the data elements we are looking for that can easily be determined up front, picked out data types, and completed those calculations. If you have any additional metrics to add, this is the place to do it. The process to do so is simple:

Add a new column to Dim_Date
Create a new local variable for the metric to be added.
Add a new calculation to assign the appropriate value into that variable.

Likewise, removing a column is the opposite process: Remove the column in Dim_Date, the local variable, and the subsequent calculation.

Our next steps are:

Turn the variables above into a row that we insert into Dim_Date.
Use set-based calculations to add holiday metrics to our data.
Run tests of the stored procedure in order to validate the results.
Conclusion

Calendar tables are extremely useful in any reporting, analytics, or even OLTP use case in which we need to frequently join data on data-related attributes. Not only can they greatly improve performance, but they simplify our code and allow reporting engines to consume that data with ease. As a bonus, we gain maintainability as we can retain a single copy of calendar data in one place. This reduces the likelihood of coding mistakes when operating on date data, especially when the calculations are complex.

Design a calendar table based on the needs of your application and add, remove, or adjust columns as needed. The metrics that matter most to one industry may be irrelevant to another. Completeness is key when creating a structure such as this, though. Consider what metrics you will need, both now and in the future. Also consider how much data you’ll need. Determine the minimum and maximum dates you’re going to need, and be ready to add or remove any when business needs change.

Flexibility, performance, and maintainability are the primary gains to be had when using a calendar table. If you think of any interesting ideas that have not been mentioned here, feel free to share!

Next articles in this series:

Implementing and Using Calendar Tables
Implementing Different Calendars in Reporting
References and Further Reading
This provides a complete list of date-related data types and functions, which can be used for generating date dimensions: Date and Time Data Types and Functions (Transact-SQL)
Some notes on calendar use in SSAS 2016 and later: Create a Date type Dimension
Details on all of SQL Server’s data types. Consider the smallest data type that fully covers a given use case. This saves space and improves performance! Data Types (Transact-SQL)
This is a link to the reference for all DATE formats, which is very helpful for determining how to quickly turn a date data type into a string without the need to pull it apart and reconstruct it from scratch. CAST and CONVERT (Transact-SQL)

Always check your results and make sure that calendar data is correct. It’s easy to update and replace, so do not hesitate to apply sufficient scrutiny as this data is intended to be used in many places.

See more

To boost SQL coding productivity, check out these SQL tools for SSMS and Visual Studio including T-SQL formatting, refactoring, auto-complete, text and data search, snippets and auto-replacements, SQL code and object comparison, multi-db script comparison, object decryption and more

 




Ed Pollack
Ed has 20 years of experience in database and systems administration, developing a passion for performance optimization, database design, and making things go faster.He has spoken at many SQL Saturdays, 24 Hours of PASS, and PASS Summit.This lead him to organize SQL Saturday Albany, which has become an annual event for New York’s Capital Region.

In his free time, Ed enjoys video games, sci-fi & fantasy, traveling, and being as big of a geek as his friends will tolerate.

View all posts by Ed Pollack
Related Posts:
Implementing Different Calendars in Reporting
SQL Server and BI – Creating a query for the revenue projection
Implementing and Using Calendar Tables
Generating Schedules with SQL Server Agent
DATEPART SQL function
General database design
102,411 Views
Newsletter
Follow us!

Popular
Different ways to SQL delete duplicate rows from a SQL Table
SQL Convert Date functions and formats
SQL PARTITION BY Clause overview
How to UPDATE from a SELECT statement in SQL Server
SQL WHILE loop with simple examples
Learn SQL: Join multiple tables
SQL Variables: Basics and usage
SQL Server table hints – WITH (NOLOCK) best practices
How to backup and restore MySQL databases using the mysqldump command
CASE statement in SQL
SQL multiple joins for beginners with examples
SQL Server functions for converting a String to a Date
What is the difference between Clustered and Non-Clustered Indexes in SQL Server?
SQL Not Equal Operator introduction and examples
The Table Variable in SQL Server
DELETE CASCADE and UPDATE CASCADE in SQL Server foreign key
Multiple options to transposing rows into columns
SQL Server Transaction Log Backup, Truncate and Shrink Operations
How to implement error handling in SQL Server
INSERT INTO SELECT statement overview and examples

Trending
SQL Server Transaction Log Backup, Truncate and Shrink Operations
Six different methods to copy tables between databases in SQL Server
How to implement error handling in SQL Server
Working with the SQL Server command line (sqlcmd)
Methods to avoid the SQL divide by zero error
Query optimization techniques in SQL Server: tips and tricks
How to create and configure a linked server in SQL Server Management Studio
SQL replace: How to replace ASCII special characters in SQL Server
How to identify slow running queries in SQL Server
SQL varchar data type deep dive
How to implement array-like functionality in SQL Server
All about locking in SQL Server
SQL Server stored procedures for beginners
Database table partitioning in SQL Server
How to drop temp tables in SQL Server
How to determine free space and file size for SQL Server databases
Using PowerShell to split a string into an array
KILL SPID command in SQL Server
How to install SQL Server Express edition
SQL Union overview, usage and examples

Solutions
Read a SQL Server transaction log
SQL Server database auditing techniques
How to recover SQL Server data from accidental UPDATE and DELETE operations
How to quickly search for SQL database data and objects
Synchronize SQL Server databases in different remote sources
Recover SQL data from a dropped table without backups
How to restore specific table(s) from a SQL Server database backup
Recover deleted SQL data from transaction logs
How to recover SQL Server data from accidental updates without backups
Automatically compare and synchronize SQL Server data
Open LDF file and view LDF file content
Quickly convert SQL code to language-specific client code
How to recover a single table from a SQL Server database backup
Recover data lost due to a TRUNCATE operation without backups
How to recover SQL Server data from accidental DELETE, TRUNCATE and DROP operations
Reverting your SQL Server database back to a specific point in time
How to create SSIS package documentation
Migrate a SQL Server database to a newer version of SQL Server
How to restore a SQL Server database backup to an older version of SQL Server
Categories and tips
►Auditing and compliance (50)
Azure (179)
Azure Data Studio (37)
Backup and restore (105)
►Business Intelligence (444)
Data science (21)
▼Database design (209)
Clustering (16)
Common Table Expressions (CTE) (10)
Concurrency (1)
Constraints (7)
Data types (10)
FILESTREAM (20)
General database design (92)
Partitioning (13)
Relationships and dependencies (12)
Temporal tables (12)
Views (16)
►Database development (372)
DBAtools (30)
DevOps (22)
DevSecOps (2)
Documentation (19)
ETL (56)
►Features (201)
Importing, exporting (45)
Installation, setup and configuration (103)
Jobs (41)
►Languages and coding (637)
Lists (12)
Machine learning (32)
Maintenance (92)
Migration (46)
Miscellaneous (1)
►Performance tuning (768)
►Professional development (57)
Recovery (32)
Security (81)
Server management (13)
SQL Azure (220)
SQL Server Management Studio (SSMS) (85)
SQL Server on Linux (9)
►SQL Server versions (161)
►Technologies (267)
Uncategorized (3)
Utilities (18)
Helpers and best practices
BI performance counters
SQL code smells rules
SQL Server wait types
﻿

© 2021 Quest Software Inc. ALL RIGHTS RESERVED.   |   GDPR   |   Terms of Use   |   Privacy

AddThis Sharing Sidebar]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Running a Next.js Site on Cloudflare Pages]]></title>
            <link>https://opstrace.com/blog/nextjs-on-cloudflare</link>
            <guid>https://opstrace.com/blog/nextjs-on-cloudflare</guid>
            <pubDate>Wed, 14 Jul 2021 19:57:09 GMT</pubDate>
            <content:encoded><![CDATA[Docs
Blog
Community
Contact us

Running a Next.js Site on Cloudflare Pages

Jul 14 | 11 min read

Patrick Heneise

Step by step tutorial on how to deploy your website on Cloudflare Pages

JAMstack Overflow

These days there are so many providers for JAMstack hosting, it's hard to choose. Netlify, GitHub Pages, Vercel, Heroku, ... the New Dynamic has a list of over 30 different hosting/deployment tools, with new ones being added regularly. However, the new kid in town caught our attention: Cloudflare Pages. They have only been around for a few months now, but since we already use Cloudflare for DNS and CDN, consolidating tools could be a nice win.

Cloudflare Pages radically simplifies the process of developing and deploying sites by taking care of all the tedious parts of web development. Now, developers can focus on the fun and creative parts instead. – https://blog.cloudflare.com/cloudflare-pages-ga/

Next.js on Cloudflare

Given they're just starting up, the features are still a bit limited. One of the biggest drawbacks as of this moment is the lack of a server to generate dynamic content. Currently, Cloudflare uses the Next.js static HTML export to prerender all pages to plain html. Given we don't use any server-side rendering capabilities at the moment, this was good enough to move forward now, but we are also excited to see the further development of Cloudflare Pages.

Getting started

Let's create a project:

Assuming you have a Next.js website and both next build and next export run through without any errors (you'll probably see an error when using next/image, we'll get to that in a moment), make sure everything is committed and pushed to a repository. In addition, make sure you create alias scripts in package.json for build and export:

"build": "next build",
"export": "next export",

This is necessary to run post-build scripts to generate additional content such as a sitemap.xml, robots.txt, RSS/Atom feeds etc.

Log in to your Cloudflare Dashboard and head to "Pages" on the right. "Create a project" and connect to your repository.

When you're in the build configuration section, they offer "Next.js (Static Export)" as a framework preset, but since this preset uses next commands by default, pre/post build hooks from our package.json are ignored. Instead, do not select a preset and configure the build options manually. The Cloudflare "build command" should be:

npm run build && npm run export
# or
# yarn build && yarn export

Similarly, the static files will be exported to a directory called out, so set the "build output directory" field to this. Your input should look like this:

Once saved, Pages will automatically initiate the first build. Once the build is successful, you can then head to the *.pages.dev URL that will be shown at the top of the page. In a Pull Request, Cloudflare comments the build status and preview url.

If you are already using Cloudflare DNS, you can connect your custom domain in the next step—Cloudflare will automatically generate the CNAME for you with a click on the "activate domain" button:

Congratulations, you're now running your Next.js site on Cloudflare Pages! Now, the fine print.

Images
The Problem

If you switched to the new next/image component in Next.js 11, you'll see the following warning during export:

Error: Image Optimization using Next.js' default loader is not compatible with `next export`.
  Possible solutions:
    - Use `next start` to run a server, which includes the Image Optimization API.
    - Use any provider which supports Image Optimization (like Vercel).
    - Configure a third-party loader in `next.config.js`.
    - Use the `loader` prop for `next/image`.
  Read more: https://nextjs.org/docs/messages/export-image-api

Since we want to do image optimization and we don't want any new tools, we've decided to look at another Clouflare option—a Cloudflare Worker.

Create a Worker

To create one in your Cloudflare Dashboard, go to "Workers" > "Create a Worker". Cloudflare Docs has an entire article about Resizing Images with Cloudflare Workers, and prepared the script for you to copy into the {} Script box:

// https://developers.cloudflare.com/images/resizing-with-workers
addEventListener('fetch', (event) => {
  event.respondWith(handleRequest(event.request))
})
async function handleRequest(request) {
  let url = new URL(request.url)
  let options = { cf: { image: {} } }
  if (url.searchParams.has('fit'))
    options.cf.image.fit = url.searchParams.get('fit')
  if (url.searchParams.has('width'))
    options.cf.image.width = url.searchParams.get('width')
  if (url.searchParams.has('height'))
    options.cf.image.height = url.searchParams.get('height')
  if (url.searchParams.has('quality'))
    options.cf.image.quality = url.searchParams.get('quality')
  const imageURL = url.searchParams.get('image')
  const imageRequest = new Request(imageURL, {
    headers: request.headers
  })
  return fetch(imageRequest, options)
}

In the top right, you can change the name of the worker. Once saved, note down the URL, we'll need that.

Configure the Loader

As the error gives us possible solutions, unfortunately we can't "Configure a third-party loader in next.config.js." - there is a small list of pre-existing loaders, but Cloudflare isn't one of them and they're no longer adding new default loaders. So we're using the loader prop for 'next/image':

// replace [yourprojectname] and [yourdomain.com] with your actual project name and (custom) domain
const cloudflareImageLoader = ({ src, width, quality }) => {
  if (!quality) {
    quality = 75
  }
  return `https://images.[yourprojectname].workers.dev?width=${width}&quality=${quality}&image=https://[yourdomain.com]${src}`
}

And the <Image>:

const MyImage = (props) => {
  return (
    <Image
      loader={cloudflareImageLoader}
      src="me.png"
      alt="Picture of the author"
      width={500}
      height={500}
    />
  )
}

This would be too cumbersome to add this loader to every single <Image> tag you have in your project. So we created a custom Image component (/components/Image.jsx):

import Image from 'next/image'


// replace [yourprojectname] and [yourdomain.com] with your actual project name and (custom) domain
const cloudflareImageLoader = ({ src, width, quality }) => {
  if (!quality) {
    quality = 75
  }
  return `https://images.[yourprojectname].workers.dev?width=${width}&quality=${quality}&image=https://[yourdomain.com]${src}`
}


export default function Img(props) {
  if (process.env.NODE_ENV === 'development') {
    return <Image unoptimized={true} {...props} />
  } else {
    return <Image {...props} loader={cloudflareImageLoader} />
  }
}
Node 16 Hiccup

If you're running on Node 16, you may already have had issues with Images on Next.js, and because we don't need image optimziation during development, we've removed the loader and added unoptimized={true} for the development environment.

Now you can search/replace all import Image from next/image to import Image from components/Image. To resolve the import path components/Image, you need to add a jsconfig.json to your project so that components/Image will resolve to ./src/components/Image:

{
  "compilerOptions": {
    "baseUrl": "."
  }
}

Once you've done all that, you'll probably still see the same error during next export, so let's add a fake third-party loader into next.config.js (this fake loader will not be used—it's just a hack to avoid the build error):

images: {
  loader: 'imgix',
  path: ''
},

npm run export should now run successfully without any errors!

Previews

Cloudflare Pages also offer a GitHub integration that provides Pull Request previews, posting a comment to each Pull Request with the deployment status, which is extremely useful. (Other services provide this as well, for example, Vercel.)

However, one thing that was missing: a direct link out to the preview. In order to retrieve the preview URL, we built a GitHub Action Cloudflare Preview URL that waits for the deployment to be ready and then returns the URL. This is useful to run E2E tests, URL link checks etc. on a real website before going live.

There's room for improvement though:

build times are still very long (2+ minutes to initialize the build environment).
more flexibility with environment and build variables to expose system/build related information in user-defined variables.
use of the GitHub Deployments API, which fires an event when a deployment is ready, instead of polling the Cloudflare API.
Sitemap

You can use next-sitemap to generate a sitemap for all your pages automatically after build. Follow the README and add the next-sitemap.js as well as the post-build hook. This works out of the box with static site generation and the sitemap.xml and robots.txt will be copied into the export (/out) folder during npm run export. You should add both files to .gitignore to prevent them being added to the repository.

RSS Feeds

If you publish regularly and you want to give your audience a way to subscribe to your blog, RSS/Atom is the standard format for that. Most tutorials you'll find about RSS generation require server-side rendering from your dynamic content, though. But we can also solve this with a post build hook.

First, we need a script to generate the feed from our articles. We put this in utils/generate-rss.js. We use feed to help generate the XML and JSON files for RSS and Atom.

import fs from 'fs'
import { Feed } from 'feed'
import getPosts from 'utils/getPosts'


// site.js exports the default site variables, such as the link, default image, favicon, etc
import meta from 'content/site.js'


async function generate() {
  const feed = new Feed({
    title: meta.title,
    description: meta.description,
    image: meta.image,
    favicon: meta.favicon,
    copyright: meta.copyright,
    language: meta.language,
    link: meta.link,
    id: meta.link,
    feedLinks: {
      json: `${meta.link}feed.json`,
      rss2: `${meta.link}feed.xml`,
      atom: `${meta.link}atom.xml`
    }
  })


  // we store blog articles in content/articles/article.mdx
  // you can change the path and regex here for your project.
  const posts = ((context) => {
    return getPosts(context)
  })(require.context('content/articles', true, /\.\/.*\.mdx$/))


  posts.forEach((post) => {
    feed.addItem({
      title: post.title,
      id: `${meta.link}${post.slug}`,
      link: `${meta.link}${post.slug}`,
      date: new Date(post.date),
      description: post.description,
      image: `${meta.link}${post.featuredImage.src}`
    })
  })


  fs.writeFileSync('./public/feed.xml', feed.rss2())
  fs.writeFileSync('./public/feed.json', feed.json1())
  fs.writeFileSync('./public/atom.xml', feed.atom1())
}


generate()

This is a little tricky. As you can see we're using require.context which isn't available outside the Next/Webpack environment. We're using a modified webpack config in next.config.js to compile the script and put it into the build directory:

webpack: function (config, { dev, isServer }) {
  if (!dev && isServer) {
    const originalEntry = config.entry


    config.entry = async () => {
      const entries = { ...(await originalEntry()) }
      entries['utils/generate-rss.js'] = 'utils/generate-rss.js'
      return entries
    }
  }
  return config
}

Finally, we'll need to run the script after build (another post-build hook). In order to run this in parallel with the sitemap generation and keep everything neat and tidy, we're using npm-run-all:

"export": "next export",
"build": "next build",
"postbuild": "run-p generate:sitemap generate:rss",
"generate:rss": "node ./.next/server/utils/generate-rss.js.js",
"generate:sitemap": "next-sitemap",

You can now add the feeds into your _document.js <Head>:

<Html lang="en">
  <Head>
    ...
    <link
      rel="alternate"
      type="application/rss+xml"
      title="Opstrace RSS2 Feed"
      href="https://opstrace.com/feed.xml"
    />
    <link
      rel="alternate"
      type="application/atom+xml"
      title="Opstrace Atom Feed"
      href="https://opstrace.com/atom.xml"
    />
    <link
      rel="alternate"
      type="application/json"
      title="Opstrace JSON Feed"
      href="https://opstrace.com/feed.json"
    />
    ...
  </Head>
  <body>
    <Main />
    <NextScript />
  </body>
</Html>
Conclusion

Getting a first build on Cloudflare is incredibly easy, fast and convenient. Give Cloudflare permission for your repo, build, deploy—done. And it's free. If you use them for DNS, no manual DNS changes need to be made because Cloudflare does that for you. As they're feeding your site directly into their incredibly powerful content delivery network (CDN), you can expect the best load performance available.

With Cloudflare you also get some decent Account Analytics out of the box without any tracking snippets. (Also, script blockers cannot side-step this tracking.) They've also recently added Web Analytics. Overall it's a great offer for JAMstack sites and reduces the need for yet another tool to log in to and maintain.

Preparing Next.js was a little bit of work, but there were no serious blockers that prevented us from deploying with and hosting on Cloudflare Pages. We're now experimenting with Cloudflare Workers and Google Cloud Functions to add some server-side capabilities to our site, for example to collect feedback or handle our Stripe subscriptions. There are a few known convenience features missing from the build environment, but Cloudflare will probably add those soon. And maybe they'll even support Server-Side Rendering (SSR) capabilities for Next.js sites, too.

Acknowledgements & Special Thanks
to Jean-Philippe Monette for feed
to Vishnu Sankar for next-sitemap
to Ian Mitchell for the article on generating rss feeds for static blogs

Follow Opstrace on...

Twitter
GitHub
LinkedIn
Slack
RSS Feed
Sign up for updates as we grow
Email address

We won't share your information with anyone

The Open Source Observability Distribution

Company
Contact us
Blog
Product
Open Source on GitHub
Roadmap
Resources
Docs
In the Media

© 2021 Opstrace, Inc.

Privacy Policy
Terms of Service
Trademark Policy
Website Data Collection Preferences]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Inline::C for Tcl]]></title>
            <link>https://wiki.tcl-lang.org/page/Inline%3A%3AC+for+Tcl</link>
            <guid>https://wiki.tcl-lang.org/page/Inline%3A%3AC+for+Tcl</guid>
            <pubDate>Wed, 14 Jul 2021 19:57:07 GMT</pubDate>
            <content:encoded><![CDATA[ Tcler's Wiki
Page
Tutorial
Articles
 Help
User
Inline::C for Tcl

Dossy wrote to the ActiveTcl mailing list in 2003:

Hi,

If there's already a project to bring Inline::C capability to Tcl, please point me at it. Otherwise, perhaps this could be the start of one.

For those unfamiliar with what Inline::C is, it is a Perl module that allows you to embed C code within your Perl program -- for more information, look here:

    http://search.cpan.org/author/INGY/Inline-0.44/C/C.pod

Now, tonight, I got to thinking: gee, it'd be nice to have something like this for Tcl. After giving it the "good ol' college try" (you know, I Googled two or three times and nothing came up) I couldn't find an implementation of Inline::C for Tcl. So, I said to myself: Tcl is awesome -- it shouldn't take me more than a minute or two to get a bare minimum snippet of Tcl code working that does what I want.

So, here is my first whack at Inline::C for Tcl: [L1 ]

Again, if such a thing already exists, pointers would be appreciated. Otherwise, perhaps if others find this useful, we can get this added to Tcllib or it can stand on its own. I don't care either way.

-- Dossy

Critcl and tcc4tcl do this and a lot more, but at 50 lines Dossy's code is worth preserving as an illustration of how simple it can be.

Note that this is pure Tcl code, except the call to exec gcc. It assumes that your system is configured so GCC will see the correct Tcl headers.

#
# $Id: inline.tcl,v 1.1.1.1 2003/08/24 04:23:14 dossy Exp $
#

package require Tcl 8

namespace eval ::inline {
    ### Do I need anything here?
}

proc ::inline::c {procName body} {
    set fd [open /tmp/inline-c.c w]

    puts $fd [subst {
#include <tcl.h>

int
${procName}ObjCmd(clientData, interp, objc, objv)
ClientData clientData;
Tcl_Interp *interp;
int objc;
Tcl_Obj *CONST objv[];
{
    $body
}

int
[string totitle $procName]_Init(interp)
Tcl_Interp *interp;
{
    Tcl_CreateObjCommand(interp, "$procName", ${procName}ObjCmd, NULL, NULL);
    return TCL_OK;
}
    }]

    close $fd

    ### FIXME: Platform-dependent.  Needs error checking, too.
    exec gcc -shared -o /tmp/inline-c.so /tmp/inline-c.c

    load /tmp/inline-c.so $procName

    file delete /tmp/inline-c.c /tmp/inline-c.so
}

package provide inline 1.0

And a test program:

    package require inline

    ::inline::c hello {
        Tcl_SetResult(interp, "Hello, world.", TCL_VOLATILE);
        return TCL_OK;
    }

    puts [hello]
Category Package	Category Example	extension
Updated 2021-07-14 19:29:11]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[How WhatsApp enables multi-device capability - Facebook Engineering]]></title>
            <link>https://engineering.fb.com/2021/07/14/security/whatsapp-multi-device/</link>
            <guid>https://engineering.fb.com/2021/07/14/security/whatsapp-multi-device/</guid>
            <pubDate>Wed, 14 Jul 2021 19:57:05 GMT</pubDate>
            <content:encoded><![CDATA[Skip to content
Search this site
POSTED ON JULY 14, 2021 TO SECURITY
How WhatsApp enables multi-device capability

For years, people have been asking us to create a true multi-device experience that allows people to use WhatsApp on other devices without requiring a smartphone connection.

Today, we’re announcing the rollout of a limited public beta test for WhatsApp’s updated multi-device capability. 

With this new capability, you can now use WhatsApp on your phone and up to four other nonphone devices simultaneously — even if your phone battery is dead. Each companion device will connect to your WhatsApp independently while maintaining the same level of privacy and security through end-to-end encryption that people who use WhatsApp have come to expect. Importantly, we have developed new technologies to maintain end-to-end encryption while still managing to sync your data — such as contact names, chat archives, starred messages, and more — across devices.

To achieve this, we had to rethink WhatsApp’s architecture and design new systems to enable a standalone multi-device experience while preserving privacy and end-to-end encryption. 

Taking smartphones out of the equation

The current WhatsApp experience for companion devices on web, macOS, Windows, and Portal uses a smartphone app as the primary device, making the phone the source of truth for all user data and the only device capable of encrypting or decrypting messages, initiating calls, etc. Companion devices maintain a persistent secure connection with the phone and simply mirror its contents on their own UI. 

This architecture makes it easy to deliver a seamlessly synchronized experience between a phone and companion device without compromising on security. However, it comes with some significant reliability trade-offs: By requiring the phone to perform all operations, companion devices are slower and frequently get disconnected — especially when the phone has a poor connection, its battery is running low, or the application process gets killed by the phone’s OS. It also allows for only a single companion device to be operative at a time, meaning people can’t be on a call in Portal while checking their messages on their PC, for example. 

The new WhatsApp multi-device architecture removes these hurdles, no longer requiring a smartphone to be the source of truth while still keeping user data seamlessly and securely synchronized and private.

The challenge in accomplishing this was in maintaining the secure user experience across devices without having to store people’s private messages on our servers in new ways.

Meeting the security challenges of multiple devices

Prior to our introducing multi-device, everyone on WhatsApp was identified by a single identity key from which all encrypted communication keys were derived. With multi-device, each device now has its own identity key.

The WhatsApp server maintains a mapping between each person’s account and all their device identities. When someone wants to send a message, they get their device list keys from the server.  

We have also addressed the challenge of preventing a malicious or compromised server from eavesdropping on someone’s communications by surreptitiously adding devices to someone’s account. We use a combination of technologies to solve this: First, we have extended security codes to now represent the combination of all of someone’s device identities so that anyone and their contact can always verify all the devices they are sending messages to. 

Second, in order to reduce the number of times that someone needs to perform identity verifications, we have developed and will roll out a technology called Automatic Device Verification. This system allows for devices to automatically establish trust between each other in a way that someone needs to compare another user’s security code only if that user reregisters their entire account, rather than each time they link a new device to their account. 

Finally, we also give people additional control and protections over which devices are linked to their account. First, everyone will continue to be required to link new companion devices by scanning a QR code from their phone. This process now requires biometric authentication before linking where people have enabled this feature on compatible devices. Finally, people will be able to see all the companion devices linked to their account as well as when they were last used, and will be able to log out of them remotely if needed. 

Maintaining message privacy

When people message each other in a one-on-one chat, a pairwise encrypted session is established between each of the sender’s and recipient’s devices. WhatsApp multi-device uses a client-fanout approach, where the WhatsApp client sending the message encrypts and transmits it N number of times to N number of different devices — those in the sender and receiver’s device lists. Each message is individually encrypted using the established pairwise encryption session with each device. Messages are not stored on the server after they are delivered. For groups, we still use the same scalable Sender Key encryption scheme from the Signal Protocol.

WhatsApp’s legacy architecture used a smartphone as the source of truth. But with the new multi-device capability, up to four other nonphone companion devices can connect to WhatsApp independently while still maintaining the same level of privacy and security.

Adapting voice and video protocols for multi-device, end-to-end encryption  

When someone on WhatsApp makes a voice or video call:


The initiator generates a set of random 32-byte SRTP master secrets for each of the recipient’s devices.

The initiator sends an incoming call message (using the client-fanout approach described above) to each of the devices of the recipient. Each recipient’s device receives this message, which contains the encrypted SRTP master secret.
If the responder answers the call from one of the devices, a SRTP encrypted call is started, protected by the SRTP master secret generated for that device.

The SRTP master secret persists in memory on the client device and is used only during the call. Our servers do not have access to the SRTP master secrets.

For group calls, the server randomly selects a participant device that is in the call (either the initiator or a device on which a user has accepted the call) to generate the SRTP master secret. That device generates the secret and sends it to other active participant devices through pairwise end-to-end encryption. This process is repeated, and the keys are reset whenever someone joins or leaves the call.

Keeping message history and other application states in sync across devices

We want to ensure that people have a consistent experience with WhatsApp no matter the device they are using. To achieve this, we synchronize message history as well as other application state data (such as contact names, whether a chat is archived, or if a message is starred) across devices. All of this data is synchronized and end-to-end encrypted between your devices.

For message history: When a companion device is linked, the primary device encrypts a bundle of the messages from recent chats and transfers them to the newly linked device. The key to this encrypted message history blob is delivered to the newly linked device via an end-to-end encrypted message. After the companion device downloads, decrypts, unpacks, and stores the messages securely, the keys are deleted. From that point forward, the companion device accesses the message history from its own local database.

Other application data requires more than an initial transfer from the phone. We also need an ongoing synchronization every time someone modifies their application state (e.g., when they add a new contact, mute a chat, or star a message).

To solve this, the WhatsApp server securely stores a copy of each application state that all of someone’s devices can access. To properly secure this, all the information, and even the metadata about the information (what kind of user data is stored or accessed), is end-to-end encrypted with constantly changing keys known only to that person’s devices. 

How to try WhatsApp multi-device beta 

We plan to initially test the experience with a small group of users from our existing beta program. We will continue optimizing performance and adding a few additional features before slowly rolling it out more broadly. Those who opt in can always opt back out.

For more information about the beta and to sign up, visit the WhatsApp Help Center.

For more information about WhatsApp multi-device, read our updated whitepaper.

TAGS:      WHATSAPP
Prev
Enforcing encryption at scale
Read More in Security
View All 
APR 16, 2021
DIT — enabling de-identified data collection on WhatsApp
FEB 9, 2021
Minesweeper automates root cause analysis as a first-line defense against bugs
AUG 12, 2020
DELF: Safeguarding deletion correctness in online social networks
AUG 7, 2020
Pysa: An open source static analysis tool to detect and prevent security issues in Python code
JUL 21, 2020
Scalable data classification for security and privacy
DEC 13, 2019
Fighting Abuse @Scale 2019 recap
Related Posts
Apr 16, 2021
DIT — enabling de-identified data collection on WhatsApp
Mar 02, 2020
Project LightSpeed: Rewriting the Messenger codebase for a faster, smaller, and simpler messaging app
Jul 21, 2020
Scalable data classification for security and privacy
Related Positions
APAC Supply Chain Security Program Manager
SINGAPORE
Cloud Security Engineer
MENLO PARK, US
Privacy Program Manager, Technical Audit
AUSTIN, US
Privacy Program Manager, Technical Audit
MENLO PARK, US
Privacy Engineer, Red Team
MENLO PARK, US
See All Jobs
Facebook © 2021
About
Careers
Privacy
Cookies
Terms
Help

To help personalize content, tailor and measure ads, and provide a safer experience, we use cookies. By clicking or navigating the site, you agree to allow our collection of information on and off Facebook through cookies. Learn more, including about available controls: Cookies Policy

I Agree]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Schrodingers Coin - Grant Williams]]></title>
            <link>https://www.grant-williams.com/download/</link>
            <guid>https://www.grant-williams.com/download/</guid>
            <pubDate>Wed, 14 Jul 2021 19:57:04 GMT</pubDate>
            <content:encoded><![CDATA[Skip to content
FOLLOW @TTMYGH
EXPLORE
Podcast
Newsletters
Hmmminars
About Grant Williams
Login
Subscribe
ABOUT
Contact
Terms & Conditions
Privacy
Cookie Policy

Copyright © 2021 – TTMYGH SEZC

By continuing to use this website, you consent to the use of cookies in accordance with our Cookie Policy.

ACCEPT
SCHRODINGER'S COIN

Download a free copy of the June 2021 edition of Things That Make You Go Hmmm…, Schrodinger’s Coin as a companion piece to the Tether podcast discussion featuring Bennett Tomlin & George Noble:

Email
 I agree with the Terms & Conditions and Privacy Policy.
READ NOW]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[What are the widest and narrowest residential streets in San Francisco?]]></title>
            <link>https://www.sfchronicle.com/projects/2021/street-widths/</link>
            <guid>https://www.sfchronicle.com/projects/2021/street-widths/</guid>
            <pubDate>Wed, 14 Jul 2021 19:57:00 GMT</pubDate>
            <content:encoded><![CDATA[SPECIAL REPORT
What are the widest and narrowest residential streets in San Francisco?
By NAMI SUMIDA | July 14, 2021 4:00 a.m.
Carlos Avila Gonzalez and Guy Wathen / The Chronicle

A
t 14 feet wide, Chula Lane in the Mission District is one of the narrowest residential streets in San Francisco — barely wide enough for a single car to pass. At the other end of the spectrum is Parker Avenue. Running north and south along the east side of the Richmond District, it has an average width of 93 feet — enough for two car lanes, on-street parking on both sides of the street and sidewalks as wide as the car lanes.

That’s according to data on street widths from Adam Millard-Ball, an associate professor at the University of California, Los Angeles. The data includes primarily residential streets, as categorized by OpenStreetMap, that are at least 100 yards long. Street dimensions are of the entire right-of-way, including the roadway, sidewalks and landscaping.

Millard-Ball’s research suggests that the narrowest and widest streets aren’t just fun trivia. It also matters for how many people can comfortably live in a city.

In his new paper, Millard-Ball compared a street’s width to the value of land used for the street to understand the economic tradeoff between using land for streets versus other purposes, like parks, houses and other infrastructure. In places experiencing housing shortages, like San Francisco, wide streets take up land that could be used to build more homes.

Median width of residential streets in San Francisco
A "street" includes the roadway, sidewalks and landscaping
© Mapbox © OpenStreetMap Improve this map
Median street width:
14 feet
100+ feet
Source: Adam Millard-Ball and OpenStreetMap

The average residential street in San Francisco is about 50 feet wide, according to Millard-Ball’s research, similar to other U.S. cities. This is in part because of federal regulations established in the 1930s that set a 50-foot minimum-width requirement for residential streets to qualify for Federal Housing Administration mortgage insurance. Since then, local regulations have established minimum-width requirements ranging from 40 to 60 feet.

Similar standards are still in place today. In San Francisco, minor streets excluding alleys must be at least 40 feet wide, with a minimum roadway width of 26 feet. Some exceptions are made based on an area’s topography or conservation plans, but must be approved by the city’s public works department.

According to Millard-Ball, 16 feet is considered the functional minimum width required for access on residential streets. For some city dwellers, that might seem too narrow, and raise concerns over congestion, reduced on-street parking and unsafe conditions for pedestrians and cyclists. But Millard-Ball notes that, on low-volume residential streets, these changes would affect few people, and previous research suggests that narrower streets actually reduce traffic speeds and lead to fewer accidents. Streets like Chula Lane, with segments narrower than 16 feet, show that it’s possible to build such narrow streets.

Chula Lane in the Mission District is one of the narrowest residential streets in San Francisco. Carlos Avila Gonzalez / The Chronicle

In contrast, streets in the Richmond and Sunset districts, neighborhoods developed later in the city’s history, are notably wide. Parker Avenue, Jordan Avenue, and Palm Avenue on the east edge of the Richmond District are all wider than 80 feet. That is valuable land, according to Millard-Ball. He estimates that every 25 feet of land along each avenue is worth hundreds of thousands of dollars.

Parker Avenue in the Richmond District is one of the widest residential streets in San Francisco, with an average width of over 90 feet. Carlos Avila Gonzalez / The Chronicle

Millard-Ball’s research finds that high-cost West Coast counties, like San Francisco and Santa Clara, are particularly harmed by using land for wide streets that could be devoted to other uses. Although there would be costs to narrowing streets, Millard-Ball thinks it would be worth the investment.

In Santa Clara County, where the average street width is 53 feet, Millard-Ball claims narrowing streets to 16 feet would lead to over $100,000 in additional land value along the average street. This land reclaimed from streets could be used for parks and conservation, or simply given to the homeowners on that street, increasing their wealth.

But the primary lesson is for places that are growing, says Millard-Ball. In new neighborhoods, planners could build narrower streets, saving land for developers to build more housing, such as duplexes instead of single-family homes.

For cities with less growth, like San Francisco, narrowing existing streets may be difficult. But the pandemic has shown that cities can adapt unused street spaces into outdoor dining parklets, slow streets, and other recreational spaces.

Average width of residential streets in San Francisco
The width of 1,134 residential streets that are at least 100 yards long. Measurements include the roadway, sidewalks and landscaping.
Source: Adam Millard-Ball and OpenStreetMap

ADVERTISEMENT

Get the Bay Area's best journalism delivered to my inbox daily

SIGN UP

This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service By subscribing, you agree to our Terms of Use and acknowledge that your information will be used as described in our Privacy Notice.

DATA DESK

This is how much single-family zoning is costing San Franciscans

Imports at the Port of Oakland are surging

Fireworks complaints blew up in 2020 in San Francisco

CREDITS

REPORTING

Nami Sumida • nami.sumida@sfchronicle.com  • @namisumida

EDITING

Dan Kopf • dan.kopf@sfchronicle.com  • @dkopf

VISUALS

Carlos Avila Gonzalez • cgonzalez@sfchronicle.com  • @CAGisMe

Guy Wathen • gwathen@sfchronicle.com  • @GuyWathen

Danielle Mollette-Parks • dparks@sfchronicle.com  • @daniellemparks

Nicole Fruge • nfruge@sfchronicle.com  • @photofruge

Homepage
TO TOP
ABOUT
Our Company
Newspaper Delivery Safety Procedures
Privacy Notice
Your California Privacy Rights
Interest Based Ads
Terms of Use
Careers
Advertising
NEWSROOM
Ethics Policy
Corrections Policy
Visual Ethics Guidelines
Anonymous Sources Policy
Endorsement Process
News Tips
CONTACT
Customer Service
FAQ
Newsroom Contacts
CCPA
Do Not Sell My Info
SERVICES
Subscriber Services
e-Edition
Reprints & Permissions
Corporate Subscriptions
App
Archives
Membership
Store
Subscription Offers
sfgate.com
©2021 Hearst]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Generate synthetic data and win a PS5!]]></title>
            <link>https://gretel.ai/gretel-beta-2-giveaway</link>
            <guid>https://gretel.ai/gretel-beta-2-giveaway</guid>
            <pubDate>Wed, 14 Jul 2021 19:56:56 GMT</pubDate>
            <content:encoded><![CDATA[Skip to main
Generate synthetic data with Gretel and win one of five Playstation 5s!
How to enter
1
Sign up for free using your Google or GitHub account.
2
Follow our tutorial to create and train your own synthetic data model.
3
Post a screenshot of your synthetic data quality score from your quality report to Twitter, LinkedIn, or our Gretel Community Slack and mention @gretel_ai. Use the hashtag #SaveDataSaveTheWorld

Finally, we can use all the help we can get to break through. It would make a huge impact if you could share the link to the Gretel console with colleagues and friends who are developers!

https://console.gretel.cloud
Copy
Product
Data Catalog
Synthetics
Transformation
Developers
Documentation
FAQs
Gretel Cloud
Gretel Synthetics
Company
About us
Team
Careers
(
WE'RE HIRING!
)
Blog
Media
Contact
Social
GitHub
Twitter
LinkedIn
YouTube
Slack Community
Legal
Privacy Policy
Terms of Service
Acceptable Use Policy
Responsible Disclosure
Copyright © 2021 Gretel Labs. All rights reserved.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Why Koko Couldn't Talk (Sorry) | The Deep Dive - YouTube]]></title>
            <link>https://www.youtube.com/watch?v=e7wFotDKEF4</link>
            <guid>https://www.youtube.com/watch?v=e7wFotDKEF4</guid>
            <pubDate>Wed, 14 Jul 2021 19:56:54 GMT</pubDate>
            <content:encoded><![CDATA[Amy's credit comeback
0:00 / 1:00]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[VDO.Ninja]]></title>
            <link>https://vdo.ninja/</link>
            <guid>https://vdo.ninja/</guid>
            <pubDate>Wed, 14 Jul 2021 19:56:52 GMT</pubDate>
            <content:encoded><![CDATA[VDO.Ninja  GO
Create a Room
 
Add your Camera to OBS
 
Remote Screenshare into OBS
 
Create Reusable Invite

What is VDO.Ninja


100% free; no downloads; no personal data collection; no sign-in
Bring live video from your smartphone, remote computer, or friends directly into OBS or other studio software.
We use cutting edge Peer-to-Peer forwarding technology that offers privacy and ultra-low latency


Youtube video  Demoing it here

Known issues:

Some devices that use H264 hardware encoding can experience video glitching; switching to VP8 or VP9 as a codec can help.
If using multiple group scenes at a time, iOS devices may fail to work if the hardware encoders max out. Perhaps try VP8 as a codec instead.
A list of less common issues can be found here.


👋 👀 Welcome to VDO Ninja! We've rebranded! 📼 Nothing else is changing and we're staying 100% free.

🌻 Site Updated on July 8th. The v18.3 release notes are here. If new issues occur, the previous version can also be found here.


🛠 For support, see the sub-reddit  or join the Discord . The documentation is here and my personal email is steve@seguin.email
Version: 18.3 - Icons made by Lucy G from www.flaticon.com is licensed by CC 3.0 BY and by Gregor Cresnar from www.flaticon.com]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Founding Engineer, Ruby on Rails Onsite / WFH Oakland, CA.]]></title>
            <link>https://www.notion.so/canopyanalytics/Lead-Engineer-Ruby-on-Rails-Onsite-WFH-Oakland-CA-43958785bead4955a8f4f250397aadba</link>
            <guid>https://www.notion.so/canopyanalytics/Lead-Engineer-Ruby-on-Rails-Onsite-WFH-Oakland-CA-43958785bead4955a8f4f250397aadba</guid>
            <pubDate>Wed, 14 Jul 2021 19:56:51 GMT</pubDate>
            <content:encoded><![CDATA[Founding Engineer, Ruby on Rails Onsite / WFH Oakland, CA.
Search
Duplicate
Notion
Drag image to reposition
Founding Engineer, Ruby on Rails 
Onsite / WFH Oakland, CA.
Canopy Analytics is hiring a founding engineer and our first senior hire. As part of the early team, you will be a strong individual contributor and a leader for the business. You will deliver high-quality code quickly, and also be responsible for our architecture, roadmap, hiring and engineering culture.
Canopy Analytics is a small but mighty team. With just three founders, we bootstrapped an enterprise SaaS platform, grew +500% in the last year, raised a strong round from top-tier investors, and our customers depend on our software everyday. The key to our success has been a strong team obsessed with customer experience and great product engineering.
What you'll work on
We're a web based cloud platform. We build analytics, workflows and alerts that let our customer navigate their data. We update our system nightly through our ETL processes, translating customer data into a common format that's easy to query and visualize. Managing a common format requires deep understanding of our integrations. To manage the complexity, we focus on a strong writing/documentation culture, high test coverage, and keeping low technical debt. 
You'll work closely with Sameer Siruguri, CTO. He will help you navigate the codebase, coach you through problems we have encountered before, and set overall goals.
When building features, you'll collaborate closely with Jessica Willis, head of design. You'll influence features at every step. You'll start with ETL, analyze the data, ensure the design reflects the data, and translate mockups into code. You'll also help Jessica understand technical nuance and negotiate scope.
Recent projects
•
Feature: Track revenue changes in real time based on changes in the market and their strategy. This is an industry first and was done entirely manually previously.
•
Performance: Introduce Redis for SQL caching
•
Operations: Production data verification in our ETL pipeline 
Tech stack
We use Ruby on Rails with server-rendered HTML. On the front end, Typescript is our primary language. We "sprinkle" interactivity using Stimulus and Chartist for visualizations. Our data is backed by Postgres and Redis. We make extensive use of window functions, rollup tables and caching to keep our application fast. We use RSpec and fixtures for testing (and our coverage is pretty good). The application is hosted on Heroku and we deploy multiple times a day. 
Our priorities are shipping velocity and correctness. We're thinking through:
•
What's the best way to catch bugs before they happen? Will gradual typing through Sorbet or RBI help?
•
How can we build more interactive visualizations and product? Should we use StimulusReflex or Hotwire?
•
How can we dynamically show the KPIs we think our customers should worry about throughout the data? What is the role of predictive analytics in this scenario?
Mission
We started Canopy Analytics because we want more housing to be built so cities can be more affordable. We embedded ourselves in the commercial real estate industry to understand their business problems. We found that they didn't have the tools to adequately deal with their scale. This drives up costs and makes it hard to deploy capital. Our early customers have seen over $1M of impact annually and we've barely scratched the surface. Our vision is to be the software that operates and finances the next generation of cities. 
Requirements
•
We’re looking for someone with strong back-end Ruby experience. You should be well-versed in Rails and SQL. Front-end programming experience, especially with Typescript and modern browser APIs, is a plus but not a requirement.
•
Excellent project management skills is a must. Your ability to break down a complex task into smaller steps helps you anticipate what edge cases might have been ignored. You thoughtfully communicate potential solutions and delegate the decision.
•
Written and verbal communication skills are highly valued. You proactively document and explain project status and technical details to both technical and non-technical audiences.
•
You have the forensic skills to start with a bug report, track down the area of code that is causing the problem, and quickly identify a solution that can both address the bug and also improve the state of the codebase.
•
You proactively suggest ways to make our QA processes better and figure out how we can catch bugs before they get into production.
•
No industry (real estate) experience is necessary but you have to be excited to empower a customer base of non-technical users. We want to hear your ideas about how to make this intuitive and fun.
Culture
•
Our customer base is nearly 60% women and we're committed to building a diverse workforce which reflects our industry segment.
•
We're a team first. No one should feel under appreciated or feel they can't do their best work because of someone else on the team. 
•
Invest in our people. It's critical we learn from each other as well as bring outside resources for training and mentorship.
•
Performance matters. We are proud of our results and reward those who contribute to them.
Compensation
•
Competitive pay, equity, and benefits 
•
$120k-$150k, .25-1%. Will share valuation details.
•
Company covers 75% of Health, dental and vision and 50% of dependents.
•
Onsite 3 days in Oakland office, 2 WFH. Flexible schedule and PTO.
Apply now!
Email sunny.juneja@canopyanalytics.com with the subject line "Future Founding Engineer - {Your Name}." In the body, mention where you saw this job posting and attach a resume. We would love to hear about what excites you about this position.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Women's Gymnastics Is Blasting Into The Future, But Its Scoring Code Is Stuck In The Past | Defector]]></title>
            <link>https://defector.com/womens-gymnastics-is-blasting-into-the-future-but-its-scoring-code-is-stuck-in-the-past/</link>
            <guid>https://defector.com/womens-gymnastics-is-blasting-into-the-future-but-its-scoring-code-is-stuck-in-the-past/</guid>
            <pubDate>Wed, 14 Jul 2021 19:56:48 GMT</pubDate>
            <content:encoded><![CDATA[Skip to contents
Defector
SUBSCRIBE
Menu
OLYMPICS
Women’s Gymnastics Is Blasting Into The Future, But Its Scoring Code Is Stuck In The Past
38
Comments
DVORA MEYERS
11:53 AM EDT on Jul 13, 2021
Emilee Chinn/Getty Images

Here is an objective statement: Simone Biles debuted a Yurchenko double pike at the U.S. Classic in May. As always with gymnastics, the subjective part is where it gets complicated. Tom Forster, the USA Gymnastics women’s high performance director, announced that the provisional value assigned to the vault by the women’s technical committee (WTC) was a 6.6. Forster voiced his displeasure with the valuation, saying that he expected it to be 6.8. Biles, too, said that she felt it was too low. Everyone agreed that the move was phenomenal. The question, which was both obscure and vital, was what it was worth.

This debate led to a flurry of op-eds that declared, with absolute certainty, that this vault value was unjust, without bothering to offer up a rationale as to why it was inappropriate. One reporter even claimed that one didn’t even need to know the difference between two different vault entry styles to understand that Biles’ vault was being undervalued; the issue, as one astute person on the gymternet pointed out, is that understanding the rules is precisely what you need to know if you wish to challenge a score’s fairness and credibility. The combination of an all-time great and opaquely derived numbers with decimal points in them tends to elicit this kind of reaction.

I, as someone who spends a good deal of time thinking and writing about things like this, also honestly didn’t know what to think about that valuation at first. That is to say that I didn’t know how the women’s technical committee had arrived at a 6.6, and I also didn’t know why Forster and Biles felt that a 6.8 was more appropriate. I can’t claim to be an expert in the Code of Points—it’s too much math for my taste—but I started reaching out to people who knew the Code much better than I did, and read as widely as I could. 

What I learned was that either a 6.6 or 6.8 could be justified though the general feeling was that 6.6 was on the low end of what would be considered acceptable for this particular vault; most of the people I consulted preferred 6.8. The details get gory from here—people I spoke with gave different reasons for why they thought the value should be 6.8, some noting that the current value of the vault doesn’t leave room for a somewhat easier tuck version of the Yurchenko double back. One argued there wasn’t enough daylight between the Produnova, which is the only other double salto vault in the women’s Code, and the Biles II. The former, which involves a forward rotation has been performed by several gymnasts since Elena Produnova first introduced it in 1999, is rated a 6.4, just two-tenths lower than the Yurchenko double pike. While the vast majority of Produnovas that have been performed since the original have been disastrous, it is a less technically challenging vault and there should be a greater separation between the two as there is in the men’s Code where .4 separates the same two vaults. It’s important to keep in mind that none of these values mean anything on their own. It’s all contextual, and these values are all temporary. They change from Code to Code. In the next version, set to take effect in 2022, all vaults will be devalued, in part to bring vault scores into line with the other events. The Produnova will drop down to 6.0. It is likely that the Biles II will also be devalued from 6.6, but the question is by how much. 

There is something especially salient in this sea of gym nerdery, though. The reason that there were so many bad Produnovas over the years was because the skill, while incredibly hard to do well, is relatively easy to “chuck”—that is, to attempt knowing that it could be duffed—and still walk away alive. As a result, many gymnasts did just that; because the vault had once been overvalued at a 7.0, they were incentivized by the rules to just go for it. The Yurchenko double pike is far more technical, and no gymnast in their right mind would chuck it because a failed attempt could literally result in grievous injury or death. It is difficult enough that no one would attempt the vault unless they could actually do it. 

That’s a lot of technical talk, but it’s absolutely the kind of thing that should’ve accompanied those early takes on Biles’ vault valuation. (If you want to know even more about the valuation, check out this excellent breakdown from Spencer Barnes of the Balance Beam Situation, who arrived at a 6.8 for the vault but also explains how the WTC might have arrived at 6.6. It’s hard to know, as the WTC 1) hasn’t offered any public explanation for why and how it got there, and 2) may yet bow to public outcry and give it a 6.8 in Tokyo.)

Wherever you fall on this particular skill valuation—I, too, am Team 6.8—it is clear that Biles’ provisional vault valuation was hardly an obvious call. So why did this particular valuation trigger a freakout so profound that people claimed FIG had actively banned her skills? Some of it has to do with Biles’ own history, and some of it has to do with the sport’s struggle to contain and quantify her genius. But it’s mostly about how confused and conflicted women’s gymnastics remains about moving beyond its fussy and antiquated roots.

To understand the reaction to Biles’ vault valuation in 2021, it helps to know what happened with her eponymous beam dismount in 2019. At the last world championships, Biles debuted a double twisting double back off the balance beam, a truly astounding skill. While it was rated H, the highest rated beam dismount in the women’s Code—the skills start with A for the easiest and move through the alphabet as the difficulty increases—this valuation deviated from the expected pattern of beam dismount valuations. Based on the value jump between the double back to full twisting double back, which leapt from D to G, Biles seemed in line for at least an I, if not a J. USA Gymnastics filed an inquiry into the valuation; Biles herself signaled her disapproval of the valuation on Twitter. It was far from the first time that a gymnast’s eponymous element was inexcusably and inexplicably lowballed, but I can’t think of another time when a gymnast or a national governing body challenged that valuation.

It was a decidedly good thing that Biles spoke up—why shouldn’t the WTC be forced to explain their rationale behind their decisions? Given Biles’ status, the WTC couldn’t simply brush her complaint off and ignore it as they might’ve with a lower profile athlete. They had to respond. And their explanation was, to put it in French, one of the official languages of the International Gymnastics Federation (FIG), tres bullshit. They claimed that their decision was about safety, that they didn’t want to incentivize gymnasts trying to do skills above their mastery level by giving too high a value to the Biles dismount. But given how few people attempt the full twisting double back dismount, despite how much higher valued it is than the one without a twist, it’s hard to imagine that a bunch of gymnasts would leapfrog from a double tuck to the Biles simply because it was rated an I or a J. The reason for this is that the only person who can perform the double double safely off the beam is Biles herself. These other gymnasts don’t have death wishes. Some skills you just cannot chuck.

When I wrote about the valuation of Biles’ dismount for the Guardian in 2019, I cited an example of another gymnast whose eponymous skill was lowballed: Liu Xuan of China. Back in 1995, she introduced a one-armed giant swing on the uneven bars. The WTC rated it a C, at a time when the highest possible rating was E. Liu stopped performing it shortly thereafter. Now the skill is only rated a B, and so basically worthless.

The fact that other gymnasts have also had their contributions undervalued by the WTC doesn’t make what happened to Biles okay. It’s wrong that it happened to Liu, and it’s also wrong that it happened to Biles—and to Andrea Maldonado, whose triple twisting front on floor exercise was criminally underrated, and also to Elisabeth Seitz, whose unique full twisting Shaposhnikova-style bar transition received the same value as one done with only half a twist. You do not need to be a gymnastics expert to work out that a skill with a full twist should be worth more than the same one with a half twist, but in the case of the Seitz on bars, it’s not.

In the coverage of the dismount debacle of 2019, I didn’t see other mainstream journalists point out that the WTC had given similarly unfair treatment to other gymnasts whose eponymous skills had been undervalued, and drastically so on some occasions. Nor did the fact that Biles has three other eponymous skills, all appropriately rated, get any notice. Biles really is sui generis in every way, but while her experiences are central to the broader story here, they aren’t the whole story. 

Many gymnastically knowledgeable people pointed to how nonsensical the women’s Code of Points is, especially when compared to the men’s rulebook. Typically, if you know the value of a skill in the men’s Code, you can figure out what that skill, with an extra twist or two, would be worth. The men’s Code uses a straightforward linear progression, and while there are exceptions, they are few and far between. But when it comes to the women’s Code, the exceptions are the rule. It’s almost impossible to predict how the next variation on a skill will be valued without consulting the document itself. As often as not, a glance at that document only makes things more confusing. One Code expert I consulted wrote in an email, “The WAG [women’s artistic gymnastics] vault value tables are a dog’s breakfast, with no clearly evident logic.”

How did the women’s rulebook end up like this? Incompetence surely plays some sort of role, but it’s likely not the whole answer. If every deviation from the expected valuation progression is labeled as mere “incompetence,” then it will become impossible for a gymnast to prove when they’re being unfairly lowballed. And that lack of transparency can serve to mask more sinister forces, like racial bias and the very gymnastics-specific forms it can take.

So if we want to understand what’s going on with Simone Biles’ valuations, we have to include not just other gymnasts whose contributions were undervalued, but also decades of the sport’s history, going back even to its earliest days in the Olympic movement. Women’s gymnastics was created to be a feminine sport, and the femininity that it promoted was the white, Eurocentric kind. As the sport progressed from its very white, very dancey origins and increased in acrobatic complexity, the WTC and FIG held fast to a certain set of self-consciously feminine artistic ideals that were seen as being at odds with the more athletic components of gymnastics. 

And so, instead of shaping the sport’s future, they created a set of rules with one eye cast back towards the past. That nostalgia for a bygone era didn’t lead to all these reboots of ’90s sitcoms on streaming services, but it did result in something equally bad: an institution caught off guard by every new development in the sport, and which responds to every such breakthrough by trying to stuff the genie back into the bottle. The WTC and FIG as a whole are simultaneously reactive and reactionary. As a result, boundary-pushing gymnasts like Biles, Liu, Maldonado, Seitz, and many others are being penalized by an institution that wants to party like it’s still 1969. 

When women’s gymnastics entered the modern Olympic pantheon in 1928, the options for female athletes were expanding, while not rapidly, but at least notably. The same year that women’s gymnastics made its debut, women were allowed to compete in a smattering of athletic events for the first time, too. The introduction of the women’s 100 meters, 4×100 relay, the 800, high jump, and discus throw to the Olympic slate was undoubtedly due to the success of Alice Milliat’s Women’s World Games, which were contested throughout the 1920s and into the ’30s. Milliat created this competition because the International Olympic Committee and International Federation of Athletic Federations (IAAF) refused to allow women to participate in track and field events. 22,000 people saw the first Women’s Games in Paris.

The IOC and the IAAF’s resistance to women participating in track and field disciplines was due to how those activities emphasized certain qualities—speed, strength, power, aggression—which were understood to be traditionally masculine. International sports powers were very concerned that participating in certain sports would have a masculinizing effect on women, perhaps even interfering with their ability to birth babies, the sole reason they were put on God’s green earth. 

But there was a sport that conformed to the feminine ideals of the day: women’s gymnastics. It was “designed specifically for women to participate in sports in a gender appropriate way,” writes Dr. Georgia Cervin in Degrees of Difficulty: How Women’s Gymnastics Rose to Prominence and Fell from Grace. Cervin, in addition to her scholarship, is a former elite gymnast who represented New Zealand in international competition. “Discussions among IOC leaders reveal that women’s gymnastics was accepted into the Olympic movement because the feminine ideals it promoted made the sport appropriate for women,” Cervin writes. “Women performed light movements appropriate for their supposedly weak bodies, demonstrating passivity, softness, and grace.”

To run this new division of gymnastics—men’s gymnastics had been in the very first Games—FIG created what would eventually become known as the women’s technical committee. This was a rather progressive move on FIG’s part, since this committee was actually comprised of women at a time when women’s sports being brought into the Olympic pantheon were controlled by men. (In fact, the IAAF and IOC were quite explicit that they were allowing select track and field events into the Games in order to wrest control of them from Milliat and the Federation Sportive Feminine Internationale.) 

“The FIG followed the IOC’s request to create and control a women’s gymnastics program,” Cervin writes, “but it went further than required, uniquely establishing a governing committee consisting of only women. This committee designed women’s gymnastics around the fundamental principle that gymnasts must demonstrate femininity.”

“You see this as a trend running through all of women’s gymnastics for the rest of the century,” Cervin told me. “There are lines in the early Code of Points about how women should show harmonious flexibility and feminine grace.” When I interviewed Laddie Bakanic, a member of the bronze medal-winning 1948 U.S. Olympic gymnastics team, she told me that she and her teammates could do skills like handstands and cartwheels on the balance beam, but were discouraged from doing them in competition. 

Anyone who has watched women’s gymnastics from the late 1960s onward can attest to the fact that some of those so-called “masculine” qualities found their way into women’s gymnastics as more explosive skills and acrobatics were adopted by the women. But with every technical leap forward, the old debate over artistry versus acrobatics resurfaced anew. Soviet Ludmilla Tourischeva was penalized for doing too much in the way of acrobatics right up until she wasn’t, at which point she started winning. (She’s the 1972 Olympic all-around champion.) Olga Korbut, the darling of the 1972 Olympics, was not beloved by the women’s technical committee due to the risky elements she introduced. While safety was one of the WTC’s concerns when it came to Korbut’s skills, they were also disturbed by how her more daring elements, such as the back tuck on the balance beam, disrupted the flow of a routine. 

Before she performed her most challenging elements, Korbut paused to prepare. “The committee clarified that the backward somersault was especially dangerous and undesirable, and attempted to outlaw the skill because it was not an element ‘peculiar to the beam,’” Cervin writes. What they meant by that was that acrobatic elements belonged on the floor, and nowhere else. Renald Knysh, Korbut’s coach, whom she and others would later accuse of sexual abuse, believed that any skill that could be performed on the floor could be brought to the other apparatuses. Hence Korbut’s standing backflip on bars and her back tuck on the balance beam. (Knysh has denied the allegations.)

Korbut had limited venues in which to voice her displeasure about the threatened ban on her skills, but she did tell the Associated Press that “if the decision is put into effect, then I simply do not see any place for myself in gymnastics.” Basically, Korbut, who was then the most famous gymnast in the world, threatened to retire if the WTC banned her skills. It seems that 2019 wasn’t the first time that the WTC was at odds with the sport’s biggest star. It’s hard to overstate just how big of a star Korbut was in the early ’70s, especially in the West. She even met with President Richard Nixon during one of her American tours with the Soviet gymnasts. 

“The question of (masculine) risk versus (feminine) artistry was finally brought before the FIG General Assembly in 1975,” Cervin writes. “President Arthur Gander told delegates, ‘We should perhaps now ask ourselves if the moment has not now arrived when we should mitigate the trend towards ‘risk’ and ‘difficulty’ which are rapidly becoming more important than deportment and execution. We should take care that artistic gymnastics do not degenerate into pure acrobatics with risk to life and limb.’” 

While Gander’s concern for the safety of the athletes was touching, the women, in most instances, were simply adopting acrobatic elements that had been performed by the men for several years. The difference was that acrobatics weren’t seen as being at odds with the purpose of men’s gymnastics, which has its origins in militaristic training of the 18th and 19th centuries. Similarly, the men’s technical committee didn’t feel the need to intervene on behalf of male gymnasts’ safety because those male gymnasts, in their quest to add more flips and twists, weren’t seen as betraying the core values of their sport. (And it is an almost entirely different sport—there is very little crossover between the men’s apparatuses and the women’s.) The concern for the athletes’ well-being that Gander and others were expressing for female gymnasts was, in other words, bound up entirely in their gender. What was appropriate for the men wasn’t appropriate for the women, because the women’s sport had a different mandate from the very beginning. 

Despite all this hand-wringing, the WTC started to formally increase the demands for difficulty. In the 1970 version of the Code of Points, the gymnasts had to demonstrate “‘difficulty and connections’ even specifically required acrobatics on the floor,’” Cervin notes. The march towards greater acrobatic complexity could not be stopped. By the 1960s, Cervin told me, “the limits of women’s gymnastics as a non-acrobatic sport had been reached. There’s only so many leaps and turns and walkovers you can do before you need to start getting airborne.” This transformed the narrative of the sport into the one still in use: Every generation of gymnasts does more flips and twists than the preceding one. Nobody embodies that ethos better than Simone “Let Me Throw Another Twist On That” Biles.

In the years since Korbut called FIG’s bluff, a lot has changed for women’s gymnastics. But the tension that Cervin describes persists between the sport’s early mandate to be a “feminine” sport, whatever the hell that means, and its evolutionary push towards greater risk and acrobatic complexity. A major change to gymnastics’ scoring system has only made it harder to miss. 

In 2006, after a major judging scandal at the 2004 Olympics threw the results of the men’s all-around into chaos, the FIG adopted an allegedly open-ended scoring system. Prior to the change, all elements of the performance—the difficulty and execution—were expressed by a single number, the 10.0. In effect, the 10.0 served as a scoring cap, which often meant that gymnasts who went above and beyond, as Biles is wont to do, weren’t rewarded for their innovation and daring. For example, at the 1992 Olympics, a full twisting Yurchenko on vault carried the same tariff as a double twisting Yurchenko: a 10. This means that if the gymnast performing either vault hit it perfectly, the maximum score they could get was a 10. As with Seitz’s undervalued uneven bars transition, the inherent unfairness in this situation is easy to grasp.

Since the scoring change was implemented, gymnasts started receiving two marks, one for difficulty and one for execution, that were then added together for the final score. That’s how you end up with numbers like 13.133. That doesn’t have the same ring to it as a 9.9 but, ideally, the awkward string of numbers should do a better job of accounting for what a gymnast actually did out on the floor. Or beam. Or vault.

With the separation of the scores, a gymnast can be rewarded for their daring on one hand and held accountable for how well they actually perform those risky skills on the other. Before, if judges wished to reward a truly groundbreaking gymnast who went above and beyond the rules, they might be tempted to look the other way on execution deductions, since sometimes an increase in risk and difficulty could mean a deterioration in execution. In theory, a gymnast with a lower degree of difficulty who performs sublimely should be able to match a gymnast with a higher D score but weaker execution. (I say “in theory” because that would mean that the execution judges are doing their jobs properly, and that isn’t always the case.) The challenge presented by a world-historic genius like Biles is that her execution hasn’t suffered a bit as she has increased her difficulty over the years—she’s just as clean on the astoundingly difficult skills as on the easier ones. This is one of the many things that makes her such a remarkable gymnast, and it is why she has become unbeatable over the past eight years. 

This new system didn’t end the exhausting and unending debate over the direction of women’s gymnastics, of course. The old gripe’s new expression manifests as concerns about lack of “artistry,” the term that seems to have replaced “feminine” or “femininity” in the discourse. These artistry qualms have been deployed in ways that often seem to hinge on body type and race, not just performance quality and engagement level. Thinner, leaner gymnasts received praise for their “long lines” and “artistry,” and for possessing the “international look that the judges love.” Most of the gymnasts described this way were white. 

After Biles won her first world title in 2013, the majority of the media attention she received was about the racist comments that the Italian Gymnastics Federation made about her. In defending a gymnast who suggested that donning blackface might help her win next time, the Italian spokesperson said, “The Code of Points is opening chances for colored people (known to be more powerful) and penalizing the typical Eastern European elegance, which, when gymnastics was more artistic and less acrobatic, allowed Russian and Romania to dominate the field.” Anyone who could say this with a straight face clearly hasn’t watched Romania’s 1978 floor lineup, but then anyone who would say it aloud in 2013 had a number of other urgent issues.

Shortly after Biles’ first world championships win, Nellie Kim, then the president of the WTC, without not specifically mentioning Biles by name, said, “I feel uneasy when gymnasts with an athletic, not gymnastic body, become world champions. Their performances lack elegance, finesse.” It’s both hard and rather nauseatingly easy to figure out what Kim means in this athletic vs. gymnastic comparison. By the standard that matters most, Biles possesses the ultimate gymnastics body. I mean, have you seen her do gymnastics?  

Anyway, this was how the debut of the greatest athlete in the sport’s history was welcomed by the international gymnastics community and the sport’s administration.  

Even after Biles established herself as the greatest in 2016 with four golds at the Olympics, Bruno Grandi, who was then the president of FIG, said of the floor exercise final results, “The only thing with which I don’t agree with the judges, and it’s a personal opinion and not a criticism—for me the gymnastics of the second American [Aly Raisman] is more artistic than the first [Simone Biles]. The first, it’s acrobatics.” It’s telling that he singles out a white gymnast, Raisman, for being artistic in comparison to Biles, whom he dubs as merely “acrobatic.” Raisman was a wonderful gymnast, but she was also never known for being particularly artistic. She was known, in fact, for her acrobatics, and became the 2012 Olympic champion on floor exercise on the strength of her tumbling. Biles, for her part, was much more polished than Raisman in terms of form and execution. But then it might not just be about the routines, here. 

While there have been more Black gymnasts competing over the last few decades, and especially over the past 10 years, the sport has only grudgingly made room for them. They will allow that they are powerful—which, of course, isn’t true for all Black gymnasts, just like being graceful isn’t somehow a natural state of being for white gymnasts—but gymnasts like Biles are still often talked about as though they’re spoilers, or interlopers; the unspoken judgment is that their arrival has transformed gymnastics, and not for the better. The implication is that the sport, once a bastion of white womanhood—and then white girlhood—has now moved so far from its roots that it’ll never again be what it once was. As though remaining that way was even desirable, and as if a sport that stopped growing was doing anything but dying.

Even skill representations in the Code of Points don’t account for the diversity among gymnasts. Cervin credited the performance studies scholar Shani Skakur-Bruno for observing that the Code of Points’ illustrations are of white gymnasts. “Although it is intended to be a neutral illustration without facial features, the gymnast’s hair is straight and pulled back into a ponytail, which precludes many non-white hair types and styles,” Cervin writes. “The illustrations [reflect] expectations of performance based on ideals of white womanhood.”

Add to all of this anti-Blackness the fact that there have been many questionable comments and a pattern of excessive censure from media and officials alike directed at Chinese gymnasts. I remember watching the Olympics in the 1990s and hearing the commentators speak about how the Chinese leotards didn’t fit as well as those of other countries and wondering why, to my eye, they seemed to fit as well as all the rest. There were also comments about their music and floor choreography although, once again, their floor routines seemed no better and no worse than everyone else’s. (Except for perhaps the Soviets, but then everyone was artistically inferior to the late-’80s/early-’90s USSR team, and that includes the Romanians, the Americans, everyone. I mean, Olga Strazheva performed a bizarre routine to Igor Stravinsky’s “The Rite of Spring” and Svetlana Boguinskaia did what can only be described as “bondage choreography” to “Bolero.” Iconic.) 

Grandi singled out China and Japan in his comments about choreography and artistry. After accusing China of “robotic-style training” at a time when the U.S. was winning under the domineering tutelage of Martha Karolyi, he praised Japan for being willing to adapt and change—by which he meant more closely align themselves with so-called “Western” styles. “They (Japan) have improved the construction of their exercises, leaving behind Eastern-style choreographies to move towards the West—that is to say more harmony, imagination, creativity.”

Donatella Saachi, the current president of the WTC, made somewhat similar comments about Chinese expressiveness on floor exercise, saying that “it’s not the nature of the country to show emotions” in a podcast interview. I hope this doesn’t need to be said, but this is outlandishly backwards bullshit. A routine’s artistic success really depends on the gymnast, the music, and the choreography; I don’t know about you, but I think Jiang Yuyuan is doing a pretty great job expressing herself in her 2008 Olympic floor routine.

Even the Chinese team’s long-admired prowess on the uneven bars—their very first world champion, Ma Yanhong in 1979, was noted for her mastery and precision—has come under attack. The skills that the Chinese gymnasts have innovated, such as pirouettes with challenging grips that require extreme amounts of shoulder flexibility, have seen their values capped at E, regardless of the type of grip they’re performed in. (Some grip positions are more difficult than others; while the Chinese have mastered every type, they don’t really get credit for this.) The WTC has instead favored a big-swinging, transition-heavy style innovated by the Russians and Great Britain’s Beth Tweddle. While this happens to match my particular preference as a fan, there’s no good reason why there shouldn’t be room in the Code to reward both approaches, especially since the Chinese approach was undoubtedly both difficult and beautiful. Saachi has even spoken about how pleased she is that the Chinese have started to move away from their own original elements—which get hit with deductions since it’s virtually impossible to land these pirouettes on top of handstand, which is now how they’re supposed to be done—towards the big-swinging transitions. The result, however satisfying to Saachi, has meant less diversity of skills on the uneven bars. The range of valuable elements has narrowed. And in the case of Seitz’s skill, bar transitions have essentially been capped in value. 

Seitz is white and from Germany, so racism and Eurocentrism can’t account for all of the boneheaded decisions of the WTC. Other white gymnasts, most notably Korbut, have also been subject to similar treatment. WTC’s fretting over the “direction of the sport” is vast enough to ensnare all kinds of innocents. 

The WTC seems to have what Barnes has aptly described as “open-ended cold feet.” Rather than truly explore what it means to have an open-ended scoring system, they get nervous, and then conservative. They bunt when they should swing for the fences. It’s minimal progress, if progress all the same, and with the 6.6, they were at least in the right ballpark. But once again, they showed their squeamishness with the open-ended scoring and the direction that the sport is headed in. 

The most fundamental problem here is that the WTC never truly embraced the open-ended scoring system. The WTC is a bit like me when I refuse to download a new iOS and then find that some of my apps don’t run as well—or open at all. The WTC is running on an antique operating system, and doing so in accordance with old and at times problematic values.  

I can’t personally say whether her vault’s valuation was an explicit attack on Biles by an institution that has been ambivalent about her and her dominance, at best, and racist at worst. There is plenty of circumstantial evidence, and Biles has been quite adamant that, when it comes to her lowballed beam dismount, she believes it is about her. “I’m almost 99.9 percent sure if any other athlete were to do it besides me they would give it correct credit,” Biles said in the new docuseries Simone vs. Herself. “But since I’m already way ahead of everybody they kind of want to pull it back, because sometimes they don’t think it’s fair that I win all the time.” But her willingness to demand an explanation for her valuations has served not only to highlight problems with her skills’ values, but stubborn problems with the women’s governing body that have been there from the very beginning. The WTC thinks it’s their job to determine the direction of the sport, which has always meant keeping one foot firmly and willfully rooted in the past. But micromanaging the sport is not their job, or at least it shouldn’t be. It should be up to the athletes to determine in which directions—and there can and absolutely should be more than one—women’s gymnastics will go.

“Because I can,” Biles told reporters about why she was going to do the Yurchenko double pike, despite that lower-than-expected valuation. If the WTC can finally figure out how to shepherd the sport into the future, or even just stop determinedly confining it to the past, maybe the greatest gymnast of all-time wouldn’t feel that she is performing her innovative skills to spite them. Who knows what we might see then?

38
Comments
Dvora Meyers

Dvora Meyers is a freelance journalist based in Brooklyn. She writes about gymnastics and other topics in her newsletter, Unorthodox Gymnastics.

Read More:
FIG
FL
MOLDERING INSTITUTIONS
OLGA KORBUT
Keep up with our blogs.
Email Address
SUBMIT

Something you think we should know? Send a story tip to tips@defector.com

THE LATEST
The Minnesota Wild: It Seems Bad!
NHL
58
COMMENTS
LAUREN THEISEN
Where Do Able-Bodied Athletes Belong In Wheelchair Basketball?
PARASPORTS
46
COMMENTS
JOHN LOEPPKY
THE DEFECTOR TANK
The Defector Tank has arrived. This 100% cotton tank top, printed by a unionized workshop, is only available for a limited time. Be the envy of all your friends this summer, or all year round if you're truly committed.
Shop Now
Nolan Arenado’s Return To Colorado Meant Something
MLB
25
COMMENTS
TOM LEY
Vladimir Guerrero Jr. Has Perfect Timing
MLB
53
COMMENTS
LAUREN THEISEN
SEE MORE STORIES
SEND US A TIP
SUPPORT AND GENERAL QUESTIONS
PRESS INQUIRIES
ADVERTISE WITH US
HALL OF FAME
MASTHEAD
Privacy Notice
Terms of Use
DEFECTOR
This is Defector, a new sports blog and media company. We made this place together, we own it together, we run it together. Without access, without favor, without discretion, and without interference.
© Copyright 2021
Made in partnership with Lede]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Internet Addiction: A Brief Summary of Research and Practice]]></title>
            <link>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3480687/</link>
            <guid>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3480687/</guid>
            <pubDate>Wed, 14 Jul 2021 19:56:44 GMT</pubDate>
            <content:encoded><![CDATA[NCBI
Skip to main content
Skip to navigation
Resources
How To
About NCBI Accesskeys
PMC
US National Library of Medicine
National Institutes of Health
Search database
PMC
All Databases
Assembly
Biocollections
BioProject
BioSample
BioSystems
Books
ClinVar
Conserved Domains
dbGaP
dbVar
Gene
Genome
GEO DataSets
GEO Profiles
GTR
HomoloGene
Identical Protein Groups
MedGen
MeSH
NCBI Web Site
NLM Catalog
Nucleotide
OMIM
PMC
PopSet
Protein
Protein Clusters
Protein Family Models
PubChem BioAssay
PubChem Compound
PubChem Substance
PubMed
SNP
SRA
Structure
Taxonomy
ToolKit
ToolKitAll
ToolKitBookgh
Search term
Search
Advanced Journal list
Help

COVID-19 Information

Public health information (CDC)

Research information (NIH)

SARS-CoV-2 data (NCBI)

Prevention and treatment information (HHS)

Español

 

Try out PMC Labs and tell us what you think. Learn More.

Journal ListBentham Open AccessPMC3480687
Current Psychiatry Reviews
Bentham Science Publishers
Curr Psychiatry Rev. 2012 Nov; 8(4): 292–298.
Published online 2012 Nov. doi: 10.2174/157340012803520513
PMCID: PMC3480687
PMID: 23125561
Internet Addiction: A Brief Summary of Research and Practice
Hilarie Cash,a,* Cosette D Rae,a Ann H Steel,a and Alexander Winklerb
Author information Copyright and License information Disclaimer
This article has been cited by other articles in PMC.
Go to:
Abstract

Problematic computer use is a growing social issue which is being debated worldwide. Internet Addiction Disorder (IAD) ruins lives by causing neurological complications, psychological disturbances, and social problems. Surveys in the United States and Europe have indicated alarming prevalence rates between 1.5 and 8.2% [1]. There are several reviews addressing the definition, classification, assessment, epidemiology, and co-morbidity of IAD [2-5], and some reviews [6-8] addressing the treatment of IAD. The aim of this paper is to give a preferably brief overview of research on IAD and theoretical considerations from a practical perspective based on years of daily work with clients suffering from Internet addiction. Furthermore, with this paper we intend to bring in practical experience in the debate about the eventual inclusion of IAD in the next version of the Diagnostic and Statistical Manual of Mental Disorders (DSM).

Keywords: Addiction, Computer, Internet, reSTART, Treatment.
Go to:
INTRODUCTION

The idea that problematic computer use meets criteria for an addiction, and therefore should be included in the next iteration of the Diagnostic and Statistical Manual of Mental Disorders (DSM), 4th ed. Text Revision [9] was first proposed by Kimberly Young, PhD in her seminal 1996 paper [10]. Since that time IAD has been extensively studied and is indeed, currently under consideration for inclusion in the DSM-V [11]. Meanwhile, both China and South Korea have identified Internet addiction as a significant public health threat and both countries support education, research and treatment [12]. In the United States, despite a growing body of research, and treatment for the disorder available in out-patient and in-patient settings, there has been no formal governmental response to the issue of Internet addiction. While the debate goes on about whether or not the DSM-V should designate Internet addiction a mental disorder [12-14] people currently suffering from Internet addiction are seeking treatment. Because of our experience we support the development of uniform diagnostic criteria and the inclusion of IAD in the DSM-V [11] in order to advance public education, diagnosis and treatment of this important disorder.

Go to:
CLASSIFICATION

There is ongoing debate about how best to classify the behavior which is characterized by many hours spent in non-work technology-related computer/Internet/video game activities [15]. It is accompanied by changes in mood, preoccupation with the Internet and digital media, the inability to control the amount of time spent interfacing with digital technology, the need for more time or a new game to achieve a desired mood, withdrawal symptoms when not engaged, and a continuation of the behavior despite family conflict, a diminishing social life and adverse work or academic consequences [2, 16, 17]. Some researchers and mental health practitioners see excessive Internet use as a symptom of another disorder such as anxiety or depression rather than a separate entity [e.g. 18]. Internet addiction could be considered an Impulse control disorder (not otherwise specified). Yet there is a growing consensus that this constellation of symptoms is an addiction [e.g. 19]. The American Society of Addiction Medicine (ASAM) recently released a new definition of addiction as a chronic brain disorder, officially proposing for the first time that addiction is not limited to substance use [20]. All addictions, whether chemical or behavioral, share certain characteristics including salience, compulsive use (loss of control), mood modification and the alleviation of distress, tolerance and withdrawal, and the continuation despite negative consequences.

Go to:
DIAGNOSTIC CRITERIA FOR IAD

The first serious proposal for diagnostic criteria was advanced in 1996 by Dr. Young, modifying the DSM-IV criteria for pathological gambling [10]. Since then variations in both name and criteria have been put forward to capture the problem, which is now most popularly known as Internet Addiction Disorder. Problematic Internet Use (PIU) [21], computer addiction, Internet dependence [22], compulsive Internet use, pathological Internet use [23], and many other labels can be found in the literature. Likewise a variety of often overlapping criteria have been proposed and studied, some of which have been validated. However, empirical studies provide an inconsistent set of criteria to define Internet addiction [24]. For an overview see Byun et al. [25].

Beard [2] recommends that the following five diagnostic criteria are required for a diagnosis of Internet addiction: (1) Is preoccupied with the Internet (thinks about previous online activity or anticipate next online session); (2) Needs to use the Internet with increased amounts of time in order to achieve satisfaction; (3) Has made unsuccessful efforts to control, cut back, or stop Internet use; (4) Is restless, moody, depressed, or irritable when attempting to cut down or stop Internet use; (5) Has stayed online longer than originally intended. Additionally, at least one of the following must be present: (6) Has jeopardized or risked the loss of a significant relationship, job, educational or career opportunity because of the Internet; (7) Has lied to family members, therapist, or others to conceal the extent of involvement with the Internet; (8) Uses the Internet as a way of escaping from problems or of relieving a dysphoric mood (e.g., feelings of helplessness, guilt, anxiety, depression) [2].

There has been also been a variety of assessment tools used in evaluation. Young’s Internet Addiction Test [16], the Problematic Internet Use Questionnaire (PIUQ) developed by Demetrovics, Szeredi, and Pozsa [26] and the Compulsive Internet Use Scale (CIUS) [27] are all examples of instruments to assess for this disorder.

Go to:
PREVALENCE

The considerable variance of the prevalence rates reported for IAD (between 0.3% and 38%) [28] may be attributable to the fact that diagnostic criteria and assessment questionnaires used for diagnosis vary between countries and studies often use highly selective samples of online surveys [7]. In their review Weinstein and Lejoyeux [1] report that surveys in the United States and Europe have indicated prevalence rates varying between 1.5% and 8.2%. Other reports place the rates between 6% and 18.5% [29].

“Some obvious differences with respect to the methodologies, cultural factors, outcomes and assessment tools forming the basis for these prevalence rates notwithstanding, the rates we encountered were generally high and sometimes alarming.” [24]

Go to:
ETIOLOGY

There are different models available for the development and maintenance of IAD like the cognitive-behavioral model of problematic Internet use [21], the anonymity, convenience and escape (ACE) model [30], the access, affordability, anonymity (Triple-A) engine [31], a phases model of pathological Internet use by Grohol [32], and a comprehensive model of the development and maintenance of Internet addiction by Winkler & Dörsing [24], which takes into account socio-cultural factors (e.g., demographic factors, access to and acceptance of the Internet), biological vulnerabilities (e.g., genetic factors, abnormalities in neurochemical processes), psychological predispositions (e.g., personality characteristics, negative affects), and specific attributes of the Internet to explain “excessive engagement in Internet activities” [24].

Go to:
NEUROBIOLOGICAL VULNERABILITIES

It is known that addictions activate a combination of sites in the brain associated with pleasure, known together as the “reward center” or “pleasure pathway” of the brain [33, 34]. When activated, dopamine release is increased, along with opiates and other neurochemicals. Over time, the associated receptors may be affected, producing tolerance or the need for increasing stimulation of the reward center to produce a “high” and the subsequent characteristic behavior patterns needed to avoid withdrawal. Internet use may also lead specifically to dopamine release in the nucleus accumbens [35, 36], one of the reward structures of the brain specifically involved in other addictions [20]. An example of the rewarding nature of digital technology use may be captured in the following statement by a 21 year-old male in treatment for IAD:

“I feel technology has brought so much joy into my life. No other activity relaxes me or stimulates me like technology. However, when depression hits, I tend to use technology as a way of retreating and isolating.”

Go to:
REINFORCEMENT/REWARD

What is so rewarding about Internet and video game use that it could become an addiction? The theory is that digital technology users experience multiple layers of reward when they use various computer applications. The Internet functions on a variable ratio reinforcement schedule (VRRS), as does gambling [29]. Whatever the application (general surfing, pornography, chat rooms, message boards, social networking sites, video games, email, texting, cloud applications and games, etc.), these activities support unpredictable and variable reward structures. The reward experienced is intensified when combined with mood enhancing/stimulating content. Examples of this would be pornography (sexual stimulation), video games (e.g. various social rewards, identification with a hero, immersive graphics), dating sites (romantic fantasy), online poker (financial) and special interest chat rooms or message boards (sense of belonging) [29, 37].

Go to:
BIOLOGICAL PREDISPOSITION

There is increasing evidence that there can be a genetic predisposition to addictive behaviors [38, 39]. The theory is that individuals with this predisposition do not have an adequate number of dopamine receptors or have an insufficient amount of serotonin/dopamine [2], thereby having difficulty experiencing normal levels of pleasure in activities that most people would find rewarding. To increase pleasure, these individuals are more likely to seek greater than average engagement in behaviors that stimulate an increase in dopamine, effectively giving them more reward but placing them at higher risk for addiction.

Go to:
MENTAL HEALTH VULNERABILITIES

Many researchers and clinicians have noted that a variety of mental disorders co-occur with IAD. There is debate about which came first, the addiction or the co-occurring disorder [18, 40]. The study by Dong et al. [40] had at least the potential to clarify this question, reporting that higher scores for depression, anxiety, hostility, interpersonal sensitivity, and psychoticism were consequences of IAD. But due to the limitations of the study further research is necessary.

Go to:
THE TREATMENT OF INTERNET ADDICTION

There is a general consensus that total abstinence from the Internet should not be the goal of the interventions and that instead, an abstinence from problematic applications and a controlled and balanced Internet usage should be achieved [6]. The following paragraphs illustrate the various treatment options for IAD that exist today. Unless studies examining the efficacy of the illustrated treatments are not available, findings on the efficacy of the presented treatments are also provided. Unfortunately, most of the treatment studies were of low methodological quality and used an intra-group design.

The general lack of treatment studies notwithstanding, there are treatment guidelines reported by clinicians working in the field of IAD. In her book “Internet Addiction: Symptoms, Evaluation, and Treatment”, Young [41] offers some treatment strategies which are already known from the cognitive-behavioral approach: (a) practice opposite time of Internet use (discover patient’s patterns of Internet use and disrupt these patterns by suggesting new schedules), (b) use external stoppers (real events or activities prompting the patient to log off), (c) set goals (with regard to the amount of time), (d) abstain from a particular application (that the client is unable to control), (e) use reminder cards (cues that remind the patient of the costs of IAD and benefits of breaking it), (f) develop a personal inventory (shows all the activities that the patient used to engage in or can’t find the time due to IAD), (g) enter a support group (compensates for a lack of social support), and (h) engage in family therapy (addresses relational problems in the family) [41]. Unfortunately, clinical evidence for the efficacy of these strategies is not mentioned.

Non-psychological Approaches

Some authors examine pharmacological interventions for IAD, perhaps due to the fact that clinicians use psychopharmacology to treat IAD despite the lack of treatment studies addressing the efficacy of pharmacological treatments. In particular, selective serotonin-reuptake inhibitors (SSRIs) have been used because of the co-morbid psychiatric symptoms of IAD (e.g. depression and anxiety) for which SSRIs have been found to be effective [42-46]. Escitalopram (a SSRI) was used by Dell’Osso et al. [47] to treat 14 subjects with impulsive-compulsive Internet usage disorder. Internet usage decreased significantly from a mean of 36.8 hours/week to a baseline of 16.5 hours/week. In another study Han, Hwang, and Renshaw [48] used bupropion (a non-tricyclic antidepressant) and found a decrease of craving for Internet video game play, total game play time, and cue-induced brain activity in dorsolateral prefrontal cortex after a six week period of bupropion sustained release treatment. Methylphenidate (a psycho stimulant drug) was used by Han et al. [49] to treat 62 Internet video game-playing children diagnosed with attention-deficit hyperactivity disorder. After eight weeks of treatment, the YIAS-K scores and Internet usage times were significantly reduced and the authors cautiously suggest that methylphenidate might be evaluated as a potential treatment of IAD. According to a study by Shapira et al. [50], mood stabilizers might also improve the symptoms of IAD. In addition to these studies, there are some case reports of patients treated with escitalopram [45], citalopram (SSRI)- quetiapine (antipsychotic) combination [43] and naltrexone (an opioid receptor antagonist) [51].

A few authors mentioned that physical exercise could compensate the decrease of the dopamine level due to decreased online usage [52]. In addition, sports exercise prescriptions used in the course of cognitive behavioral group therapy may enhance the effect of the intervention for IAD [53].

Psychological Approaches

Motivational interviewing (MI) is a client-centered yet directive method for enhancing intrinsic motivation to change by exploring and resolving client ambivalence [54]. It was developed to help individuals give up addictive behaviors and learn new behavioral skills, using techniques such as open-ended questions, reflective listening, affirmation, and summarization to help individuals express their concerns about change [55]. Unfortunately, there are currently no studies addressing the efficacy of MI in treating IAD, but MI seems to be moderately effective in the areas of alcohol, drug addiction, and diet/exercise problems [56].

Peukert et al. [7] suggest that interventions with family members or other relatives like “Community Reinforcement and Family Training” [57] could be useful in enhancing the motivation of an addict to cut back on Internet use, although the reviewers remark that control studies with relatives do not exist to date.

Reality therapy (RT) is supposed to encourage individuals to choose to improve their lives by committing to change their behavior. It includes sessions to show clients that addiction is a choice and to give them training in time management; it also introduces alternative activities to the problematic behavior [58]. According to Kim [58], RT is a core addiction recovery tool that offers a wide variety of uses as a treatment for addictive disorders such as drugs, sex, food, and works as well for the Internet. In his RT group counseling program treatment study, Kim [59] found that the treatment program effectively reduced addiction level and improved self-esteem of 25 Internet-addicted university students in Korea.

Twohig and Crosby [60] used an Acceptance & Commitment Therapy (ACT) protocol including several exercises adjusted to better fit the issues with which the sample struggles to treat six adult males suffering from problematic Internet pornography viewing. The treatment resulted in an 85% reduction in viewing at post-treatment with results being maintained at the three month follow-up (83% reduction in viewing pornography).

Widyanto and Griffith [8] report that most of the treatments employed so far had utilized a cognitive-behavioral approach. The case for using cognitive-behavioral therapy (CBT) is justified due to the good results in the treatment of other behavioral addictions/impulse-control disorders, such as pathological gambling, compulsive shopping, bulimia nervosa, and binge eating-disorders [61]. Wölfling [5] described a predominantly behavioral group treatment including identification of sustaining conditions, establishing of intrinsic motivation to reduce the amount of time being online, learning alternative behaviors, engagement in new social real-life contacts, psycho-education and exposure therapy, but unfortunately clinical evidence for the efficacy of these strategies is not mentioned. In her study, Young [62] used CBT to treat 114 clients suffering from IAD and found that participants were better able to manage their presenting problems post-treatment, showing improved motivation to stop abusing the Internet, improved ability to control their computer use, improved ability to function in offline relationships, improved ability to abstain from sexually explicit online material, improved ability to engage in offline activities, and improved ability to achieve sobriety from problematic applications. Cao, Su and Gao [63] investigated the effect of group CBT on 29 middle school students with IAD and found that IAD scores of the experimental group were lower than of the control group after treatment. The authors also reported improvement in psychological function. Thirty-eight adolescents with IAD were treated with CBT designed particularly for addicted adolescents by Li and Dai [64]. They found that CBT has good effects on the adolescents with IAD (CIAS scores in the therapy group were significant lower than that in the control group). In the experimental group the scores of depression, anxiety, compulsiveness, self-blame, illusion, and retreat were significantly decreased after treatment. Zhu, Jin, and Zhong [65] compared CBT and electro acupuncture (EA) plus CBT assigning forty-seven patients with IAD to one of the two groups respectively. The authors found that CBT alone or combined with EA can significantly reduce the score of IAD and anxiety on a self-rating scale and improve self-conscious health status in patients with IAD, but the effect obtained by the combined therapy was better.

Multimodal Treatments

A multimodal treatment approach is characterized by the implementation of several different types of treatment in some cases even from different disciplines such as pharmacology, psychotherapy and family counseling simultaneously or sequentially. Orzack and Orzack [66] mentioned that treatments for IAD need to be multidisciplinary including CBT, psychotropic medication, family therapy, and case managers, because of the complexity of these patients’ problems.

In their treatment study, Du, Jiang, and Vance [67] found that multimodal school-based group CBT (including parent training, teacher education, and group CBT) was effective for adolescents with IAD (n = 23), particularly in improving emotional state and regulation ability, behavioral and self-management style. The effect of another multimodal intervention consisting of solution-focused brief therapy (SFBT), family therapy, and CT was investigated among 52 adolescents with IAD in China. After three months of treatment, the scores on an IAD scale (IAD-DQ), the scores on the SCL-90, and the amount of time spent online decreased significantly [68]. Orzack et al. [69] used a psychoeducational program, which combines psychodynamic and cognitive-behavioral theoretical perspectives, using a combination of Readiness to Change (RtC), CBT and MI interventions to treat a group of 35 men involved in problematic Internet-enabled sexual behavior (IESB). In this group treatment, the quality of life increased and the level of depressive symptoms decreased after 16 (weekly) treatment sessions, but the level of problematic Internet use failed to decrease significantly [69]. Internet addiction related symptom scores significantly decreased after a group of 23 middle school students with IAD were treated with Behavioral Therapy (BT) or CT, detoxification treatment, psychosocial rehabilitation, personality modeling and parent training [70]. Therefore, the authors concluded that psychotherapy, in particular CT and BT were effective in treating middle school students with IAD. Shek, Tang, and Lo [71] described a multi-level counseling program designed for young people with IAD based on the responses of 59 clients. Findings of this study suggest this multi-level counseling program (including counseling, MI, family perspective, case work and group work) is promising to help young people with IAD. Internet addiction symptom scores significantly decreased, but the program failed to increase psychological well-being significantly. A six-week group counseling program (including CBT, social competence training, training of self-control strategies and training of communication skills) was shown to be effective on 24 Internet-addicted college students in China [72]. The authors reported that the adapted CIAS-R scores of the experimental group were significantly lower than those of the control group post-treatment.

The reSTART Program

The authors of this article are currently, or have been, affiliated with the reSTART: Internet Addiction Recovery Program [73] in Fall City, Washington. The reSTART program is an inpatient Internet addiction recovery program which integrates technology detoxification (no technology for 45 to 90 days), drug and alcohol treatment, 12 step work, cognitive behavioral therapy (CBT), experiential adventure based therapy, Acceptance and Commitment therapy (ACT), brain enhancing interventions, animal assisted therapy, motivational interviewing (MI), mindfulness based relapse prevention (MBRP), Mindfulness based stress reduction (MBSR), interpersonal group psychotherapy, individual psychotherapy, individualized treatments for co-occurring disorders, psycho- educational groups (life visioning, addiction education, communication and assertiveness training, social skills, life skills, Life balance plan), aftercare treatments (monitoring of technology use, ongoing psychotherapy and group work), and continuing care (outpatient treatment) in an individualized, holistic approach.

The first results from an ongoing OQ45.2 [74] study (a self-reported measurement of subjective discomfort, interpersonal relationships and social role performance assessed on a weekly basis) of the short-term impact on 19 adults who complete the 45+ days program showed an improved score after treatment. Seventy-four percent of participants showed significant clinical improvement, 21% of participants showed no reliable change, and 5% deteriorated. The results have to be regarded as preliminary due to the small study sample, the self-report measurement and the lack of a control group. Despite these limitations, there is evidence that the program is responsible for most of the improvements demonstrated.

Go to:
CONCLUSION

As can be seen from this brief review, the field of Internet addiction is advancing rapidly even without its official recognition as a separate and distinct behavioral addiction and with continuing disagreement over diagnostic criteria. The ongoing debate whether IAD should be classified as an (behavioral) addiction, an impulse-control disorder or even an obsessive compulsive disorder cannot be satisfactorily resolved in this paper. But the symptoms we observed in clinical practice show a great deal of overlap with the symptoms commonly associated with (behavioral) addictions. Also it remains unclear to this day whether the underlying mechanisms responsible for the addictive behavior are the same in different types of IAD (e.g., online sexual addiction, online gaming, and excessive surfing). From our practical perspective the different shapes of IAD fit in one category, due to various Internet specific commonalities (e.g., anonymity, riskless interaction), commonalities in the underlying behavior (e.g., avoidance, fear, pleasure, entertainment) and overlapping symptoms (e.g., the increased amount of time spent online, preoccupation and other signs of addiction). Nevertheless more research has to be done to substantiate our clinical impression.

Despite several methodological limitations, the strength of this work in comparison to other reviews in the international body of literature addressing the definition, classification, assessment, epidemiology, and co-morbidity of IAD [2-5], and to reviews [6-8] addressing the treatment of IAD, is that it connects theoretical considerations with the clinical practice of interdisciplinary mental health experts working for years in the field of Internet addiction. Furthermore, the current work gives a good overview of the current state of research in the field of internet addiction treatment. Despite the limitations stated above this work gives a brief overview of the current state of research on IAD from a practical perspective and can therefore be seen as an important and helpful paper for further research as well as for clinical practice in particular.

Go to:
ACKNOWLEDGEMENTS

Declared none.

Go to:
CONFLICT OF INTEREST

The authors confirm that this article content has no conflict of interest.

Go to:
REFERENCES
1. Weinstein A, Lejoyeux M. Internet addiction or excessive Internet use. The American Journal of Drug and Alcohol Abuse. 2010 Aug;36(5 ):277–83. [PubMed] [Google Scholar]
2. Beard KW. Internet addiction: a review of current assessment techniques and potential assessment questions. CyberPsychology & Behavior. 2005 Feb;8(1 ):7–14. [PubMed] [Google Scholar]
3. Chou C, Condron L, Belland JC. A review of the research on Internet addiction. Educational Psychology Review. 2005 Dec;17(4 ):363–88. [Google Scholar]
4. Douglas AC, Mills JE, Niang M, Stepchenkova S, Byun S, Ruffini C, et al. Internet addiction: meta-synthesis of qualitative research for the decade 1996-2006. Computers in Human Behavior. 2008 Sep;24(6 ):3027–44. [Google Scholar]
5. Wolfling K, Buhler M, Lemenager T, Morsen C, Mann K. Gambling and internet addiction. Review and research agenda. Der Nervenarzt. 2009 Sep;80(9 ):1030–9. [PubMed] [Google Scholar]
6. Petersen KU, Weymann N, Schelb Y, Thiel R, Thomasius R. Pathological Internet use - epidemiology, diagnostics, co-occurring disorders and treatment. Fortschritte Der Neurologie Psychiatrie. [Review] 2009 May;77(5 ):263–71. [PubMed] [Google Scholar]
7. Peukert P, Sieslack S, Barth G, Batra A. Internet- and computer game addiction: Phenomenology, comorbidity, etiology, diagnostics and therapeutic implications for the addictives and their relatives. Psychiatrische Praxis. 2010 Jul;37(5 ):219–24. [PubMed] [Google Scholar]
8. Widyanto L, Griffiths MD. 'Internet addiction': a critical review. International Journal of Mental Health and Addiction. 2006 Jan;4(1 ):31–51. [Google Scholar]
9. American Psychiatric Association. Diagnostic and statistical manual of mental disorders. (4th ed., text rev.) Washington, DC: 2000. Author. [Google Scholar]
10. Young KS. Internet addiction: The emergence of a new clinical disorder. 104th annual meeting of the American Psychological Association; August 11 1996; Toronto, Canada. [Google Scholar]
11. American Psychiatric Association. DSM-5 Publication Date Moved to May 2013. 2009 [cited 2011 August 21]; [Press release]. Available from: http: //www.psych.org/MainMenu/Newsroom/ NewsReleases/2009NewsReleases/DSM-5-Publication-Date- Moved-.aspx .
12. Block JJ. Issues for DSM-V: Internet addiction. The American Journal of Psychiatry. 2008 Mar;165(3 ):306–7. [Editorial] [PubMed] [Google Scholar]
13. Pies R. Should DSM-V designate "Internet addiction" a mental disorder? Psychiatry. 2009 Feb;6(2 ):31–7. [PMC free article] [PubMed] [Google Scholar]
14. O'Brien CP. Commentary on Tao et al. (2010): Internet addiction and DSM-V. Addiction. [Comment/Reply] 2010 Mar;105(3 ):565. [Google Scholar]
15. Czincz J, Hechanova R. Internet addiction: Debating the diagnosis. Journal of Technology in Human Services. 2009 Oct;27(4 ):257–72. [Google Scholar]
16. Young KS. Caught in the net: how to recognize the signs of Internet addiction and a winning strategy for recovery. New York: J. Wiley; 1998. [Google Scholar]
17. Young KS. Internet addiction: the emergence of a new clinical disorder. CyberPsychology & Behavior. 1998 Fal ;1(3 ):237–44. [Google Scholar]
18. Kratzer S, Hegerl U. Is "Internet Addiction" a disorder of its own? A study on subjects with excessive internet use. Psychiatrische Praxis. 2008 Mar;35(2 ):80–3. [PubMed] [Google Scholar]
19. Grant JE, Potenza MN, Weinstein A, Gorelick DA. Introduction to behavioral addictions. The American Journal of Drug and Alcohol Abuse. 2010 Aug;36(5 ):233–41. [PMC free article] [PubMed] [Google Scholar]
20. American Society of Addiction Medicine. Public Policy Statement: Definition of Addiction. 2011 [cited 2011 August 21]; http: //www.asam.org/1DEFINITION_OF_ ADDICTION_LONG_4-11.pdf. Public Policy Statement: Definition of Addiction. 2011 [cited 2011 Augus.
21. Davis RA. A cognitive behavioral model of pathological internet use (PIU) Computers in Human Behavior. 2001;17(2 ):187–95. [Google Scholar]
22. Dowling NA, Quirk KL. Screening for Internet dependence: Do the proposed diagnostic criteria differentiate normal from dependent Internet use? CyberPsychology & Behavior. 2009 Feb;12(1 ):21–7. [PubMed] [Google Scholar]
23. Caplan SE. Problematic Internet use and psychosocial well-being: development of a theory-based cognitive-behavioral measurement instrument. Computers in Human Behavior. 2002;18(5 ):553–75. [Google Scholar]
24. Winkler A, Dörsing B. Treatment of internet addiction disorder: a first meta-analysis [Diploma thesis] Marburg: University of Marburg; 2011. [Google Scholar]
25. Byun S, Ruffini C, Mills JE, Douglas AC, Niang M, Stepchenkova S, et al. Internet addiction: metasynthesis of 1996-2006 quantitative research. CyberPsychology & Behavior. 2009 Apr;12(2 ):203–7. [PubMed] [Google Scholar]
26. Demetrovics Z, Szeredi B, Rozsa S. The three-factor model of Internet addiction: the development of the Problematic Internet Use Questionnaire. Behavior Research Methods. 2008;40(2 ):563–74. [PubMed] [Google Scholar]
27. Meerkerk G, Van Den Eijnden R, Vermulst A, Garretsen H. The Compulsive Internet Use Scale (CIUS): some psychometric properties. CyberPsychology & Behavior. 2009 Feb;12(1 ):1–6. [PubMed] [Google Scholar]
28. Chakraborty K, Basu D, Kumar K. Internet addiction: Consensus, controversies, and the way ahead. East Asian Archives of Psychiatry. 2010 Sep;20(3 ):123–32. [PubMed] [Google Scholar]
29. Young KS, Nabuco de Abreu C. Internet Addiction: A handbook and guide to evaluation and treatment. New Jersey: John Wiley & Sons Inc; 2011. [Google Scholar]
30. Young KS, Griffin-Shelley E, Cooper A, O'Mara J, Buchanan J. Online infidelity: A new dimension in couple relationships with implications for evaluation and treatment. Sexual Addiction & Compulsivity. 2000;7(1-2 ):59–74. [Google Scholar]
31. Cooper A, Putnam DE, Planchon LA, Boies SC. Online sexual compulsivity: getting tangled in the net. Sexual Addiction & Compulsivity. 1999;6(2 ):79–104. [Google Scholar]
32. Grohol JM. Internet addiction guide. Internet addiction guide. 1999 [updated 2005, April 16; cited 2011 April 20]; Available from: http: //psychcentral.com/ netaddiction/
33. Linden DJ. The Compass of Pleasure: How Our Brains Make Fatty Foods, Orgasm, Exercise, Marijuana, Generosity, Vodka, Learning, and Gambling Feel So Good. Viking Adult. 2011.
34. Gabor Maté MD. In the Realm of Hungry Ghosts: Close Encounters with Addiction. North Atlantic Books. 2010.
35. Bai Y-M, Lin C-C, Chen J-Y. Internet Addiction Disorder Among Clients of a Virtual Clinic. Psychiatric Services. 2001;52(10 ):1397. [Letter] [PubMed] [Google Scholar]
36. Ko C-H, Liu G-C, Hsiao S, Yen J-Y, Yang M-J, Lin W-C, et al. Brain activities associated with gaming urge of online gaming addiction. Journal of Psychiatric Research. 2009;43(7 ):739–47. [PubMed] [Google Scholar]
37. Amichai-Hamburger Y, Ben-Artzi E. Loneliness and Internet use. Computers in Human Behavior. 2003;19(1 ):71–80. [Google Scholar]
38. Eisen S, Lin N, Lyons M, Scherrer J, Griffith K, True W, et al. Familial influences on gambling behavior: an analysis of 3359 twin pairs. Addiction. 1998 Sep;1998:1375–84. [PubMed] [Google Scholar]
39. Grant JE, Brewer JA, Potenza MN. The neurobiology of substance and behavioral addictions. CNS Spectrums. 2006. 2006 Dec;11(12 ):924–30. [PubMed] [Google Scholar]
40. Dong G, Lu Q, Zhou H, Zhao X. Precursor or sequela: pathological disorders in people with Internet addiction disorder. Public Library of Science One [serial on the Internet] 2011;6(2 ) Available from: http: //www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal. pone.0014703 . [PMC free article] [PubMed] [Google Scholar]
41. Young KS. Internet Addiction: Symptoms, Evaluation, And Treatment. Innovations in Clinical Practice [serial on the Internet]. 1999;17 Available from: http: //treatmentcenters.com/downloads/ internet-addiction.pdf . [Google Scholar]
42. Arisoy O. Internet addiction and its treatment. Psikiyatride Guncel Yaklasimlar. 2009;1(1 ):55–67. [Google Scholar]
43. Atmaca M. A case of problematic Internet use successfully treated with an SSRI-antipsychotic combination. Progress in Neuro-Psychopharmacology & Biological Psychiatry. 2007 May;31(4 ):961–2. [Letter] [PubMed] [Google Scholar]
44. Huang X-q, Li M-c, Tao R. Treatment of Internet addiction. Current Psychiatry Reports. 2010 Oct ;12(5 ):462–70. [PubMed] [Google Scholar]
45. Sattar P, Ramaswamy S. Internet gaming addiction. Canadian Journal of Psychiatry. 2004 Dec;49(12 ):871–2. [Google Scholar]
46. Wieland DM. Computer addiction: implications for nursing psychotherapy practice. Perspectives in Psychiatric Care. 2005 Oct-Dec;41(4 ):153–61. [PubMed] [Google Scholar]
47. Dell'Osso B, Hadley S, Allen A, Baker B, Chaplin WF, Hollander E. Escitalopram in the treatment of impulsive-compulsive Internet usage disorder: an open-label trial followed by a double-blind discontinuation phase. Journal of Clinical Psychiatry. 2008 Mar;69(3 ):452–6. [PubMed] [Google Scholar]
48. Han DH, Hwang JW, Renshaw PF. Bupropion sustained release treatment decreases craving for video games and cue-induced brain activity in patients with Internet video game addiction. Experimental and Clinical Psychopharmacology. 2010 Aug;18(4 ):297–304. [PubMed] [Google Scholar]
49. Han DH, Lee YS, Na C, Ahn JY, Chung US, Daniels MA, et al. The effect of methylphenidate on Internet video game play in children with attention-deficit/hyperactivity disorder. Comprehensive Psychiatry. 2009 May-Jun;50(3 ):251–6. [PubMed] [Google Scholar]
50. Shapira NA, Goldsmith TD, Keck PE , Jr, Khosla UM, McElroy SL. Psychiatric features of individuals with problematic Internet use. Journal of affective disorders. 2000 Jan-Mar;57(1-3 ):267–72. [PubMed] [Google Scholar]
51. Bostwick JM, Bucci JA. Internet sex addiction treated with naltrexone. Mayo Clinic Proceedings. 2008;83(2 ):226–30. [PubMed] [Google Scholar]
52. Greenfield DN. Suchtfalle Internet. Hilfe fuer Cyberfreaks, Netheads und ihre Partner. Virtual addiction: Zuerich: Walter. 2000.
53. Lanjun Z. The applications of group mental therapy and sports exercise prescriptions in the intervention of Internet addiction disorder. Psychological Science (China) 2009 May;32(3 ):738–41. [Google Scholar]
54. Miller WR, Rollnick S. In: Motivational interviewing: preparing people for change. 2nd ed. Miller WR, Rollnick S, editors. New York: Guilford Press; 2002. [Google Scholar]
55. Miller NH. Motivational interviewing as a prelude to coaching in healthcare settings. Journal of Cardiovascular Nursing. 2010 May-Jun;25(3 ):247–51. [PubMed] [Google Scholar]
56. Burke BL, Arkowitz H, Menchola M. The efficacy of motivational interviewing: a meta-analysis of controlled clinical trials. Journal of consulting and clinical psychology. 2003 Oct;71(5 ):843–61. [PubMed] [Google Scholar]
57. Meyers RJ, Miller WR, Smith JE. Community reinforcement and family training (CRAFT) In: Meyers RJ, Miller WR, editors. A community reinforcement approach to addiction treatment. New York, NY: Cambridge University Press; US; 2001. pp. 147–60. [Google Scholar]
58. Kim J-U. A reality therapy group counseling program as an Internet addiction recovery method for college students in Korea. International Journal of Reality Therapy. 2007 Spr ;26(2 ):3–9. [Google Scholar]
59. Kim J-U. The effect of a R/T group counseling program on the Internet addiction level and self-esteem of Internet addiction university students. International Journal of Reality Therapy. 2008 Spr; 27(2 ):4–12. [Google Scholar]
60. Twohig MP, Crosby JM. Acceptance and Commitment Therapy as a treatment for problematic Internet pornography viewing. Behavior Therapy. 2010 Sep;41(3 ):285–95. [PubMed] [Google Scholar]
61. Abreu CN, Goes DS. Psychotherapy for Internet addiction. In: Young KS, de Abreu CN, editors. Internet addiction: A handbook and guide to evaluation and treatment. Hoboken, NJ: John Wiley & Sons Inc; US; 2011. pp. 155–71. [Google Scholar]
62. Young KS. Cognitive behavior therapy with Internet addicts: treatment outcomes and implications. CyberPsychology & Behavior. 2007 Oct;10(5 ):671–9. [PubMed] [Google Scholar]
63. Cao F-L, Su L-Y, Gao X-P. Control study of group psychotherapy on middle school students with Internet overuse. Chinese Mental Health Journal. 2007 May;21(5 ):346–9. [Google Scholar]
64. Li G, Dai X-Y. Control study of cognitive-behavior therapy in adolescents with Internet addiction disorder. Chinese Mental Health Journal. 2009 Jul;23(7 ):457–70. [Google Scholar]
65. Zhu T-m, Jin R-j, Zhong X-m. Clinical effect of electroacupuncture combined with psychologic interference on patient with Internet addiction disorder. Chinese Journal of Integrated Traditional & Western Medicine. 2009 Mar;29(3 ):212–4. [PubMed] [Google Scholar]
66. Orzack MH, Orzack DS. Treatment of computer addicts with complex co-morbid psychiatric disorders. Cyberpsychology & Behavior. 1999;2(5 ):465–73. [PubMed] [Google Scholar]
67. Du Y-s, Jiang W, Vance A. Longer term effect of randomized, controlled group cognitive behavioural therapy for Internet addiction in adolescent students in Shanghai. Australian and New Zealand Journal of Psychiatry. 2010;44(2 ):129–34. [PubMed] [Google Scholar]
68. Fang-ru Y, Wei H. The effect of integrated psychosocial intervention on 52 adolescents with Internet addiction disorder. Chinese Journal of Clinical Psychology. 2005 Aug;13(3 ):343–5. [Google Scholar]
69. Orzack MH, Voluse AC, Wolf D, Hennen J. An ongoing study of group treatment for men involved in problematic Internet-enabled sexual behavior. CyberPsychology & Behavior. 2006 Jun;9(3 ):348–60. [PubMed] [Google Scholar]
70. Rong Y, Zhi S, Yong Z. Comprehensive intervention on Internet addiction of middle school students. Chinese Mental Health Journal. 2006 Jul;19(7 ):457–9. [Google Scholar]
71. Shek DTL, Tang VMY, Lo CY. Evaluation of an Internet addiction treatment program for Chinese adolescents in Hong Kong. Adolescence. 2009;44(174 ):359–73. [PubMed] [Google Scholar]
72. Bai Y, Fan FM. The effects of group counseling on Internet-dependent college students. Chinese Mental Health Journal. 2007;21(4 ):247–50. [Google Scholar]
73. reSTART: Internet Addiction Recovery Program. First detox center for Internet addicts opens its doors: Creates solutions for computer related addictive behaviors. 2009. [[cited 2011 August 21]]. Available from: http: //www.netaddictionrecovery.com .
74. Lambert MJ, Morton JJ, Hatfield D, Harmon C, Hamilton S, Reid RC, et al. Administration and Scoring Manual for the OQ-45.2 (Outcome Measures) American Professional Credentialing Services L.L.C. 2004.
Formats:
Article | PubReader | ePub (beta) | PDF (214K) | Cite
Share
 Facebook Twitter Google+
Save items
Add to Favorites
View more options
Similar articles in PubMed
A nationwide survey of the prevalence and psychosocial correlates of internet addictive disorders in Taiwan.
[J Formos Med Assoc. 2019]
[Internet Addiction Disorder in a Sample of 402 High School Students].
[Psychiatr Pol. 2015]
Internet addiction disorder and problematic use of Google Glass™ in patient treated at a residential substance abuse treatment program.
[Addict Behav. 2015]
Internet addiction or excessive internet use.
[Am J Drug Alcohol Abuse. 2010]
Behavioral addictions in addiction medicine: from mechanisms to practical considerations.
[Prog Brain Res. 2016]
See reviews...
See all...
Cited by other articles in PMC
Internet Addiction Among Male Adolescents in Indonesia: A Qualitative Study
[American Journal of Men's Heal...]
Emerging Health and Education Issues Related to Internet Technologies and Addictive Problems
[International Journal of Envir...]
Association of Internet Addiction with Family Functionality, Depression, Self-Efficacy and Self-Esteem among Early Adolescents
[International Journal of Envir...]
Involvement of DAT1 Gene on Internet Addiction: Cross-Correlations of Methylation Levels in 5′-UTR and 3’-UTR Genotypes, Interact with Impulsivity and Attachment-Driven Quality of Relationships
[International Journal of Envir...]
Adolescent internet addiction – role of parental control and adolescent behaviours
[International Journal of Pedia...]
See all...
Links
MedGen
PubMed
Taxonomy
Recent Activity
Clear
Turn Off
Internet Addiction: A Brief Summary of Research and Practice
Internet Addiction: A Brief Summary of Research and Practice
Bentham Open Access. 2012 Nov; 8(4)292
See more...
Internet addiction: a review of current assessment techniques and potential assessment questions.
[Cyberpsychol Behav. 2005]
Screening for Internet dependence: do the proposed diagnostic criteria differentiate normal from dependent Internet use?
[Cyberpsychol Behav. 2009]
Internet addiction: metasynthesis of 1996-2006 quantitative research.
[Cyberpsychol Behav. 2009]
Internet addiction: a review of current assessment techniques and potential assessment questions.
[Cyberpsychol Behav. 2005]
The three-factor model of Internet addiction: the development of the Problematic Internet Use Questionnaire.
[Behav Res Methods. 2008]
The Compulsive Internet Use Scale (CIUS): some psychometric properties.
[Cyberpsychol Behav. 2009]
Internet addiction: consensus, controversies, and the way ahead.
[East Asian Arch Psychiatry. 2010]
Review [Internet- and computer game addiction: phenomenology, comorbidity, etiology, diagnostics and therapeutic implications for the addictives and their relatives].
[Psychiatr Prax. 2010]
Review Internet addiction or excessive internet use.
[Am J Drug Alcohol Abuse. 2010]
Internet addiction disorder among clients of a virtual clinic.
[Psychiatr Serv. 2001]
Brain activities associated with gaming urge of online gaming addiction.
[J Psychiatr Res. 2009]
Familial influences on gambling behavior: an analysis of 3359 twin pairs.
[Addiction. 1998]
Review The neurobiology of substance and behavioral addictions.
[CNS Spectr. 2006]
Internet addiction: a review of current assessment techniques and potential assessment questions.
[Cyberpsychol Behav. 2005]
[Is "Internet Addiction" a disorder of its own?--a study on subjects with excessive internet use].
[Psychiatr Prax. 2008]
Precursor or sequela: pathological disorders in people with Internet addiction disorder.
[PLoS One. 2011]
Review [Pathological Internet use--epidemiology, diagnostics, co-occurring disorders and treatment].
[Fortschr Neurol Psychiatr. 2009]
Computer addiction: implications for nursing psychotherapy practice.
[Perspect Psychiatr Care. 2005]
Escitalopram in the treatment of impulsive-compulsive internet usage disorder: an open-label trial followed by a double-blind discontinuation phase.
[J Clin Psychiatry. 2008]
Bupropion sustained release treatment decreases craving for video games and cue-induced brain activity in patients with Internet video game addiction.
[Exp Clin Psychopharmacol. 2010]
The effect of methylphenidate on Internet video game play in children with attention-deficit/hyperactivity disorder.
[Compr Psychiatry. 2009]
Psychiatric features of individuals with problematic internet use.
[J Affect Disord. 2000]
A case of problematic internet use successfully treated with an SSRI-antipsychotic combination.
[Prog Neuropsychopharmacol Biol Psychiatry. 2007]
Internet sex addiction treated with naltrexone.
[Mayo Clin Proc. 2008]
Motivational interviewing as a prelude to coaching in healthcare settings.
[J Cardiovasc Nurs. 2010]
The efficacy of motivational interviewing: a meta-analysis of controlled clinical trials.
[J Consult Clin Psychol. 2003]
Review [Internet- and computer game addiction: phenomenology, comorbidity, etiology, diagnostics and therapeutic implications for the addictives and their relatives].
[Psychiatr Prax. 2010]
Acceptance and commitment therapy as a treatment for problematic internet pornography viewing.
[Behav Ther. 2010]
Review [Gambling and internet addiction: review and research agenda].
[Nervenarzt. 2009]
Cognitive behavior therapy with Internet addicts: treatment outcomes and implications.
[Cyberpsychol Behav. 2007]
[Clinical effect of electroacupuncture combined with psychologic interference on patient with Internet addiction disorder].
[Zhongguo Zhong Xi Yi Jie He Za Zhi. 2009]
Treatment of computer addicts with complex co-morbid psychiatric disorders.
[Cyberpsychol Behav. 1999]
Longer term effect of randomized, controlled group cognitive behavioural therapy for Internet addiction in adolescent students in Shanghai.
[Aust N Z J Psychiatry. 2010]
An ongoing study of group treatment for men involved in problematic Internet-enabled sexual behavior.
[Cyberpsychol Behav. 2006]
Evaluation of an Internet addiction treatment program for Chinese adolescents in Hong Kong.
[Adolescence. 2009]
Internet addiction: a review of current assessment techniques and potential assessment questions.
[Cyberpsychol Behav. 2005]
Review [Gambling and internet addiction: review and research agenda].
[Nervenarzt. 2009]
Review [Pathological Internet use--epidemiology, diagnostics, co-occurring disorders and treatment].
[Fortschr Neurol Psychiatr. 2009]
Support Center
Support Center
External link. Please review our privacy policy.
NLM
NIH
DHHS
USA.gov

National Center for Biotechnology Information, U.S. National Library of Medicine
8600 Rockville Pike, Bethesda MD, 20894 USA

Policies and Guidelines | Contact]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Windows Hello Bypass Fools Biometrics Safeguards | Threatpost]]></title>
            <link>https://threatpost.com/windows-hello-bypass-biometrics-pcs/167771/</link>
            <guid>https://threatpost.com/windows-hello-bypass-biometrics-pcs/167771/</guid>
            <pubDate>Wed, 14 Jul 2021 19:56:42 GMT</pubDate>
            <content:encoded><![CDATA[Threatpost
 Search
Microsoft Crushes 116 Bugs, Three Actively Exploited
Updated Joker Malware Floods into Android Apps
Windows Hello Bypass Fools Biometrics Safeguards in PCs
Author:
Elizabeth Montalbano
July 14, 2021  7:05 am
3:30 minute read
 Write a comment

Share this article:

A Windows security bug would allow an attacker to fool a USB camera used in the biometric facial-recognition aspect of the system.

A vulnerability in Microsoft’s Windows 10 password-free authentication system has been uncovered that could allow an attacker to spoof an image of a person’s face to trick the facial-recognition system and take control of a device.

Windows Hello is a feature in Windows 10 that allows users to authenticate themselves without a password, using a PIN code or biometric identity—either a fingerprint or facial recognition—to access a device or machine. According to Microsoft, about 85 percent of Windows 10 users use the system.

The Windows Hello bypass vulnerability, tracked as CVE-2021-34466, requires an attacker to have physical access to a device to exploit it, according to researchers at CyberArk Labs who discovered the flaw in March.

From there, they can go on “to manipulate the authentication process by capturing or recreating a photo of the target’s face and subsequently plugging in a custom-made USB device to inject the spoofed images to the authenticating host,” Omer Tsarfati, cybersecurity researcher at CyberArk Labs, wrote in a report about the vulnerability published Tuesday.

Further, exploitation of the bypass can extend beyond Windows Hello systems to “any authentication system that allows a pluggable third-party USB camera to act as biometric sensor,” Tsarfati noted.

Researchers have no evidence that anyone has tried or used the attack in the wild, but someone with motive could potentially use it on a targeted espionage victim, such as “a researcher, scientist, journalist, activist or privileged user with sensitive IP on their device, for example,” according to the analysis.

Microsoft addressed the vulnerability — which affects both consumer and business versions of the feature — in its July Patch Tuesday update. Also, Windows users with Windows Hello Enhanced Sign-in Security — a new security feature in Windows that requires specialized and pre-installed hardware, drivers and firmware — are protected against the any attacks “which tamper with the biometrics pipeline,” according to Microsoft.

However, Tsarfati said that the solution may not fully mitigate the issue.

“Based on our preliminary testing of the mitigation, using Enhanced Sign-in Security with compatible hardware limits the attack surface but is dependent on users having specific cameras,” he said. “Inherent to system design, implicit trust of input from peripheral devices remains. To mitigate this inherent trust issue more comprehensively, the host should validate the integrity of the biometric authentication device before trusting it.”

Biometric Weakest Link

CyberArk researchers posted a video of a proof-of-concept (PoC) for how to exploit the vulnerability, which can be used on both the consumer version, Windows Hello, and an enterprise version of the feature called Windows Hello for Business (WHfB) that businesses use with ActiveDirectory.

The bypass itself exploits a weakness in the biometric sensor of Windows Hello, which “transmits information on which the OS … makes its authentication decision,” he wrote. “Therefore, manipulating this information can lead to a potential bypass to the whole authentication system,” Tsarfati said.

For facial recognition, the biometric sensor is either a camera embedded in a device, such as a laptop, or connected to a computer via USB. Therefore, the entire process depends on this camera for proof of identity–which is where the vulnerability lies, particularly when a USB camera is used for authentication, he wrote.

“The answer lies in the input itself,” Tsarfati wrote. “Keyboard input is known only to the person who is typing before the information is entered into the system, while camera input isn’t.”

Therefore, using a camera to access “public” information—i.e., a person’s face—for authentication can easily be hijacked, he explained.

“It is similar to stealing a password, but much more accessible since the data (face) is out there,” Tsarfati wrote. “At the heart of this vulnerability lies the fact that Windows Hello allows external data sources, which can be manipulated, as a root of trust.”

Attack Vector

Researchers detailed a somewhat complex way for an attacker to capture someone’s image, save the captured frames, impersonate a USB camera device, and eventually send those frames to the Windows hello system for verification.

To prove the concept, they created a custom USB device that acts as a USB camera with both infrared (IR) and Red Green Blue (RGB) sensors, using an evaluation board manufactured by NXP. They used this custom camera to transmit valid IR frames of the person they were targeting, while sending the RGB frames image of the cartoon character SpongeBob SquarePants.

“To our surprise, it worked!” Tsarfati wrote.

Based on this understanding, an attacker would only need to  implement a USB camera that supports RGB and IR cameras and then send only one genuine IR frame of a victim to bypass the login phase of the device, while the RGB frames can contain any random image, he explained.

The entire process depends on an attacker having an IR frame of a potential victim to use in an attack, which can be done either by capturing one or converting one of the person’s regular RBG frames to an IR one, Tsarfati explained.

“Our findings show that any USB device can be cloned, and any USB device can impersonate any other USB device,” he said.  “We used the IR frames of a person to ‘bypass’ the face recognition mechanism. We believe that those IR frames can be created out of regular color images.”

Check out our free upcoming live and on-demand webinar events – unique, dynamic discussions with cybersecurity experts and the Threatpost community.

 

Write a comment

Share this article:

Vulnerabilities
Web Security
SUGGESTED ARTICLES
Apps Built Better: Why DevSecOps is Your Security Team’s Silver Bullet

Phil Richards, vice president and CSO at Ivanti, explains how organizations can design DevOps processes and systems to thwart cyberattacks.

July 14, 2021
Microsoft Crushes 116 Bugs, Three Actively Exploited

Microsoft tackles 12 critical bugs, part of its July 2021 Patch Tuesday roundup, capping a ‘PrintNightmare’ month of headaches for system admins.

July 13, 2021
Linux-Focused Cryptojacking Gang Tracked to Romania

The gang is using a new brute-forcer – “Diicot brute” – to crack passwords on Linux-based machines with weak passwords.

July 14, 2021
Apps Built Better: Why DevSecOps is Your Security Team’s Silver Bullet

Phil Richards, vice president and CSO at Ivanti, explains how organizations can design DevOps processes and systems to thwart cyberattacks.

July 14, 2021
Microsoft Crushes 116 Bugs, Three Actively Exploited

Microsoft tackles 12 critical bugs, part of its July 2021 Patch Tuesday roundup, capping a ‘PrintNightmare’ month of headaches for system admins.

July 13, 2021
Linux-Focused Cryptojacking Gang Tracked to Romania

The gang is using a new brute-forcer – “Diicot brute” – to crack passwords on Linux-based machines with weak passwords.

July 14, 2021
Apps Built Better: Why DevSecOps is Your Security Team’s Silver Bullet

Phil Richards, vice president and CSO at Ivanti, explains how organizations can design DevOps processes and systems to thwart cyberattacks.

July 14, 2021
Microsoft Crushes 116 Bugs, Three Actively Exploited

Microsoft tackles 12 critical bugs, part of its July 2021 Patch Tuesday roundup, capping a ‘PrintNightmare’ month of headaches for system admins.

July 13, 2021
DISCUSSION
Leave A Comment
Save my name, email, and website in this browser for the next time I comment.

Notify me when new comments are added.

 

This site uses Akismet to reduce spam. Learn how your comment data is processed.

INFOSEC INSIDER
Apps Built Better: Why DevSecOps is Your Security Team’s Silver Bullet
July 14, 2021
Is Remote Desktop Protocol Secure? It Can Be
July 13, 2021
 1
How Fake Accounts and Sneaker-Bots Took Over the Internet
July 8, 2021
Why I Love (Breaking Into) Your Security Appliances
July 7, 2021
Ransomware Defense: Top 5 Things to Do Right Now
July 5, 2021
 1
Newsletter
Subscribe to Threatpost Today 

Join thousands of people who receive the latest breaking cybersecurity news every day.

Subscribe now
Twitter

A #vulnerability in @Microsoft’s #Windows 10 password-free #authentication could allow a #cyberattacker to spoof an… https://t.co/NQqrgJV7tM

1 hour ago

Follow @threatpost
Subscribe to our newsletter, Threatpost Today! 

Get the latest breaking news delivered daily to your inbox.

Subscribe now
Threatpost

The First Stop For Security News

Home
About Us
Contact Us
Advertise With Us
RSS Feeds
Copyright © 2021 Threatpost
Privacy Policy
Terms and Conditions
Advertise
TOPICS
Black Hat
Breaking News
Cloud Security
Critical Infrastructure
Cryptography
Facebook
Government
Hacks
IoT
Malware
Mobile Security
Podcasts
Privacy
RSAC
Security Analyst Summit
Videos
Vulnerabilities
Web Security
We use cookies to make your experience of our websites better. By using and further navigating this website you accept this. Detailed information about the use of cookies on this website is available by clicking on more information.

ACCEPT AND CLOSE]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Cybersecurity organizations announce new first responder credentialing program | ZDNet]]></title>
            <link>https://www.zdnet.com/article/cybersecurity-organizations-announce-new-first-responder-credentialing-program/</link>
            <guid>https://www.zdnet.com/article/cybersecurity-organizations-announce-new-first-responder-credentialing-program/</guid>
            <pubDate>Wed, 14 Jul 2021 19:56:07 GMT</pubDate>
            <content:encoded><![CDATA[	
	
MENU
	
	
US
 MUST READ: Windows 11: Everything you need to know
Cybersecurity organizations announce new first responder credentialing program

CISA and the ISA Global Cybersecurity Alliance are working together to certify first responders for cyber incidents.

By Jonathan Greig | July 13, 2021 -- 21:00 GMT (14:00 PDT) | Topic: Government : US

Cybersecurity companies and organizations are banding together to create a cybersecurity first responder credentialing program designed to support both large and small organizations dealing with cyber incidents. 

The ISA Global Cybersecurity Alliance is working with CISA on the effort alongside the Incident Command System for Industrial Control Systems (ICS4ICS) and more than 50 other cybersecurity companies, universities and corporations. 

The groups will be incorporating FEMA's Incident Command System framework for response structure, roles, and interoperability, according to a statement from ISA. 

Deloitte, Dragos, Ford Motor Company, Fortinet, Honeywell, Johnson Controls, KPMG, Nozomi Networks, Pfizer, Tenable, CyberOwl and Idaho State University are just a few of the organizations involved in the ISA Global Cybersecurity Alliance. 

"For many years, we've needed ICS4ICS, to enable collectively organized cyber and physical responses in a unified way. Credentialing cybersecurity first responders is an important milestone in this valuable public-private partnership," said ISAGCA Advisory Board chairperson Megan Samford, 

Samford, who is also chief product security officer of Schneider Electric's energy management business, said the groups have "developed an adjudication process and certified our first four responders."

The first round of credentials were given to Samford, CISA branch chief of cyber defense coordination Mark Bristow, FireEye senior manager of industrial control systems Neal Gay and the US Army Reserve's Brian Wisniewski. 

"I'm proud to be one of them and stand ready to help companies recover from cyber incidents," Samford added. 

FEMA's Incident Command System framework is currently used in response to natural disasters, industrial accidents and other incidents while the ICS4ICS' methods are used by organizations to identify incidents, assess any damage, address immediate challenges, communicate with stakeholders and eventually resume operations. 

Senator slams panel for passing a "surveillance bill by another name"

A Senate committee overwhelmingly passes a controversial bill aimed at sharing user data with the government, in efforts to prevent cyberattacks. Just one lawmaker opposed.

Read More

"The framework applies traditional Incident Command Systems best practices to cybersecurity incidents, ensuring common terminology and enabling diverse incident management and support entities to work together," the groups said in a statement.  

"ICS4ICS provides clearly defined command structures, including standard roles needed in a response, and the framework can scale to support small or extremely large-scale incidents that impact many organizations."

A committee within ICS4ICS will manage the adjudication process, which the organization said will involve applications and candidate evaluations by a panel of incident command system subject matter experts. 

"The proven approach is vetted by industry companies and subject matter experts and the program has significant value for small to medium sized entities that do not have the time, finances, or personnel to assign a full-time cyber response unit, but still need to develop plans and train employees accordingly," the groups said. 

RELATED TOPICS: SECURITY CXO INNOVATION SMART CITIES

By Jonathan Greig | July 13, 2021 -- 21:00 GMT (14:00 PDT) | Topic: Government : US

 SHOW COMMENTS
MORE FROM JONATHAN GREIG

Security

REvil websites down after governments pressured to take action following Kaseya attack

Apple

JetBlue to give pilots iPad Pro for flights

Security

Guess announces breach of employee SSNs and financial data after DarkSide ransomware attack

Security

SolarWinds releases security advisory after Microsoft discovers vulnerability

NEWSLETTERS
ZDNet Week in Review - US
A weekly summary of the news that matters in business technology.
 SUBSCRIBE
SEE
ALL
MORE RESOURCES

Live demo: AI-driven Enterprise

White Papers from Juniper Networks
 GET IT TODAY

Gartner IT Symposium/Xpo™: Leading today and tomorrow

Live Event from Gartner
 REGISTER NOW

NGINX finds out the truth about your Apps - the good, the bad and the ugly!

Resource Center from NGINX
 LEARN MORE
RELATED STORIES
 1 of 3 

US charges Greek national for selling insider trading subscriptions in the Dark Web

"TheBull" offered customers insider information, tips, and pre-release earnings.

REvil websites down after governments pressured to take action following Kaseya attack

Biden said last week that he expected the Russian government to "act" if given information on who and where ransomware actors are.

US Senate confirms Jen Easterly as head of cyber agency

Easterly brings both corporate and military experience to the Cybersecurity and Infrastructure Security Agency

ZDNet
CONNECT WITH US
 
 
 

© 2021 ZDNET, A RED VENTURES COMPANY. ALL RIGHTS RESERVED. Privacy Policy | Cookie Settings | Advertise | Terms of Use

Topics
Galleries
Videos
Sponsored Narratives
Do Not Sell My Information
Join | Log In
Membership
Newsletters
Site Assistance
ZDNet Academy
TechRepublic Forums


Give Us Your Feedback!
Fill out this confidential survey and you could help make ZDNet better for users everywhere.

TAKE THIS SURVEY
When you reply to this survey, you acknowledge that Red Ventures collects your personal data in accordance with the Red Ventures privacy policy available here]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[CNN - Breaking News, Latest News and Videos]]></title>
            <link>https://lite.cnn.com/en/article/h_ec46398606c2a4b6de9e83db6c4c09ef</link>
            <guid>https://lite.cnn.com/en/article/h_ec46398606c2a4b6de9e83db6c4c09ef</guid>
            <pubDate>Wed, 14 Jul 2021 19:56:02 GMT</pubDate>
            <content:encoded><![CDATA[CNN | 7/14/2021 | Listen
Experts are bracing for a spike in STDs, but not just because it's 'hot vax summer'

By Rachel Trent, CNN

Updated: Wed, 14 Jul 2021 16:30:11 GMT

Source: CNN

After more than a year of Americans being urged to practice the safe six (feet), infectious disease specialists want to remind them about safe sex.

While different people reacted to pandemic safety guidelines in different ways, for some Americans, lockdown meant less sex. But as more vaccines are administered, social restrictions are getting relaxed -- and some people seem to be ready to make up for lost time by embracing their "hot vax summer."

Male condom sales shot up 23.4% to $37 million during the four weeks ending April 18, compared to the same stretch in 2020, according to market research firm IRI. That increase followed a 4.4% drop in all of 2020.

But while many see the further reopening of the economy as a sign that Covid-19 is less of a health crisis, there are other viruses and bacteria out there -- such as those that are sexually transmitted. And physicians warn a rise in STD cases is on the way. But that's not just because vaccinated singles are ready to mingle again.

Rates were already rising

Reported STDs in the United States reached an all-time high for the sixth consecutive year in 2019, according to the US Centers for Disease Control and Prevention, with more than 2.5 million cases of chlamydia, gonorrhea and syphilis reported.

These reportable STDs increased by nearly 30% between 2015 and 2019, the agency said.

Experts told CNN these worrisome trends can be tied to several factors.

Dr. Hunter Handsfield, a professor emeritus of medicine at the University of Washington Center for AIDS and STD, told CNN one of those could be that people are using condoms less. He said this applies particularly to men who have sex with men because they see that layer of protection, plus selecting uninfected partners, as less important now that there are more tools to prevent HIV, specifically, pre-exposure prophylaxis, or PrEP -- pills people at high risk can take to prevent infection.

There are also changed attitudes about sexuality.

"People currently in their teens and 20s, I think, there are different attitudes and beliefs about what constitutes a committed relationship and what doesn't," Handsfield said.

Additionally, there are more resources to meet sexual partners, including dating apps, which have less of a stigma compared to years past.

The CDC notes high infection levels can also be impacted by obstacles to prevention and care, such as poverty, unstable housing or lack of a medical home.

Add a pandemic that requires health care systems to reallocate staff from STD prevention to helping fight a deadly respiratory virus and these problems get exacerbated.

Numbers don't tell the whole story

The CDC says preliminary 2020 data suggest many of these concerning trends continued into 2020, when the Covid-19 pandemic disrupted STD testing and treatment services.

In a September press briefing, Dr. Hilary Reno, a medical consultant with the Division of STD Prevention at the CDC, detailed how the pandemic led to a dramatic drop in STD testing last year.

BJC HealthCare, one of the main hospitals in the St. Louis metro region, saw testing decline after the first positive Covid-19 case in March, Reno said. After the city issued stay-at-home orders, testing for gonorrhea and chlamydia dropped 45%. Reno added this amounted to about 4,400 missed gonorrhea and chlamydia tests in a 10-week period in this region.

HIV testing had a similar pattern, with an estimated 5,000 missed tests in the same period, Reno said.

Handsfield told CNN it is difficult to know for sure what really happened to the number of STD cases during the peak of the pandemic.

"The notion that there is a risk that they will rebound, to me, makes a certain amount of sense. But it's with that caveat that we really don't know very well how to interpret the data behind those observations," Handsfield said.

Testing also may have increased pre-pandemic.

Dr. Kees Rietmeijer, former director of the STD Control Program at the Denver Public Health Department, pointed out to CNN that, like Covid-19, "the more you test, the more you find." But unlike coronavirus cases, the number of negative STD tests is not reported, so the positivity rate isn't known.

Not all sex stopped

One way sexually transmitted infections are like Covid-19 is that many cases are asymptomatic, said Dr. Julie Dombrowski, an associate professor of medicine at the University of Washington who also does research on HIV and STI clinical and public health services.

That means the decrease in testing resulted in a number of STDs that went undetected and untreated, which presumably led to some ongoing transmission, Dombrowski told CNN. She noted chlamydia is especially an issue in this case, as it is usually asymptomatic and can lead to infertility and other reproductive issues.

And while some people may have been less sexually active during the pandemic, not all sex stopped, so those pre-pandemic infections didn't just disappear.

Dr. Edward Hook, a professor of medicine at the University of Alabama at Birmingham, told CNN part of maintaining sexual health is realizing these infections are more common than many people think.

"Nobody wants to think they've got a sexually transmitted infection or going to get one," he said.

Rietmeijer echoed Hook, pointing out that the approach to treating STDs has focused on the clinical aspect, rather than the individual and societal impacts, such as inequity in health care and a stigma that can hinder people from taking preventative measures seriously.

A National Academies of Sciences, Engineering Medicine report, which Hook and Rietmeijer worked on, said "the national response to STIs must also consider the root causes of poor health," which range from racism and poverty to social stigma.

A lack of timely diagnosis or preventative measures can lead to dangerous consequences.

For example, human papillomavirus (HPV), can cause cervical cancer, head and neck cancer, and cancers of the anus and penis.

The good news is, STDs are preventable and treatable.

Preventative measures

Vaccines are recommended for protection against hepatitis B and HPV. The HPV vaccine is recommended for preteens ages 11 or 12 and everyone through age 26, though it's approved for anyone through age 45. The hepatitis B vaccine is recommended for infants at birth, with the series of shots being completed at 6 months. It's also recommended for certain unvaccinated adults, such as those with sexual partners who have hepatitis B.

The CDC recommends everyone from ages 13 to 64 be tested at least once for HIV. But people at higher risk, which includes men who have sex with men, should get tested more often. Those men should get tested every three to six months. Anyone else who has unsafe sex should get tested for HIV at least once a year.

All sexually active women younger than 25 years should be tested for gonorrhea and chlamydia every year, according to the agency's guidance. All pregnant women should be tested for syphilis, HIV and hepatitis B starting early in pregnancy. All men who have sex with men should be tested at least once a year for syphilis, chlamydia and gonorrhea. (You can look for a place to get tested near you with the CDC's GetTested tool.)

Hook said another element of maintaining good sexual health involves having a conversation with sexual partners.

"Hopefully people are interested in each other's health as well as their own," he said. "Increasingly, although not increasingly enough, we are seeing and we continue to encourage couples who are thinking about or planning to initiate sexual activity, or even couples who have just recently begun sexual activity together, to go together to be screened for STIs."

© 2021 Cable News Network. A Warner Media Company. All Rights Reserved.

Listen to CNN (low-bandwidth usage)

Go to the full CNN experience]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Marine Corps Meets THOR, Verizon’s Futuristic 5G-Enabled Response Vehicle - Nextgov]]></title>
            <link>https://www.nextgov.com/emerging-tech/2021/06/marine-corps-meets-thor-verizons-futuristic-5g-enabled-response-vehicle/174976/</link>
            <guid>https://www.nextgov.com/emerging-tech/2021/06/marine-corps-meets-thor-verizons-futuristic-5g-enabled-response-vehicle/174976/</guid>
            <pubDate>Wed, 14 Jul 2021 19:56:01 GMT</pubDate>
            <content:encoded><![CDATA[CONTINUE TO THE SITE →
National Park Service To Share Special Use Permit Data With White House
Report: DOD Budget Request Shows IT Increases, Shift To Information Warfare Focus
Cybersecurity Funding Faces Political Clash During Appropriations Markup
SPONSOR CONTENT
Beyond TDM
Skip to Content
Marine Corps Meets THOR, Verizon’s Futuristic 5G-Enabled Response Vehicle

Verizon's Tactical Humanitarian Operations Response vehicle. VERIZON

Sponsor Message

Get the latest federal technology news delivered to your inbox.

email

Sponsor Message

Featured eBooks

By BRANDI VINCENT

JUNE 25, 2021
The vehicle is the first of its kind.
5G
DEFENSE

This week, the Marine Corps and Verizon deployed the latter’s new, next-generation communication and disaster response prototype—a Tactical Humanitarian Operations Response vehicle, or THOR—at their joint 5G ‘living lab’ on a California military base. 

THOR was built to operate under any network in any environment, from dense forests during wildfires to remote military settings. 

“At Marine Corps Air Station Miramar this week, we demonstrated THOR’s ability to enable a fully-operational 5G network that allowed: autonomous robot communication to a self-driving battery delivery vehicle, video streaming between people and vehicles in the field, data from sensors on devices operating in an austere environment, and 5G mobile edge computing being used to help decision-makers by providing a single operating picture of all of these data feeds in real-time,” Director of Verizon 5G Labs Christian Guirnalda explained Friday. 

Guirnalda and Director of Verizon Response and Public Safety Operations Cory Davis briefed Nextgov on the prototype and its potential impact across the defense and first response landscapes.

Almost a year ago, Verizon and the Marine Corps unveiled their experimental testbed at MCAS Miramar to strategically explore fifth-generation wireless technologies’ potential to support the Pentagon’s pursuits. It marked Verizon’s first-ever 5g Ultra Wideband service deployment on a military base. For DOD, it’s a chance to grow its insiders’ grasp of what the next-level technology is capable of and mature their understanding of how they can best put it to use.

“The first military base with 5G in the United States has seized the opportunity to bring together industry partners and stakeholders across the base to collaborate in new ways and accelerate innovation in their key areas of focus,” Guirnalda said.

Also a first- and one-of-a-kind, THOR is a prototype, 5G-based disaster response and command hub vehicle—and there are no present plans to build another. It has modular, private 5G and edge computing architecture at its core. Davis confirmed it’s designed to be National Incident Management System or NIMS-1 compliant and offers full radio interoperability and onboard Joint Operations Center services. In addition, it provides what he referred to as “a multitude of connectivity options,” spanning private 5G, commercial 4G LTE, Land Mobile Radio and tactical radio, wireless networking, microwave, mesh, and more—together in one package. Other components include 4G/5G radios, a rear command center, a camera, a 6-seat cabin, and an exterior touch screen display. 

Davis noted it’s also equipped with a tethered drone to capture an aerial view “that can be fed over the network to devices on the ground and the command center below, potentially helping those in public safety or the military with risk and damage assessment, situational awareness or search and rescue operations.”

“THOR is a bit like a Swiss-Army-Knife on wheels,” he added. 

Although 5G technology is more accessible than it has ever been, Davis said in some cases, there remains an opportunity “to boost the network and technological capabilities” of first responders and the U.S. military. 

“In situations ranging from fighting wildfires in forests where network connections and coverage can be challenging to the devastation and infrastructure damage caused by earthquakes, public safety professionals face the potential of coverage and technology gaps or an out-of-service network,” Davis noted. 

But Verizon built the futuristic vehicle to confront those challenges. “In a field where seconds always matter, and lives are on the line, connectivity and reliability matter,” he added.

THOR consists of the “full menu” of emerging and existing tech solutions. But Davis said future iterations for public safety or the military could potentially go “a la carte.” 

“In other words, these Verizon Frontline services can be delivered in a number of different configurations,” he explained.

Guirnalda added that THOR is essentially a proxy for the systems implemented with the 5G commercial network in California.

“The 5G network and 5G Edge, our mobile edge computing platform, will allow the same capabilities offered by THOR to provide permanent transformation at MCAS Miramar,” he said. “Energy management and resilience, EV and autonomous vehicles and supply chains, as well as base services to families, will all be enabled further with 5G.”

Share This:

NEXT STORY: It's Time to Wargame Against an AI-Enabled China

Pentagon Cancels JEDI Cloud Contract
Are UFOs Real? Government Continues To Investigate
VA Secretary: Changes Coming To Electronic Health Records Program
SPONSOR CONTENT
Trusted Internet Connection (TIC) 3.0
Back to top]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Twitter is ending a yearlong flirt with Fleets, its ephemeral posts feature. - The New York Times]]></title>
            <link>https://www.nytimes.com/2021/07/14/business/twitter-ending-fleets.html</link>
            <guid>https://www.nytimes.com/2021/07/14/business/twitter-ending-fleets.html</guid>
            <pubDate>Wed, 14 Jul 2021 19:55:59 GMT</pubDate>
            <content:encoded><![CDATA[SKIP TO CONTENT
SKIP TO SITE INDEX
SUBSCRIBE NOWLOG IN

ADVERTISEMENT

Continue reading the main story
Daily Business Briefing
Twitter is ending a yearlong flirt with Fleets, its ephemeral posts feature.
Twitter hoped its Fleets feature would lower the barrier to posting. Instead, the company said, people mostly used it to amplify their own tweets.
Credit...
Twitter

By Kate Conger

July 14, 2021, 1:29 p.m. ET

Twitter plans to remove an ephemeral-stories feature from its app after it failed to attract users, the company said in a blog post on Wednesday. The feature, Fleets, automatically deleted images or text after 24 hours.

Snapchat introduced the so-called stories format in 2013 as a bridge between its core private messaging features and the public sharing that most people expected from social media platforms. Instagram copied the feature in 2016, and ephemeral stories quickly spread across social media, including Facebook and LinkedIn.

Twitter arrived late to the trend, rolling out Fleets in March 2020. The company believed that the format would help new users become comfortable posting on Twitter by relieving the pressure that comes with making a permanent public post. But Fleets didn’t cause new users to flock to the platform, Twitter said.

“We hoped Fleets would help more people feel comfortable joining the conversation on Twitter,” Ilya Brown, a Twitter vice president of product, wrote in the blog post. “Although we built Fleets to address some of the anxieties that hold people back from Tweeting, Fleets are mostly used by people who are already Tweeting to amplify their own Tweets and talk directly with others.”

ADVERTISEMENT

Continue reading the main story

Twitter will remove Fleets from its service by Aug. 3, Mr. Brown said. It is the only major social media company to deactivate a stories feature.

The company will look into other ways to reduce the anxiety of tweeting for new users, Mr. Brown added. Twitter executives also said the company would continue to research the impact of its features and would not hesitate to move on from projects if the features did not resonate with users.

Dig deeper into the moment.
Special offer: Subscribe for $1 a week.

“Big bets are risky and speculative, so by definition a number of them won’t work,” Kayvon Beykpour, Twitter’s head of product, said in a tweet about the change. “If we’re not having to wind down features every once in a while, then it would be a sign that we’re not taking big enough swings.”

ADVERTISEMENT

Continue reading the main story
Site Index
Site Information Navigation
© 2021 The New York Times Company
NYTCoContact UsAccessibilityWork with usAdvertiseT Brand StudioYour Ad ChoicesPrivacy PolicyTerms of ServiceTerms of SaleSite MapHelpSubscriptions
Already have an account? Log in.
Keep reading with one of these options:
Limited articles
Free
Access some articles and personalized
email briefings.
Log in or create an account
Limited time offer
Unlimited access
$4.25 $1/week for one year
Enjoy unlimited news coverage and article access. Cancel online anytime.
Subscribe now
No commitment required, cancel anytime.
Your payment method will automatically be charged in advance every 4 weeks. You will be charged the introductory rate for the introductory period, and thereafter will be charged the standard rate. All subscriptions renew automatically. You can cancel anytime. Mobile apps are not supported on all devices. These offers are not available for current subscribers. Other restrictions and taxes may apply. Offers and pricing are subject to change without notice.
© 2021 The New York Times Company
Help
Feedback]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Doc Searls Weblog · A storage crisis]]></title>
            <link>http://blogs.harvard.edu/doc/2021/06/24/a-storage-crisis/</link>
            <guid>http://blogs.harvard.edu/doc/2021/06/24/a-storage-crisis/</guid>
            <pubDate>Wed, 14 Jul 2021 19:55:55 GMT</pubDate>
            <content:encoded><![CDATA[Doc Searls Weblog
Home
About
Me2B
People vs. Adtech

Subscribe to feed

‹ Redux 002: Listen Up  •  Speaking of character ›

A storage crisis

June 24, 2021 in Photography | 3 comments

The best new phones come with the ability to shoot 108 megapixel photos, record 4K video with stereo sound, and pack the results into a terabyte of onboard storage. But what do you do when that storage fills up?

If you want to keep those files, you’ll need to offload them somewhere. Since your computer probably doesn’t have more than 2Tb of storage, you’ll need an external drive. Or two. Or three. Or more. Over time, a lot more.

Welcome to my world.

Gathered here for a portrait in a corner of my desk in Manhattan are 22 hard drives, plus three SD cards that each exceed the capacities of the drives they’re laying on. And then there’s the 2Tb one in the laptop I’m using now. That one has 357.33Gb available. Most of the others you see are also full, dead, or both. Five have FireWire connections, which my current laptop doesn’t comprehend at all. I also have a similar collection of drives in Santa Barbara.

Photos occupy most of the data I’ve stored on all those drives. Currently my photo archives are spread between two portable drives and my laptop, and total about 7Tb. I also have a 5Tb portable drive for videos, which is back in Santa Barbara awaiting dubs off tapes. The portable photo drives are among those in the picture above. Earlier today, my laptop gave me this news about the main one, called Black 4Tb WD Photo Drive:

That’s why I’m transferring its contents over to the 10Tb drive called Elements, on the far left. A progress report:

About 5Tb of Elements is occupied by Apple Time Machine backups. After the transfer is done, there won’t be room for more backups. So my project now is figuring out what to do next.

I could get some Network Attached Storage (NAS). I already have used 2012-vintage 18Tb QNAP one in Santa Barbara that I’ve never been able to make work.

So I am tempted now to put it all in a cloud.

I hadn’t bothered with that before, because upstream speeds have been highly sphinctered by ISPs for decades. Here in New York, where our ISP is Spectrum, our speeds have long run 100-400 Mbps down, but only 10 Mbps up. However…. I just checked again with Speedtest.net, and got this:

And that’s over wi-fi.

Now I’m encouraged. But before I commit to a supplier, I’d like to hear what others recommend. Currently I’m considering Backblaze, which is top rated here. The cost i $6/month, or less for unlimited sums of data. But I’m open to whatever.

[Later…] Hmm. At that last link it says this:

What We Don’t Like:

Something I should mention is that some users have had bad experiences with Backblaze because of a not-so-apparent feature that maybe should be a lot more obvious: Backblaze doesn’t function as a permanent archive of all of your data, but instead as a mirror.

In other words, if you delete files on your computer, or the drive fails and you’re connected to Backblaze’s website, Backblaze will see that those files are gone and will remove them from your online account, too.

Granted, signing up for the forever version history option would eliminate any issues with this, but it still poses a problem for anyone using one of the limited version history options.

Alas, the forever thing is complicated.

To be clear, I want more than a mirroring of what I have on my laptop and external drives. I want to replace those external drives with cloud storage. Is that possible? Not clear.

Alas, for all of us, this problem remains.

Oh, and Spectrum now only measures under 10Mbps upstream. So forget the cloud.

SHARE THIS:
Click to share on LinkedIn (Opens in new window)
Click to share on Facebook (Opens in new window)
Click to share on Google+ (Opens in new window)
Click to email this to a friend (Opens in new window)
Click to share on Tumblr (Opens in new window)
Click to share on Pinterest (Opens in new window)

Tags: Storage

3 comments

Comments feed for this article

Trackback link: http://blogs.harvard.edu/doc/2021/06/24/a-storage-crisis/trackback/

ksfiles on June 24, 2021 at 5:16 pm

Hi Doc,

One combination I have found really handy is Backblaze B2 (the storage API, not the backup app), and ODrive (a unified storage app, which provides file syncing to a variety of cloud services, and can also provide temporary or permanent shared links to your files).

B2 is reasonably cheap ($5/mo for a TB), and keeps file revision history. Meanwhile, ODrive allows you to mount your storage as a shared drive, without requiring hard drive space to cache the files locally (like Dropbox does).

I use it B2 both as primary storage for large files, and as a backup mirror for my QNAP fileserver (with its Hybrid Sync feature, I can get offsite backups of my backups really easily).

Trackback from Best Laptop for Agriculture Students on July 8, 2021 at 5:34 am

Doc Searls on July 12, 2021 at 5:55 pm

Thanks, ksfiles. Great advice.

I plan to do something like that when I get back to a university setting next month, where I expect to take advantage of fat fiber upstream capacity. The cable connection where I’ll be staying is, alas (I am told) just 10 MBp/s upstream.

And if I can get my QNAP rig going for real at home in Santa Barbara in September, I’ll follow your footsteps there as well.

Thanks again!

Reply

You must be logged in to post a comment.

Subscribe to feed

Powered by WordPress and Tarski

Protected by Akismet • Blog with WordPress]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Highlights from the Google for Games Developer Summit]]></title>
            <link>https://blog.google/technology/developers/highlights-google-games-developer-summit/</link>
            <guid>https://blog.google/technology/developers/highlights-google-games-developer-summit/</guid>
            <pubDate>Wed, 14 Jul 2021 19:55:54 GMT</pubDate>
            <content:encoded><![CDATA[Google serves cookies to analyze traffic to this site. Information about your use of our site is shared with Google for that purpose.See details.
OK
The Keyword
Share
The Keyword
Latest stories
Product updates
Company news
Press corner
RSS feed
Subscribe
DEVELOPERS
Highlights from the Google for Games Developer Summit

Jul 14, 2021

2 mins read

Share
C
Chris Luhur
Google for Games
Google for Games Developer Summit

This week, we hosted the Google for Games Developer Summit, a free digital event for game developers, publishers and advertisers to come together globally. Though we couldn’t meet in person, we’re grateful for the chance to share our latest solutions for developers to create immersive and memorable gaming experiences for players everywhere.

All keynotes and sessions from the summit are available on demand. Here are a few things we discussed during our keynote sessions:

Easier game development on Android

The new Android Game Development Kit can help make game development easier while Play as you download and the new Reach and devices data and insights tool can help get your games running on more screens and drive your launch success on Google Play.

Get the most out of your games on Stadia 

Bringing games to Stadia is now even easier. We revealed new initiatives coming soon that will maximize the return on launching Stadia titles, including an affiliate marketing program, sharing monthly Stadia Pro subscription revenue with partners and an updated revenue share split for new transactional games launching under the new Stadia terms.

Drive lasting business revenue and growth with Ads

This past year, we have seen more people than ever play online games, which means there’s a growth opportunity to build a more sustainable games business. Get players back to your game while focusing on profitability with target return on ad spend (tROAS) bidding for App campaigns for engagement, or maximize revenue within your game by using AdMob bidding.

tROAS bidding for App campaigns for engagement in Google Ads

Bring your game to global audiences with Google Cloud

With flexible, scalable gaming solutions like Open Saves, Google Cloud helps you serve great gaming experiences all over the world so you and your players can focus on the fun.

As more people turn to games both for entertainment and for connecting with friends and family, we’re inspired by how the gaming community thrived this past year. That’s why we’re more committed than ever to help take your games to the next level.


POSTED IN: DEVELOPERS  ADMOB  ANDROID  STADIA
Related stories
GOOGLE AD MANAGER
Making it easier for publishers to manage privacy and messaging
Jul 12, 2021
ADMOB
New ways to grow your games business sustainably
Jul 12, 2021
STADIA
Stadia Savepoint: June updates
Jul 02, 2021
A MESSAGE FROM OUR CEO
A new Android smartphone and 5G partnership with Jio
Jun 24, 2021
ANDROID
6 new features on Android this summer
Jun 15, 2021
STADIA
Stadia Savepoint: May updates
Jun 03, 2021
 
 
 
 
 

Follow Us

Privacy
Terms
About Google
Google Products
About the Keyword
 Help
English
Deutsch]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Accused Pirate Asks Court to Freeze Assets of 'Copyright Troll' Malibu Media * TorrentFreak]]></title>
            <link>https://torrentfreak.com/accused-pirate-asks-court-to-freeze-assets-of-copyright-troll-malibu-media-210710/</link>
            <guid>https://torrentfreak.com/accused-pirate-asks-court-to-freeze-assets-of-copyright-troll-malibu-media-210710/</guid>
            <pubDate>Wed, 14 Jul 2021 19:55:53 GMT</pubDate>
            <content:encoded><![CDATA[NEWS CONTACT SUBSCRIBE
Accused Pirate Asks Court to Freeze Assets of ‘Copyright Troll’ Malibu Media
July 10, 2021 by Ernesto Van der Sar
12 comments

HOME > LAWSUITS > COPYRIGHT TROLLS >

Malibu Media, the adult entertainment company that has demanded hefty settlements from thousands of pirates over the years, is sailing rough waters. The company has been suspended over tax troubles and now a wrongfully accused pirate has asked a Texas court to freeze Malibu's assets, to secure potential attorneys' fees.

In recent years, adult entertainment outfit Malibu Media has often been described as a copyright-trolling operation.

The company, known for its popular “X-Art” brand, has gone after thousands of alleged file-sharers in U.S. courts, collecting millions of dollars in settlements.

Accused Pirate Fight Back

Most accused pirates don’t put up a fight, but occasionally one does. This includes a “John Doe” who filed a countersuit accusing Malibu Media of abuse of process, among other things.

If the accused pirate wins this case, he hopes to recoup tens of thousands of dollars in legal fees. However, whether Malibu is able and willing to pay this is rather uncertain, as it appears to be in trouble.

Up until a year or two ago, the adult content company was one of the most active copyright trolls in the United States. In recent months, however, it hasn’t filed any new cases.

The Doe’s attorney previously discovered that Malibu’s corporate status had been suspended over tax deficiencies, which is still the case today. To stay ahead of any problems, the attorney then asked if the company’s CEO Colette Pelissier could be added as a defendant as well.

John Doe Wants to Freeze Malibu’s Assets

This week, “John Doe” is back in court looking for more guarantees. The accused pirate and his lawyer fear that Malibu could try to transfer assets elsewhere to avoid paying, and they request a preliminary injunction to prevent this from happening.

“Absent injunctive relief, Doe will suffer irreparable harm. He has incurred over $80,000.00 dollars in attorney’s fees and costs defending himself. And the evidence shows Malibu and its single member, Colette Pelissier, have a history of obscuring assets and ignoring judgments,” they write.

According to earlier testimony from Malibu’s CEO, the company only serves as a “pass-through” asset. The subscriptions for X-art.com go directly to Brigham Field, the husband of Pelissier, who recently filed for bankruptcy.

‘Flounting Court Orders’

In addition, John Doe’s attorney also highlights the problematic legal history of the adult entertainment company and its CEO.

“Pelissier has a history of flouting court orders and rules, spurring one judge to hold her in contempt,” the attorney writes, adding that “Malibu and Pelissier have several other judgments against them.”

These accusations are backed up with testimonies and references to other cases where Malibu ran into trouble. And in a separate filing this week, Malibu itself confirms that the tax issues have not yet been resolved.

Imminent Risk

According to the accused pirate, this is sufficient evidence to issue an injunction and temporarily freeze all assets.

“All in all, this evidence reveals a sizeable and imminent risk that Malibu will not pay any fee award to Doe, that Pelissier will conceal or move Malibu’s assets, or both.”

This injunction should cover all subscription fees from the x-art.com website, as well as the domain itself. In addition, Malibu should not be allowed to transfer any settlement funds it receives, nor should it transfer any copyrights to other entities.

At the time of writing, Malibu Media hasn’t responded to this request, but the company will likely object.

—

A copy of John Doe’s motions for a preliminary injunction to freeze assets is available here (pdf)

Next Post
Previous Post
Tagged In:
copyright trolls Malibu Media
You Might Also Like:

LAWSUITS

Movie Pirates Beware: Does ‘The Marksman’ Have You In His Crosshairs?
June 27, 2021, 13:22 by Andy Maxwell
12

LAWSUITS

EU Court: Copyright Trolls Can Target BitTorrent Pirates Provided Claims Aren’t ‘Abusive’
June 21, 2021, 18:17 by Andy Maxwell
13

LAWSUITS

‘Pirate’ Law Firm Pressured Cooperative Housing Project to Settle Porn ‘Lawsuit’
April 13, 2021, 20:21 by Andy Maxwell
6

There are 12 comments. Add yours?

Comment Policy

SPONSORS





POPULAR POSTS
Which VPN Providers Really Take Privacy Seriously in 2021?
Top 10 Most Popular Torrent Sites of 2021
SPARKS Piracy Busts: Facts, Rumors & Fear Point to Something Huge
How ‘Anonymous’ is a Seedbox Provider?
Meet FitGirl, The Repack ‘Queen’ Of Pirated Games
MOST COMMENTED POSTS
96
Top 10 Most Pirated Movies of The Week – 07/12/2021
35
Sony Thinks Cloud Gaming Can Eliminate Piracy (and Consoles)
21
Comcast Suspends Internet Connection For Downloading Torrents
31
Should Internet Users Pay a Piracy Levy To Ensure Creators Get Paid?
10
OMI IN A HELLCAT: My Pirate IPTV Service Was Legal. US Govt: No Way
FROM 2 YEARS AGO…
•••
Kodi Addon & Build Repositories Shut Down Citing Legal Pressure (Updated)
TorrentFreak Stats
13243

BREAKING NEWS STORIES

 
179k

SOCIAL MEDIA FOLLOWERS

 
19.9k

RSS SUBSCRIBERS

Copyright · Privacy Policy · VPN Providers · About TorrentFreak

 ]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Learn Something Old Every Day | OS/2 Museum]]></title>
            <link>https://www.os2museum.com/wp/learn-something-old-every-day/</link>
            <guid>https://www.os2museum.com/wp/learn-something-old-every-day/</guid>
            <pubDate>Wed, 14 Jul 2021 19:55:51 GMT</pubDate>
            <content:encoded><![CDATA[OS/2 Museum
OS/2, vintage PC computing, and random musings
Skip to content
Home
About
OS/2 History
DOS History
NetWare History
Windows History
PC UNIX History
← Dirty Work
Learn Something Old Every Day
Posted on July 14, 2021 by Michal Necasek

More or less by accident I found myself writing a very basic DOS utility to read data off of an IDE drive. It started out by just issuing the IDENTIFY DRIVE command and capturing the data, but adding the ability to read sectors was not difficult.

In case that sounds pointless, it kind of is, except it allows me to attach a secondary IDE channel to an old 486 board whose BIOS only supports primary IDE. Thus the secondary channel is open to experiments without any BIOS interference. And this kind of setup lets me work with drives that for one reason or another do not work with a semi-modern system, including broken drives that may not be able to read/write at all but still have functioning electronics.

Once I got as far as identifying and reading old IDE drives, I realized that it’s not too difficult to extend the code to work with pre-IDE drives. The catch is not relying on IDENTIFY DRIVE but instead manually supplying the drive geometry. Once that was done, the rest of the code worked unchanged with my ancient Seagate ST-225 drive (by the way, that drive is now 35 years old and still can be read with no bad sectors).

Well… the code almost worked.

When the entire drive was read, the heads obviously ended up being positioned at the last cylinder. Upon starting the utility again, the drive started seeking back to the beginning but my code timed out before the drive was done moving the heads.

Okay, so I extended the timeout. That did the job, the second invocation of my utility now worked. But then I started wondering: The initial timeout was about three seconds. The ST-225 drive is specified to have maximum (full) seek time of 150 milliseconds. Three seconds really should have been far more than enough!

Yet I could clearly hear that the drive did take a bit more than three seconds to complete the full seek. Why could that be?

I’m fairly familiar with ATA standards and IDE drive documentation, but this turned out to be one of those things that IDE doesn’t really talk about at all. IDE drives, being integrated, don’t need to be told how fast they should seek—they already know.

But with old ST506 interface drives and PC/AT style controllers (in my case, a true blue IBM/WD adapter P/N 68X3948) it’s a little more complicated. Most ST506 drives, including the ST-225, can buffer step pulses that the controller issues very rapidly and then seek to the desired track as fast as the drive can.

Really old drives don’t work like that though. They behave very much like floppy drives and the controller directly moves the stepper motor. And just like with floppy drives, the step rate is variable. On the IBM/WD controller, it ranges from 0.5ms to 7.5ms in increments of 0.5ms. There are thus 15 step rates to choose from, and there’s a special 16th rate of 35 microseconds per step that is used with drives that can buffer step pulses.

Reading IBM’s Fixed Disk and Diskette Drive Adapter Technical Reference, the answer was staring me in the face: “After a Diagnose or Reset Command, the stepping rate is set to 7.5 milliseconds.”

The ST-225 drive has 615 cylinders; at 7.5ms per step, moving the head from one end of the drive to another takes over 4.5 seconds. No wonder the 3-second timeout wasn’t quite enough!

The same Technical Reference also explained how to fix the problem. The RECALIBRATE (called Restore in IBM documentation) and SEEK commands take the step rate as input in the low nibble of the command (1xh for RECALIBRATE, 7xh for SEEK). The step rate is then used for subsequent implied seeks, and my code only used implied seeks, not explicit SEEK commands.

Once I added a RECALIBRATE command to my code (with command code 10h, setting the maximum step rate), the full seek became quite a bit faster—presumably closer to 150 milliseconds than 4.5 seconds—and the drive sounded noticeably different, too. I could lower the timeout back to 3 seconds and things were no longer timing out.

Again, this detail is not mentioned anywhere in the ATA specifications, not even in the first ATA standard draft from 1990. But given the provenance of some early IDE drives, I’m now wondering if there might be some IDE drives where RECALIBRATE not only moves the heads to track zero but also sets the step rate, and if RECALIBRATE is omitted, seeks will be extremely slow. Something to investigate later.

This entry was posted in Documentation, PC hardware, PC history, Seagate, Storage. Bookmark the permalink.
← Dirty Work
Leave a Reply

Your email address will not be published. Required fields are marked *

Comment 

Name * 

Email * 

Website 

 Really, I am not a spammer.

This site uses Akismet to reduce spam. Learn how your comment data is processed.

Archives
July 2021
June 2021
May 2021
April 2021
March 2021
February 2021
January 2021
December 2020
November 2020
October 2020
September 2020
August 2020
July 2020
June 2020
May 2020
April 2020
March 2020
February 2020
January 2020
December 2019
November 2019
October 2019
September 2019
August 2019
July 2019
June 2019
May 2019
April 2019
March 2019
February 2019
January 2019
December 2018
November 2018
October 2018
August 2018
July 2018
June 2018
May 2018
April 2018
March 2018
February 2018
January 2018
December 2017
November 2017
October 2017
August 2017
July 2017
June 2017
May 2017
April 2017
March 2017
February 2017
January 2017
December 2016
November 2016
October 2016
September 2016
August 2016
July 2016
June 2016
May 2016
April 2016
March 2016
February 2016
January 2016
December 2015
November 2015
October 2015
September 2015
August 2015
July 2015
June 2015
May 2015
April 2015
March 2015
February 2015
January 2015
December 2014
November 2014
October 2014
September 2014
August 2014
July 2014
June 2014
May 2014
April 2014
March 2014
February 2014
January 2014
December 2013
November 2013
October 2013
September 2013
August 2013
July 2013
June 2013
May 2013
April 2013
March 2013
February 2013
January 2013
December 2012
November 2012
October 2012
September 2012
August 2012
July 2012
June 2012
May 2012
April 2012
March 2012
February 2012
January 2012
December 2011
November 2011
October 2011
September 2011
August 2011
July 2011
June 2011
May 2011
April 2011
March 2011
January 2011
November 2010
October 2010
August 2010
July 2010
Categories
286
386
3Com
3Dfx
486
8086/8088
Adaptec
AGP
AMD
AMD64
Apple
Archiving
ATi
BIOS
Books
Borland
BSD
Bugs
BusLogic
C
C&T
Cirrus Logic
CompactFlash
Compaq
Compression
Conner
Corrections
Creative Labs
Crystal Semi
Cyrix
DDR RAM
Debugging
DEC
Development
Digital Research
Documentation
DOS
DOS Extenders
Dream
E-mu
Editors
EISA
Ensoniq
ESDI
Ethernet
Fakes
Fixes
Floppies
Graphics
Hardware Hacks
IBM
IDE
Intel
Internet
Keyboard
Kryoflux
Kurzweil
LAN Manager
Legal
Linux
MCA
Microsoft
MIDI
NetWare
Networking
NeXTSTEP
NFS
Novell
NT
OS X
OS/2
PC architecture
PC hardware
PC history
PC press
PCI
PCMCIA
Pentium
Pentium 4
Pentium II
Pentium III
Pentium Pro
Plug and Play
PowerPC
Pre-release
PS/2
QNX
Random Thoughts
RDRAM
Roland
Ryzen
S3
SCO
SCSI
Seagate
Security
Site Management
SMP
Software Hacks
Solaris
Sound
Sound Blaster
Source code
Storage
Supermicro
TCP/IP
ThinkPad
Trident
UltraSound
Uncategorized
Undocumented
UNIX
UnixWare
USB
VGA
VirtualBox
Virtualization
VLB
Watcom
Wave Blaster
Western Digital
Windows
Windows 95
Windows XP
Wireless
WordStar
x86
Xenix
Xeon
Yamaha
OS/2 Museum
Proudly powered by WordPress.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Say hello to the Windows 365 Cloud PC | Computerworld]]></title>
            <link>https://www.computerworld.com/article/3625450/say-hello-to-the-windows-365-cloud-pc.html</link>
            <guid>https://www.computerworld.com/article/3625450/say-hello-to-the-windows-365-cloud-pc.html</guid>
            <pubDate>Wed, 14 Jul 2021 19:55:49 GMT</pubDate>
            <content:encoded><![CDATA[computerworld
 
UNITED STATES 
 
  
BUSINESS TECH
Browsers
Blockchain
Cloud Computing
Collaboration Tech
Macs
Office Software
Productivity Software
Small Business
Windows
MOBILE TECH
Android
Chrome OS & Chromebooks
iOS
SHARK TANK
DIGITAL DOWNLOADS
NEWSLETTERS
IDG EVENTS
BEST PLACES TO WORK
IN-DEPTH
News Analysis
Features
How To
Opinion
Reviews
VIDEO
TECH(talk)
IDG TECH(talk) Channel
PODCASTS
BLOGS
RESOURCE LIBRARY
 
SIGN IN
REGISTER
FROM OUR PARTNERS
The Latest Content from Our Sponsors
MORE FROM THE IDG NETWORK
The voice of IT leadership
Analytics
Careers
CIO Role
Security at the speed of business
Application Security
Cloud Security
Identity Management
From the data center to the edge
Data Center
Internet of Things
Linux
Building the next-gen enterprise
Analytics
Cloud Computing
Databases
About Us |Contact |Reprints |Privacy Policy |Cookie Policy |Member Preferences |Advertising |IDG Careers |Ad Choices |E-commerce Links |California: Do Not Sell My Personal Info Follow Us   
There are two kinds of desktops: Yours and someone else's
RELATED STORIES
Everything you need to know about Windows 10X
OPINION
Say hello to the Windows 365 Cloud PC
It's finally here: A full Windows desktop-as-a-service is now ready to replace your Windows desktop on a PC.
     

By Steven J. Vaughan-Nichols

Computerworld | JUL 14, 2021 11:47 AM PDT

Microsoft

It's good to finally see Windows 365 Cloud PC arrive. I've been talking about Microsoft's Desktop-as-a-Service (DaaS) for years. (Yes, I know all about Windows 11, which I think is just a massive Windows 10 security patch. Windows 11 was never, contrary to what some people think, the future of Windows.)

Tomorrow's desktop, as far as Microsoft's concerned, is going to be Windows running on its Azure cloud.

WHITE PAPERS
	

Banking Transformed

	

Connecting Marketing at High Velocity

	

Powering the CMO Agenda in Banking and Capital Markets Through the Adobe Suite of Products

SEE ALL WHITE PAPERS

When I say, "Windows running on the Azure cloud," I mean running on the cloud. There needs to be some kind of operating system on your PC, but, frankly, Microsoft doesn't care what you’re using. As Wangui McKelvey, Microsoft 365's General Manager, said: "Windows 365 takes the operating system to the Microsoft Cloud, securely streaming the full Windows experience — including all your apps, data, and settings — to your personal or corporate devices. This approach creates a fully new personal computing category, specifically for the hybrid world: the Cloud PC."

[ Related: Say goodbye to all that: Microsoft ends Windows-as-a-Service ]

Microsoft explicitly states that you'll be able to stream all your personalized applications, tools, data, and settings from the cloud across any device. And it means any, including  the Mac, iPads, Linux PCs, and Android devices. No matter what you're running, you'll get the same Windows experience. It also means "You can pick up right where you left off, because the state of your Cloud PC remains the same, even when you switch devices."

What Windows 11 means for the enterprise
Volume 0%
 

What about in-house apps? While Microsoft can't promise you'll be able to run some  customized program you set up in the 1990s, Windows 365 supports all of its business apps — Microsoft 365, Microsoft Dynamics 365, Microsoft Power Platform — line-of-business apps, and more. The company also promises to stand by its promise of app compatibility with Microsoft's Fastrack App Assure. This is a service designed to help businesses with 150 or more users fix any app problems at no additional cost.

Microsoft has also been working with its independent software vendor (ISV) partners. The four largest turning their efforts towards Windows 365 are Nerdio, NetApp, ServiceNow, and UKG.  

Microsoft isn't reinventing the wheel here. As I have been pointing out ad nauseam, Microsoft has been moving to a Windows DaaS for years now. Specifically, Windows 365 is built on Azure Virtual Desktop. Unlike the Azure Virtual Desktop, which takes an expert to set up properly, Microsoft sets up Windows 365 for you. You control how to scale your Windows 365 instances and monitor Cloud PC's performance, and you don't need to be an Azure Solutions Architect Expert to create and manage your new virtual Cloud PCs.

RECOMMENDED WHITEPAPERS
	

Banking Transformed

	

Connecting Marketing at High Velocity

	

Powering the CMO Agenda in Banking and Capital Markets Through the Adobe Suite of Products

Azure Virtual Desktop, by the way, isn't going anywhere. It will still be around. The key difference between Azure Virtual Desktop and Windows 365 is the former is optimized for flexibility, while the latter is set up for simplicity.

So does all of this sounds interesting? If so, you won’t have to wait long to try it out. Windows 365 will be available Aug. 2.

If this all sounds familiar to you, it should. Microsoft has been saying DaaS was the plan all along — if you listened closely enough. And Google's been offering a similar universal DaaS plan with its Chromebooks for more than a decade.

I recently noted that soon we'll have two "desktop" choices. One will be cloud-based with Windows 365 Cloud PC and Chrome OS. The other will be the old-school PC-centric operating systems: Linux and macOS. That day is coming faster than ever. 

Say hello to the real future of Windows. Like all the rest of IT, it's floating on the cloud.

Related: Windows Microsoft Cloud Computing Small and Medium Business

Steven J. Vaughan-Nichols has been writing about technology and the business of technology since CP/M-80 was the cutting-edge PC operating system, 300bps was a fast Internet connection, WordStar was the state-of-the-art word processor, and we liked it!

Follow

Copyright © 2021 IDG Communications, Inc.

 Learn how IT leaders are building cyberdefenses. Attend CSO's Future of Cybersecurity & Trust Summit-7/20-7/22
 
SHOP TECH PRODUCTS AT AMAZON
SPONSORED LINKS
Online Master of Science in Information Systems at Northwestern University
Cisco SecureX Simplify with the broadest, most integrated security platform
See how the new Webex Suite powers the McLaren F1 Team.
Reimagine remote work to catch the next wave in digital transformation. Read e-book
Bridge the clouds you have to the experience you want. Get started, today
Preparing Your Technology Foundation for a New Hybrid World
Getting a Grip on Basic Cyber Hygiene with the CIS Controls
NETSCOUT Visibility Without Borders helps you see it all from the data center to the cloud, and everywhere in between.
NetApp let's you unleash SAP anywhere. Migrate and innovate fiercely.
Computerworld
The Voice of Business Technology
FOLLOW US
ABOUT USCONTACTREPRINTSPRIVACY POLICYCOOKIE POLICYMEMBER PREFERENCESADVERTISINGIDG CAREERSAD CHOICESE-COMMERCE LINKSCALIFORNIA: DO NOT SELL MY PERSONAL INFO

Copyright © 2021 IDG Communications, Inc.

Explore the IDG Network
descend]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Coca-Cola Is Changing Coke Zero's Flavor, Risking Backlash - The New York Times]]></title>
            <link>https://www.nytimes.com/2021/07/14/business/coke-zero-change.html</link>
            <guid>https://www.nytimes.com/2021/07/14/business/coke-zero-change.html</guid>
            <pubDate>Wed, 14 Jul 2021 19:55:43 GMT</pubDate>
            <content:encoded><![CDATA[SKIP TO CONTENT
SKIP TO SITE INDEX
SUBSCRIBE NOWLOG IN

ADVERTISEMENT

Continue reading the main story
Coca-Cola Is Changing the Flavor of a Soda. Again.

The company promised “an even more iconic Coke taste” for its new version of Coke Zero. But some anxious consumers remember the New Coke debacle of 1985.

By Maria Cramer

July 14, 2021, 2:59 p.m. ET

Coca-Cola changed the flavor of its soda in 1985 and enraged a nation.

Now, the company is doing it again, risking another outcry. This time, it is changing the taste and look of one of its most popular soft drinks: Coca-Cola Zero Sugar, better known as Coke Zero, the diet spinoff that is supposed to closely resemble the sugary version of “classic” Coke.

Company officials said on Tuesday that the plan was to change the drink in such a way that it would “deliver an even more iconic Coke taste.”

Anxious Americans, or at least the ones who regularly quaff Coke Zero, will be the judge.

Already, on social media, worry and apprehension greeted the impending change. Some consumers vowed to switch to other drinks, like Diet Dr Pepper, or threatened to turn to the drink of Coca-Cola’s archrival, Pepsi.

Others recalled the marketing debacle of 1985, when Coca-Cola unveiled “The New Coke,” a sweeter version of the original soft drink that was rejected by many consumers.

ADVERTISEMENT

Continue reading the main story

A Detroit waitress told The New York Times that year that the soda was “flat and too sweet.” A writer in Florida called it “a taste tragedy.” A spokesman for Pepsi-Cola declared it “a tremendous opportunity for us.”

That change was an attempt to beat back the growing success of Pepsi, which was beginning to cut into Coca-Cola’s market share.

Daily business updates  The latest coverage of business, markets and the economy, sent by email each weekday. Sign up.

But consumers hated the New Coke. In June 1985, the company was getting 1,500 calls a day on its consumer hotline.

“People seemed to hold any Coca-Cola employee — from security officers at our headquarters building to their neighbors who worked for Coke — personally responsible for the change,” according to a detailed account of the fiasco on the company’s website, which describes the episode as one of the “most memorable marketing blunders ever.”

ADVERTISEMENT

Continue reading the main story

The flavor change so angered people that an episode of the sitcom “The Golden Girls” referred to the fury in a joke, consumers stockpiled cans of the original, and at least one lawsuit tried to make Coca-Cola return to its original formula. (A federal judge rejected the suit, mentioning that he preferred Pepsi.)

Daily Business Briefing
Latest Updates
Updated 
July 13, 2021, 6:52 p.m. ET
July 13, 2021
July 13, 2021
TIAA is accused of misleading retirement investors in latest scrutiny of its tactics.
Norwegian Cruise Line Holdings sues Florida over prohibition on vaccine requirements.
A judge blocked Maryland’s bid to cut off federal unemployment benefits.

In July 1985, after only three months, the company announced that it would restore the original Coca-Cola, now rebranded as “Coca-Cola Classic,” to store shelves. “If that is what the consumer wants, that is what we will give him,” Charles Millard, chairman of the Coca-Cola Bottling Company of New York, said after the about-face.

Image
Credit...
Todd Gipstein/CORBIS, via Corbis, via Getty Images

This time around, the change is not likely to cause the same sort of backlash, despite some of the early grumbling, said Doug Bowman, professor of marketing at Emory University’s Goizueta Business School.

“This is a strategy where Coke is trying to stay ahead of the market,” he said.

In general, consumers have grown used to beverage companies changing and adapting popular drinks. Professor Bowman noted that in the nearly 40 years since the New Coke kerfuffle, vodka companies have introduced vanilla, lime and peach flavors; popular beer brands have experimented with myriad tastes; and both Coke and Pepsi have dabbled in fruit varieties.

Coca-Cola even made a limited supply of “New Coke” available in 2019 as part of a promotion related to “Stranger Things,” the supernatural thriller set in the 1980s.

The advertised changes in the new Coke Zero are subtle by comparison, he said.

“It is hard to see anyone except the most die-hard Coke Zero Sugar people noticing the difference,” said Professor Bowman, who from 2002 to 2004 taught courses at Emory to Coca-Cola employees through a program paid for by the company.

ADVERTISEMENT

Continue reading the main story

Natalia Suarez, a senior brand manager at Coca-Cola, said in a statement that the company had tinkered with the soda recipe because, to keep growing, “we must keep challenging ourselves to innovate and differentiate just as other iconic brands have done.”

She added: “The consumer landscape is always changing, which means we must evolve to stay ahead.”

Coca-Cola Zero Sugar, which the company released in 2005, has had its flavor changed before. In 2017, the company said the product was “reformulated” so that it would taste more like standard Coca-Cola.

In its statement, the company said the new change “optimizes existing Coca-Cola Zero Sugar flavors and existing ingredients.”

Though the company did not say what that process would look like, it promised on social media that it would not change the ingredients, which include carbonated water, caramel color, phosphoric acid, aspartame, caffeine and potassium benzoate.

ADVERTISEMENT

Continue reading the main story
Site Index
Site Information Navigation
© 2021 The New York Times Company
NYTCoContact UsAccessibilityWork with usAdvertiseT Brand StudioYour Ad ChoicesPrivacy PolicyTerms of ServiceTerms of SaleSite MapHelpSubscriptions
Already have an account? Log in.
Keep reading with one of these options:
Limited articles
Free
Access some articles and personalized
email briefings.
Log in or create an account
Limited time offer
Unlimited access
$4.25 $1/week for one year
Enjoy unlimited news coverage and article access. Cancel online anytime.
Subscribe now
No commitment required, cancel anytime.
Your payment method will automatically be charged in advance every 4 weeks. You will be charged the introductory rate for the introductory period, and thereafter will be charged the standard rate. All subscriptions renew automatically. You can cancel anytime. Mobile apps are not supported on all devices. These offers are not available for current subscribers. Other restrictions and taxes may apply. Offers and pricing are subject to change without notice.
© 2021 The New York Times Company
Help
Feedback]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Sullivan: Data Privacy Key To AI Race Against China - Defense One]]></title>
            <link>https://www.defenseone.com/technology/2021/07/sullivan-data-privacy-key-ai-race-against-china/183747/</link>
            <guid>https://www.defenseone.com/technology/2021/07/sullivan-data-privacy-key-ai-race-against-china/183747/</guid>
            <pubDate>Wed, 14 Jul 2021 19:55:38 GMT</pubDate>
            <content:encoded><![CDATA[CONTINUE TO THE SITE 
Information Warfare Looms Larger In Russia’s New Security Strategy
Sullivan: Data Privacy Key To AI Race Against China
Reduce The Pentagon’s Dependence On China By Recharging US Battery, Electronics Industry
SPONSOR CONTENT
How The DoD Is Tapping Hardware Security Keys To Protect Against Threats
Skip to Content

: National Security Advisor Jake Sullivan talks to reporters during the daily news conference in the Brady Press Briefing Room at the White House on June 07, 2021 in Washington, DC. CHIP SOMODEVILLA/GETTY IMAGES

Sponsor Message

Get all our news and commentary in your inbox at 6 a.m. ET.

email
SCIENCE & TECH
Sullivan: Data Privacy Key To AI Race Against China
New privacy-protecting technologies will enable democracies to work together to win the AI race against China, says Biden’s national security advisor.

PATRICK TUCKER 

| JULY 13, 2021 11:26 PM ET
CHINA ARTIFICIAL INTELLIGENCE
   

If the United States is going to bring allies together to set norms  around new technologies like AI, they’ll have to address concerns about privacy, said Jake Sullivan, the national security advisor to U.S. President Joe Biden, said on Tuesday.

Speaking at the National Security Commission for Artificial Intelligence summit in Washington, D.C., Sullivan noted several recent Biden-administration initiatives aimed at setting multinational standards on 5G and other new technologies, and coordinating on supply-chain issues. One is the  Quad Critical and Emerging Technology Working Group, composed of representatives from India, Australia, Japan and the United States. 

But there is a lot of relationship repair work with allies to do. Areas of disagreement have emerged over the last several years between the United States and Europe around consumer data and how some American companies were treating it. In 2018, the European Union enacted a massive privacy law called the General Data Protection Regulation, or GDPR, squarely aimed at how Silicon Valley companies were using Europeans’ data. And the European Union has since taken steps to further restrict how European companies’ data is shared. 

Sullivan on Tuesday said concerns about privacy wouldn’t necessarily be a barrier to better U.S. and allied partnership on AI. In fact, he said, privacy concerns actually underscore the two communities’ shared values and provide an important contrast with less democratic states like China and Russia. 

“I actually think there are innovations in the space and standards we can set that will give us the advantage over those societies that instead have shredded any notion of privacy. The large majority of the world actually is not ready to sign onto a vision of the future that says you have absolutely no privacy. No Trust. No security… big data owned by the government,” he said. 

Specifically, he highlighted emerging technologies like “privacy-preserving machine learning,” or PPML, that can allow machine learning algorithms to process data without revealing personal information in the data itself. Such technologies “promise to overcome data privacy challenges while still delivering the value of big data,” he said. 

That tracks closely with the NSCAI commission report, which sought to help the United States to compete on AI.  “The United States can use diplomacy and leverage its global partnerships to advocate for establishing privacy-protecting technical standards and norms in international bodies, and it can work with like-minded nations to ensure that other nations have an alternative to embracing China’s technology and methods of social control and access to technologies that protect democratic values like privacy,” it said.

The Biden administration was increasing the government’s ability to better monitor how companies are using consumers under Executive Order 13873, Sullivan said, an order that relates to the digital supply chain and connected devices, as well as the data those devices collect.

“Our strategic competitors see big data as a strategic asset. And we have to see it the same way.  But data security and privacy go to the heart of our national competitiveness, and the free flow of data with trust and security is critical for the third wave of the digital revolution,” he said. 

SHARE THIS:

NEXT STORY: Information Warfare Looms Larger in Russia’s New Security Strategy

Is The Biden Administration Proud Of Its Pentagon Budget?
Don’t Just End The War In Afghanistan, Repeal The Resolution That Authorized It
As Space Junk Multiplies, Pentagon Is Stuck Tracking It For Civilians
Libya’s UAV Strike Should Galvanize Efforts To Do Something About Autonomous Weapons
Back to top]]></content:encoded>
        </item>
    </channel>
</rss>